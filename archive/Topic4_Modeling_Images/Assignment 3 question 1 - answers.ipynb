{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uj4T8PEHGbMF"
   },
   "source": [
    "# Assignment 3\n",
    "## Question 1: Siamese networks & one-shot learning (8pt)\n",
    "The Cifar-100 dataset is similar to the Cifar-10 dataset. It also consists of 60,000 32x32 RGB images, but they are distributed over 100 classes instead of 10. Thus, each class has much less examples, only 500 training images and 100 testing images per class. For more info about the dataset, see https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "*HINT: Import the Cifar-100 dataset directly from Keras, no need to download it from the website. Use* `label_mode=\"fine\"`\n",
    "\n",
    "### Task 1.1: Siamese network\n",
    "**a)**\n",
    "* Train a Siamese Network on the first 80 classes of (the training set of) Cifar-100, i.e. let the network predict the probability that two input images are from the same class. Use 1 as a target for pairs of images from the same class (positive pairs), and 0 for pairs of images from different classes (negative pairs). Randomly select image pairs from Cifar-100, but make sure you train on as many positive pairs as negative pairs.\n",
    "\n",
    "* Evaluate the performance of the network on 20-way one-shot learning tasks. Do this by generating 250 random tasks and obtain the average accuracy for each evaluation round. Use the remaining 20 classes that were not used for training. The model should perform better than random guessing.\n",
    "\n",
    "For this question you may ignore the test set of Cifar-100; it suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
    "\n",
    "*HINT: First sort the data by their labels (see e.g.* `numpy.argsort()`*), then reshape the data to a shape of* `(n_classes, n_examples, width, height, depth)`*, similar to the Omniglot data in Practical 4. It is then easier to split the data by class, and to sample positive and negative images pairs for training the Siamese network.*\n",
    "\n",
    "*NOTE: do not expect the one-shot accuracy for Cifar-100 to be similar to that accuracy for Omniglot; a lower accuracy can be expected. However, accuracy higher than random guess is certainly achievable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7637,
     "status": "ok",
     "timestamp": 1521032642324,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "MUtFUcp9GbMG",
    "outputId": "3e03b53f-309c-47ee-d4b9-e796b4104c4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "NYuDudaRGbMK"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "import pickle\n",
    "\n",
    "# load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode=\"fine\")\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# transform the dataset\n",
    "img_rows, img_cols, chns = 32, 32, 3\n",
    "n_classes = 100\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], chns, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], chns, img_rows, img_cols)\n",
    "    input_shape = (chns, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, chns)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, chns)\n",
    "    input_shape = (img_rows, img_cols, chns)\n",
    "\n",
    "# normalise the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# find the order of indices that sort the datasets by label\n",
    "sort_indices_train = y_train.argsort()\n",
    "sort_indices_test = y_test.argsort()\n",
    "\n",
    "# sort the data by label, and reshape into (n_classes, n_examples, width, height, depth)\n",
    "x_train_sorted = x_train[sort_indices_train]\n",
    "x_test_sorted = x_test[sort_indices_test]\n",
    "x_train_sorted = x_train_sorted.reshape(100, 500, img_rows, img_cols, chns)\n",
    "x_test_sorted = x_test_sorted.reshape(100, 100, img_rows, img_cols, chns)\n",
    "\n",
    "# sort the labels\n",
    "y_train_sorted = y_train[sort_indices_train]\n",
    "y_test_sorted = y_test[sort_indices_test]\n",
    "\n",
    "# split the data 80/20\n",
    "x_train_80 = x_train_sorted[:80, :, :, :, :]\n",
    "x_test_80 = x_test_sorted[:80, :, :, :, :]\n",
    "x_train_20 = x_train_sorted[80:, :, :, :, :]\n",
    "x_test_20 = x_test_sorted[80:, :, :, :, :]\n",
    "y_train_80 = y_train_sorted[:80*500]\n",
    "y_test_80 = y_test_sorted[:80*100]\n",
    "y_train_20 = y_train_sorted[80*500:]\n",
    "y_test_20 = y_test_sorted[80*100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 756,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1521032665453,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "UpEQTLtZ0Yby",
    "outputId": "7cd08fbe-f45b-465d-9eb8-877c68c12f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              51384320  \n",
      "=================================================================\n",
      "Total params: 51,404,096\n",
      "Trainable params: 51,403,904\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         51404096    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 51,408,193\n",
      "Trainable params: 51,408,001\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "# build convnet to use in each siamese \"leg\"\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.5))\n",
    "convnet.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "convnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.5))\n",
    "\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096, activation='sigmoid'))\n",
    "\n",
    "convnet.summary()\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "# merge two encoded inputs with the L1 distance between them, and connect to prediction output layer\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = Lambda(L1_distance)([encoded_l, encoded_r])\n",
    "prediction = Dense(1, activation='sigmoid')(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
    "\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mjt6sGa89O5A"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs = [np.zeros((batch_size, h, w, d)) for i in range(2)]\n",
    "    # initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "    targets = np.zeros((batch_size,))\n",
    "    targets[batch_size//2:] = 1\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = np.random.randint(0, n_examples)\n",
    "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, d)\n",
    "        idx_2 = np.random.randint(0, n_examples)\n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        if i >= batch_size // 2:\n",
    "            category_2 = category\n",
    "        else:\n",
    "            #add a random number to the category modulo n_classes to ensure 2nd image has different category\n",
    "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h, d)\n",
    "    return pairs, targets\n",
    "\n",
    "def batch_generator(batch_size, X):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size, X)\n",
    "        yield (pairs, targets)\n",
    "\n",
    "def train(model, X_train, batch_size=64, steps_per_epoch=100, epochs=1):\n",
    "    model.fit_generator(batch_generator(batch_size, X_train), steps_per_epoch=steps_per_epoch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lEZrudhXNweZ"
   },
   "outputs": [],
   "source": [
    "def make_oneshot_task(N, X):\n",
    "    \"\"\"Create pairs of (test image, support set image) with ground truth, for testing N-way one-shot learning.\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    indices = np.random.randint(0, n_examples, size=(N,))\n",
    "    categories = np.random.choice(range(n_classes), size=(N,), replace=False)            \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
    "    test_image = np.asarray([X[true_category, ex1, :, :, :]]*N).reshape(N, w, h, d)\n",
    "    support_set = X[categories, indices, :, :, :]\n",
    "    support_set[0, :, :] = X[true_category, ex2]\n",
    "    support_set = support_set.reshape(N, w, h, d)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image, support_set]\n",
    "    return pairs, targets\n",
    "\n",
    "def test_oneshot(model, X, N=20, k=250, verbose=True):\n",
    "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N, X)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct += 1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SkOIA1V9PBTc"
   },
   "outputs": [],
   "source": [
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc,h,w,d = X.shape\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h,d))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h,:] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "def plot_oneshot_task(pairs):\n",
    "    \"\"\"Takes a one-shot task given to a siamese net and  \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.imshow(pairs[0][0])\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 248,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1521032668201,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "tVCEAF2mQPt9",
    "outputId": "e0cbbe71-c10b-4ca8-9989-f4f0cc98b075"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHEAAADnCAYAAAApQbmOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndUfE26DuiHgb1P8JhnOjGQh/K2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad760644a8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs, targets = make_oneshot_task(20, x_train_20)\n",
    "plot_oneshot_task(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 17306,
     "output_extras": [
      {
       "item_id": 141
      },
      {
       "item_id": 254
      },
      {
       "item_id": 393
      },
      {
       "item_id": 449
      },
      {
       "item_id": 488
      },
      {
       "item_id": 528
      },
      {
       "item_id": 568
      },
      {
       "item_id": 608
      },
      {
       "item_id": 646
      },
      {
       "item_id": 681
      },
      {
       "item_id": 714
      },
      {
       "item_id": 754
      },
      {
       "item_id": 794
      },
      {
       "item_id": 834
      },
      {
       "item_id": 872
      },
      {
       "item_id": 913
      },
      {
       "item_id": 954
      },
      {
       "item_id": 994
      },
      {
       "item_id": 1034
      },
      {
       "item_id": 1075
      },
      {
       "item_id": 1114
      },
      {
       "item_id": 1155
      },
      {
       "item_id": 1194
      },
      {
       "item_id": 1234
      },
      {
       "item_id": 1275
      },
      {
       "item_id": 1314
      },
      {
       "item_id": 1354
      },
      {
       "item_id": 1395
      },
      {
       "item_id": 1435
      },
      {
       "item_id": 1473
      },
      {
       "item_id": 1508
      },
      {
       "item_id": 1542
      },
      {
       "item_id": 1582
      },
      {
       "item_id": 1622
      },
      {
       "item_id": 1662
      },
      {
       "item_id": 1699
      },
      {
       "item_id": 1732
      },
      {
       "item_id": 1769
      },
      {
       "item_id": 1808
      },
      {
       "item_id": 1848
      },
      {
       "item_id": 1889
      },
      {
       "item_id": 1928
      },
      {
       "item_id": 1969
      },
      {
       "item_id": 2007
      },
      {
       "item_id": 2046
      },
      {
       "item_id": 2079
      },
      {
       "item_id": 2116
      },
      {
       "item_id": 2155
      },
      {
       "item_id": 2194
      },
      {
       "item_id": 2234
      },
      {
       "item_id": 2273
      },
      {
       "item_id": 2312
      },
      {
       "item_id": 2352
      },
      {
       "item_id": 2392
      },
      {
       "item_id": 2431
      },
      {
       "item_id": 2471
      },
      {
       "item_id": 2512
      },
      {
       "item_id": 2551
      },
      {
       "item_id": 2592
      },
      {
       "item_id": 2629
      },
      {
       "item_id": 2662
      },
      {
       "item_id": 2699
      },
      {
       "item_id": 2738
      },
      {
       "item_id": 2777
      },
      {
       "item_id": 2817
      },
      {
       "item_id": 2858
      },
      {
       "item_id": 2897
      },
      {
       "item_id": 2937
      },
      {
       "item_id": 2963
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3026250,
     "status": "ok",
     "timestamp": 1520596811645,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "JnjQhc93RKeG",
    "outputId": "556b321f-5f3c-4c78-edad-dcf9e63f390f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training loop 1 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.8310\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 2 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.7327\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 3 ===\n",
      "Epoch 1/1\n",
      " 84/100 [========================>.....] - ETA: 1s - loss: 0.7085100/100 [==============================] - 12s 119ms/step - loss: 0.7045\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 4 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6873\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 5 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6834\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 6 ===\n",
      "Epoch 1/1\n",
      " 18/100 [====>.........................] - ETA: 9s - loss: 0.6807100/100 [==============================] - 12s 119ms/step - loss: 0.6821\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 7 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6777\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 8 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6884\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 9 ===\n",
      "Epoch 1/1\n",
      "  6/100 [>.............................] - ETA: 11s - loss: 0.6909100/100 [==============================] - 12s 119ms/step - loss: 0.6813\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 10 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6790\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 11 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6570\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 12 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6828100/100 [==============================] - 12s 119ms/step - loss: 0.6789\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 13 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6632\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 14 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6663\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 15 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6900100/100 [==============================] - 12s 120ms/step - loss: 0.6785\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 16 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6696\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 17 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6708\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 18 ===\n",
      "Epoch 1/1\n",
      "  5/100 [>.............................] - ETA: 11s - loss: 0.6922100/100 [==============================] - 12s 120ms/step - loss: 0.6659\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 19 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6658\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 20 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6667\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 21 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6674100/100 [==============================] - 12s 119ms/step - loss: 0.6612\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 22 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6600\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 23 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6623\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 24 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6542100/100 [==============================] - 12s 120ms/step - loss: 0.6604\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 25 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6591\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 26 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6563\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 27 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6582\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 28 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6607\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 29 ===\n",
      "Epoch 1/1\n",
      " 68/100 [===================>..........] - ETA: 3s - loss: 0.6655100/100 [==============================] - 12s 119ms/step - loss: 0.6620\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 30 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6497\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 31 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6572\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 32 ===\n",
      "Epoch 1/1\n",
      " 16/100 [===>..........................] - ETA: 10s - loss: 0.6522100/100 [==============================] - 12s 120ms/step - loss: 0.6459\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 33 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6512\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 34 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6588\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 35 ===\n",
      "Epoch 1/1\n",
      " 12/100 [==>...........................] - ETA: 10s - loss: 0.6479100/100 [==============================] - 12s 119ms/step - loss: 0.6502\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 36 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6519\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 37 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6532\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 38 ===\n",
      "Epoch 1/1\n",
      " 12/100 [==>...........................] - ETA: 10s - loss: 0.6701100/100 [==============================] - 12s 120ms/step - loss: 0.6490\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 39 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6434\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 40 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6521\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 41 ===\n",
      "Epoch 1/1\n",
      " 12/100 [==>...........................] - ETA: 10s - loss: 0.6286100/100 [==============================] - 12s 119ms/step - loss: 0.6468\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 42 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6537\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 43 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6465\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 44 ===\n",
      "Epoch 1/1\n",
      "  5/100 [>.............................] - ETA: 11s - loss: 0.6344100/100 [==============================] - 12s 120ms/step - loss: 0.6448\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 45 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6442\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 46 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6416\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 47 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6574100/100 [==============================] - 12s 119ms/step - loss: 0.6524\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 48 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6499\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 49 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6423\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 50 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6371100/100 [==============================] - 12s 119ms/step - loss: 0.6330\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 51 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6510\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 52 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6387\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 53 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6585100/100 [==============================] - 12s 119ms/step - loss: 0.6364\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 54 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6467\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 55 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6418\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 56 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6511100/100 [==============================] - 12s 119ms/step - loss: 0.6537\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 57 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6421\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 58 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6468\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 59 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6585100/100 [==============================] - 12s 119ms/step - loss: 0.6376\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 60 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6396\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 61 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6345\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 62 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6418100/100 [==============================] - 12s 119ms/step - loss: 0.6364\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 63 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6465\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 64 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6391\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 65 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6453100/100 [==============================] - 12s 119ms/step - loss: 0.6446\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 66 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6369\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 67 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6387\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 68 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6410100/100 [==============================] - 12s 119ms/step - loss: 0.6533\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 69 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6433\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 70 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6328\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 71 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6396100/100 [==============================] - 12s 120ms/step - loss: 0.6441\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 72 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6246\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 73 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6439\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 74 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6478100/100 [==============================] - 12s 119ms/step - loss: 0.6393\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 75 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6407\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 76 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6303\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 77 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6385100/100 [==============================] - 12s 120ms/step - loss: 0.6256\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 78 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6430\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 79 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6328\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 80 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6403100/100 [==============================] - 12s 119ms/step - loss: 0.6362\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 81 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6349\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 82 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6291\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 83 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6180100/100 [==============================] - 12s 119ms/step - loss: 0.6284\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 84 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6352\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 85 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6364\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 86 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6016100/100 [==============================] - 12s 119ms/step - loss: 0.6253\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 87 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6338\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 88 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6461\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 89 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6352\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 90 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6258\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 91 ===\n",
      "Epoch 1/1\n",
      " 68/100 [===================>..........] - ETA: 3s - loss: 0.6258100/100 [==============================] - 12s 120ms/step - loss: 0.6246\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 92 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6367\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 93 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6382\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 94 ===\n",
      "Epoch 1/1\n",
      " 16/100 [===>..........................] - ETA: 10s - loss: 0.6165100/100 [==============================] - 12s 120ms/step - loss: 0.6268\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 95 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6307\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 96 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6285\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 97 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/100 [==>...........................] - ETA: 10s - loss: 0.6172100/100 [==============================] - 12s 119ms/step - loss: 0.6320\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 98 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6283\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 99 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6291\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 100 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6016100/100 [==============================] - 12s 119ms/step - loss: 0.6350\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 101 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6276\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 102 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6302\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 103 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6098100/100 [==============================] - 12s 119ms/step - loss: 0.6246\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 104 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6447\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 105 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6327\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 106 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6275\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 107 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6290\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 108 ===\n",
      "Epoch 1/1\n",
      " 41/100 [===========>..................] - ETA: 7s - loss: 0.6326100/100 [==============================] - 12s 119ms/step - loss: 0.6354\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 109 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6356\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 110 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6333\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 111 ===\n",
      "Epoch 1/1\n",
      " 13/100 [==>...........................] - ETA: 10s - loss: 0.6161100/100 [==============================] - 12s 120ms/step - loss: 0.6282\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 112 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6391\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 113 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6296\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 114 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6279100/100 [==============================] - 12s 120ms/step - loss: 0.6315\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 115 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6233\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 116 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6256\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 117 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6350100/100 [==============================] - 12s 120ms/step - loss: 0.6286\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 118 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6320\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 119 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6312\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 120 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6441100/100 [==============================] - 12s 120ms/step - loss: 0.6252\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 121 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6223\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 122 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6321\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 123 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6132100/100 [==============================] - 12s 120ms/step - loss: 0.6270\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 124 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6251\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 125 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6260\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 126 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6236100/100 [==============================] - 12s 119ms/step - loss: 0.6375\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 127 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6326\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 128 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6130\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 129 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/100 [>.............................] - ETA: 11s - loss: 0.6019100/100 [==============================] - 12s 119ms/step - loss: 0.6196\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 130 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6240\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 131 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6213\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 132 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6238\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 133 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6214\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 134 ===\n",
      "Epoch 1/1\n",
      " 41/100 [===========>..................] - ETA: 7s - loss: 0.6351100/100 [==============================] - 12s 119ms/step - loss: 0.6279\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 135 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6321\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 136 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6182\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 137 ===\n",
      "Epoch 1/1\n",
      " 13/100 [==>...........................] - ETA: 10s - loss: 0.6393100/100 [==============================] - 12s 120ms/step - loss: 0.6284\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 138 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6253\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 139 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6228\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 140 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6172100/100 [==============================] - 12s 119ms/step - loss: 0.6263\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 141 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6296\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 142 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6282\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 143 ===\n",
      "Epoch 1/1\n",
      "  5/100 [>.............................] - ETA: 11s - loss: 0.6351100/100 [==============================] - 12s 119ms/step - loss: 0.6297\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 144 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6219\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 145 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6342\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 146 ===\n",
      "Epoch 1/1\n",
      " 10/100 [==>...........................] - ETA: 10s - loss: 0.6270100/100 [==============================] - 12s 119ms/step - loss: 0.6230\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 147 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6147\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 148 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6290\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 149 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6162100/100 [==============================] - 12s 119ms/step - loss: 0.6227\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 150 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6227\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 151 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6287\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 152 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6215100/100 [==============================] - 12s 120ms/step - loss: 0.6241\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 153 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6221\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 154 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6220\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 155 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6023100/100 [==============================] - 12s 120ms/step - loss: 0.6196\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 156 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6300\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 157 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6223\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 158 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6047100/100 [==============================] - 12s 119ms/step - loss: 0.6269\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 159 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6297\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 160 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6195\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 161 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.5989100/100 [==============================] - 12s 120ms/step - loss: 0.6128\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 162 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6244\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 163 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6179\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 164 ===\n",
      "Epoch 1/1\n",
      " 10/100 [==>...........................] - ETA: 10s - loss: 0.6229100/100 [==============================] - 12s 119ms/step - loss: 0.6293\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 165 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6146\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 166 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6225\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 167 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6026100/100 [==============================] - 12s 119ms/step - loss: 0.6231\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 168 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6130\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 169 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6200\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 170 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6141100/100 [==============================] - 12s 120ms/step - loss: 0.6249\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 171 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6222\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 172 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6334\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 173 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6133100/100 [==============================] - 12s 119ms/step - loss: 0.6116\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 174 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6187\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 175 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6196\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 176 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6320\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 177 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6075\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 178 ===\n",
      "Epoch 1/1\n",
      " 41/100 [===========>..................] - ETA: 7s - loss: 0.6180100/100 [==============================] - 12s 120ms/step - loss: 0.6272\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 179 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6194\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 180 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6281\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 181 ===\n",
      "Epoch 1/1\n",
      " 13/100 [==>...........................] - ETA: 10s - loss: 0.6243100/100 [==============================] - 12s 120ms/step - loss: 0.6144\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 182 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6250\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 183 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6250\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 184 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6343100/100 [==============================] - 12s 120ms/step - loss: 0.6207\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 185 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6218\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 186 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6243\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 187 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6286100/100 [==============================] - 12s 120ms/step - loss: 0.6216\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 188 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6225\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 189 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6208\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 190 ===\n",
      "Epoch 1/1\n",
      " 10/100 [==>...........................] - ETA: 10s - loss: 0.6052100/100 [==============================] - 12s 120ms/step - loss: 0.6218\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 191 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6363\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 192 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6268\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 193 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6174100/100 [==============================] - 12s 119ms/step - loss: 0.6182\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 194 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6243\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 195 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6150\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 196 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6023100/100 [==============================] - 12s 119ms/step - loss: 0.6119\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 197 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6203\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 198 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6270\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 199 ===\n",
      "Epoch 1/1\n",
      " 11/100 [==>...........................] - ETA: 10s - loss: 0.6084100/100 [==============================] - 12s 119ms/step - loss: 0.6226\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 200 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6134\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n"
     ]
    }
   ],
   "source": [
    "loops = 200\n",
    "best_acc = 0\n",
    "for i in range(loops):\n",
    "    print(\"=== Training loop {} ===\".format(i+1))\n",
    "    train(siamese_net, x_train_80)\n",
    "    test_acc = test_oneshot(siamese_net, x_train_20)\n",
    "    if test_acc >= best_acc:\n",
    "        print(\"New best one-shot accuracy, saving model ...\")\n",
    "        #siamese_net.save(os.path.join(\"models\", \"siamese_omniglot.h5\"))\n",
    "        best_acc = test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaivGyk_AVTY"
   },
   "source": [
    "***\n",
    "\n",
    "**b)** Briefly motivate your model's architecture, as well as its performance. What accuracy would random guessing achieve (on average)?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQVd8vHrAYEX"
   },
   "source": [
    "*=== write your answer here ===*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COiAqXWDAgCe"
   },
   "source": [
    "***\n",
    "\n",
    "**c)** Compare the performance of your Siamese network for Cifar-100 to the Siamese network from Practical 4 for Omniglot. Name three fundamental differences between the Cifar-100 and Omniglot datasets. How do these differences influence the difference in one-shot accuracy?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIHkoQ0PBWuB"
   },
   "source": [
    "*=== write your answer here ===*\n",
    "\n",
    "***1: Type of images: greyscale shapes (one shape = one meaning) vs. versatile RGB images (various shapes can mean same thing). 2: Omniglot has fewer examples per class than Cifar-100. 3: Omniglot has way more classes than Cifar-100.\n",
    "The first difference outweighs the other two, making one-shot learning on Cifar-100 much harder.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWpFF_5-Bf4B"
   },
   "source": [
    "***\n",
    "\n",
    "### Task 1.2: One-shot learning with neural codes\n",
    "**a)**\n",
    "* Train a CNN classifier on the first 80 classes of Cifar-100. Make sure it achieves at least 40% classification accuracy on those 80 classes (use the test set to validate this accuracy).\n",
    "* Then use neural codes from one of the later hidden layers of the CNN with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DbQfN8KOFOFH"
   },
   "outputs": [],
   "source": [
    "# reshape data for training classifier\n",
    "x_train_80 = x_train_80.reshape(-1, img_rows, img_cols, chns)\n",
    "x_test_80 = x_test_80.reshape(-1, img_rows, img_cols, chns)\n",
    "\n",
    "# transform 80 labels to one-hot\n",
    "y_train_80 = to_categorical(y_train_80)\n",
    "y_test_80 = to_categorical(y_test_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 538,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1521033469245,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "4k5yfAqoqHL2",
    "outputId": "d7fdb3d0-27e9-47b6-e409-8fc21bb57cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "neural_codes (Dense)         (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 80)                10320     \n",
      "=================================================================\n",
      "Total params: 1,636,368\n",
      "Trainable params: 1,635,920\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cnn architecture\n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu', name=\"neural_codes\"))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(80, activation='softmax'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 706,
     "output_extras": [
      {
       "item_id": 114
      },
      {
       "item_id": 211
      },
      {
       "item_id": 320
      },
      {
       "item_id": 426
      },
      {
       "item_id": 529
      },
      {
       "item_id": 633
      },
      {
       "item_id": 737
      },
      {
       "item_id": 874
      },
      {
       "item_id": 986
      },
      {
       "item_id": 992
      },
      {
       "item_id": 993
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 266347,
     "status": "ok",
     "timestamp": 1521033741234,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "zDRBMA5YniHW",
    "outputId": "ab6bb1a1-04c8-4e80-ec21-28d94ed19d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 14s 349us/step - loss: 3.8909 - acc: 0.1201\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 13s 330us/step - loss: 3.2270 - acc: 0.2146\n",
      "Epoch 3/20\n",
      "24500/40000 [=================>............] - ETA: 5s - loss: 2.9487 - acc: 0.262940000/40000 [==============================] - 13s 328us/step - loss: 2.9193 - acc: 0.2691\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 13s 332us/step - loss: 2.7035 - acc: 0.3135\n",
      "Epoch 5/20\n",
      "34300/40000 [========================>.....] - ETA: 1s - loss: 2.5532 - acc: 0.342640000/40000 [==============================] - 13s 331us/step - loss: 2.5579 - acc: 0.3418\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 13s 331us/step - loss: 2.4335 - acc: 0.3677\n",
      "Epoch 7/20\n",
      "38300/40000 [===========================>..] - ETA: 0s - loss: 2.3449 - acc: 0.383640000/40000 [==============================] - 13s 329us/step - loss: 2.3481 - acc: 0.3834\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 13s 331us/step - loss: 2.2839 - acc: 0.4001\n",
      "Epoch 9/20\n",
      "39500/40000 [============================>.] - ETA: 0s - loss: 2.2235 - acc: 0.410640000/40000 [==============================] - 13s 332us/step - loss: 2.2239 - acc: 0.4103\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 13s 331us/step - loss: 2.1589 - acc: 0.4238\n",
      "Epoch 11/20\n",
      "39100/40000 [============================>.] - ETA: 0s - loss: 2.1108 - acc: 0.434340000/40000 [==============================] - 13s 332us/step - loss: 2.1110 - acc: 0.4343\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 13s 332us/step - loss: 2.0754 - acc: 0.4456\n",
      "Epoch 13/20\n",
      "39300/40000 [============================>.] - ETA: 0s - loss: 2.0421 - acc: 0.448640000/40000 [==============================] - 13s 331us/step - loss: 2.0413 - acc: 0.4487\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 13s 330us/step - loss: 1.9982 - acc: 0.4597\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 13s 330us/step - loss: 1.9669 - acc: 0.4675\n",
      "Epoch 16/20\n",
      "  100/40000 [..............................] - ETA: 12s - loss: 2.1636 - acc: 0.410040000/40000 [==============================] - 13s 329us/step - loss: 1.9284 - acc: 0.4777\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 13s 331us/step - loss: 1.8982 - acc: 0.4778\n",
      "Epoch 18/20\n",
      "27100/40000 [===================>..........] - ETA: 4s - loss: 1.8534 - acc: 0.490540000/40000 [==============================] - 13s 327us/step - loss: 1.8815 - acc: 0.4843\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 13s 329us/step - loss: 1.8437 - acc: 0.4939\n",
      "Epoch 20/20\n",
      "36100/40000 [==========================>...] - ETA: 1s - loss: 1.8250 - acc: 0.497940000/40000 [==============================] - 13s 328us/step - loss: 1.8221 - acc: 0.4982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad72fa2e10>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "cnn.fit(x_train_80, y_train_80,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2023,
     "status": "ok",
     "timestamp": 1521033774616,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "JsMOdun6pukv",
    "outputId": "eacad9aa-11c7-4557-fa3c-eca5c4f8d440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.139175796866417\n",
      "Test accuracy: 0.44375\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn.evaluate(x_test_80, y_test_80, verbose=0)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Y8ahHDkgrZlm"
   },
   "outputs": [],
   "source": [
    "cnn_nc = Model(inputs=cnn.input, outputs=cnn.get_layer(\"neural_codes\").output)\n",
    "\n",
    "def test_oneshot_nc(model_nc, X, N=20, k=250, verbose=True):\n",
    "    \"\"\"Test average N-way oneshot learning accuracy for L2-distance between neural codes over k one-shot tasks.\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N, X)\n",
    "        # this part of the code is new:\n",
    "        test_image = inputs[0]\n",
    "        support_set = inputs[1]\n",
    "        test_image_nc = model_nc.predict(test_image)\n",
    "        support_set_nc = model_nc.predict(support_set)\n",
    "        mse = np.mean((test_image_nc - support_set_nc)**2, axis=1)  # mean squared error is proportional to L2 distance\n",
    "        # back to the old code:\n",
    "        if np.argmin(mse) == np.argmax(targets):\n",
    "            n_correct += 1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "output_extras": [
      {
       "item_id": 2
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3048,
     "status": "ok",
     "timestamp": 1521041806094,
     "user": {
      "displayName": "Loek Tonnaer",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113849499377556963886"
     },
     "user_tz": -60
    },
    "id": "unVXLO4TJ6HC",
    "outputId": "87b01e1b-2fd4-4171-d8ca-1396634b49ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.8% accuracy for 20-way one-shot learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.8"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_oneshot_nc(cnn_nc, x_test_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1BDzdPAz26B"
   },
   "source": [
    "***\n",
    "\n",
    "**b)** Briefly motivate your CNN architecture, and discuss the difference in one-shot accuracy between the Siamese network approach and the CNN neural codes approach.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRpVm956FR8P"
   },
   "source": [
    "*=== write your answer here ===*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Assignment 3 question 1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
