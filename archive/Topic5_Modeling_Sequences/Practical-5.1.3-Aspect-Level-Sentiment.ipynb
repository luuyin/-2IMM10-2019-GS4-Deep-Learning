{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0VnIJhDRpvc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_path = 'data/aspect_level-sentiment/aspect_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = 'data/doc_level-sentiment/doc_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gl50euzvDcQP",
    "outputId": "54082e09-e6db-4178-e8b2-b8b86a0f51a1"
   },
   "source": [
    "### Reading preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(data_path, file_name):\n",
    "\n",
    "    f = open(os.path.join(data_path, file_name), 'rb')\n",
    "    read_file = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return read_file\n",
    "\n",
    "def save_pickle(data_path, file_name, data):\n",
    "\n",
    "    f = open(os.path.join(data_path, file_name), 'wb')\n",
    "    cPickle.dump(data, f)\n",
    "    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n",
    "\n",
    "train_x = read_pickle(aspect_path, 'train_x.pkl')\n",
    "train_y = read_pickle(aspect_path, 'train_y.pkl')\n",
    "dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n",
    "dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n",
    "test_x = read_pickle(aspect_path, 'test_x.pkl')\n",
    "test_y = read_pickle(aspect_path, 'test_y.pkl')\n",
    "\n",
    "train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n",
    "dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n",
    "test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n",
    "\n",
    "\n",
    "pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n",
    "pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch generator and data iterator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataiterator():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, aspect_data, doc_data, seq_length=32, decoder_dim=300, batch_size=32):\n",
    "        \n",
    "        len_aspect_data = len(aspect_data[0])\n",
    "        len_doc_data = len(doc_data[0])\n",
    "        \n",
    "        self.X_aspect = aspect_data[0] \n",
    "        self.y_aspect = aspect_data[1]\n",
    "        self.aspect_terms = aspect_data[2]\n",
    "        \n",
    "        self.X_doc = doc_data[0]\n",
    "        self.y_doc = doc_data[1]\n",
    "        \n",
    "        self.num_data = len_aspect_data\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        \n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "                \n",
    "        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n",
    "        batch_X_doc = self.X_doc[np.array(X_ids)]\n",
    "        batch_y_doc = self.y_doc[np.array(X_ids)]\n",
    "        \n",
    "        \n",
    "        return batch_X_aspect, batch_y_aspect, batch_aspect_terms, batch_X_doc, batch_y_doc\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X_aspect, self.y_aspect, self.aspect_terms, self.X_doc, self.y_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sklA6jSUWDS6"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDU0hXVJ1PR5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM\n",
    "from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pvg-Uf2h_6Qm"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dnbn0_O0XlGf"
   },
   "source": [
    "### Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overal_maxlen = 82\n",
    "overal_maxlen_aspect = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjiAsayW1zx9"
   },
   "outputs": [],
   "source": [
    "def custom_softmax(x, axis=1):\n",
    "            \"\"\"Softmax activation function.\n",
    "            # Arguments\n",
    "                x : Tensor.\n",
    "                axis: Integer, axis along which the softmax normalization is applied.\n",
    "            # Returns\n",
    "                Tensor, output of softmax transformation.\n",
    "            # Raises\n",
    "                ValueError: In case `dim(x) == 1`.\n",
    "            \"\"\"\n",
    "            ndim = K.ndim(x)\n",
    "            if ndim == 2:\n",
    "                return K.softmax(x)\n",
    "            elif ndim > 2:\n",
    "                e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "                s = K.sum(e, axis=axis, keepdims=True)\n",
    "                return e / s\n",
    "            else:\n",
    "                raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bp5xh27GXmva"
   },
   "outputs": [],
   "source": [
    "repeator = RepeatVector(overal_maxlen, name='repeator_att')\n",
    "concatenator = Concatenate(axis=-1, name='concator_att')\n",
    "densor1 = Dense(300, activation = \"tanh\", name='densor1_att')\n",
    "densor2 = Dense(1, activation = \"relu\", name='densor2_att')\n",
    "activator = Activation(custom_softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1, name='dotor_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VH3g4z6R8O3_"
   },
   "outputs": [],
   "source": [
    "def attention(keys, query):\n",
    "    \n",
    "    query = repeator(query)\n",
    "    print(\"query shape: %s\" %str(query._keras_shape))\n",
    "    concat = concatenator([keys, query])\n",
    "    print(\"concat shape: %s\" %str(concat._keras_shape))\n",
    "    e1 = densor1(concat)\n",
    "    print(\"e1 shape: %s\" %str(e1._keras_shape))\n",
    "    e2 = densor2(e1)\n",
    "    print(\"e2 shape: %s\" %str(e2._keras_shape))\n",
    "    alphas = activator(e2)\n",
    "    print(\"alphas shape: %s\" %str(alphas._keras_shape))\n",
    "    context = dotor([alphas, keys])\n",
    "    print(\"context shape: %s\" %str(context._keras_shape))\n",
    "    \n",
    "    return context, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gVmvIn0X_0Ji"
   },
   "outputs": [],
   "source": [
    "class Average(Layer):\n",
    "  \n",
    "    def __init__(self, mask_zero=True, **kwargs):\n",
    "        self.mask_zero = mask_zero\n",
    "        self.supports_masking = True\n",
    "        super(Average, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.mask_zero:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            x = x * mask\n",
    "            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n",
    "        else:\n",
    "            return K.mean(x, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def compute_mask(self, x, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsyFHokczuvO"
   },
   "source": [
    "### Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5     \n",
    "recurrent_dropout = 0.1\n",
    "vocab_size = len(vocab)\n",
    "num_outputs = 3 # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs: How many inputs do you need for the current task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Inputs #####\n",
    "sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')\n",
    "aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input')\n",
    "pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-level embedding (shareable between all model inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### construct word embedding layer #####\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect-level representation (averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use average term embs as aspect embedding\n",
      "WARNING:tensorflow:From /home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "### represent aspect as averaged word embedding ###\n",
    "print ('use average term embs as aspect embedding')\n",
    "aspect_term_embs = word_emb(aspect_input)\n",
    "aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(300)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-level representation from two domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentence representation ###\n",
    "sentence_embs = word_emb(sentence_input) # from aspect-level domain\n",
    "pretrain_embs = word_emb(pretrain_input) # from document-level domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM layer (shared between three representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout, name='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "sentence_lstm = rnn(sentence_embs)\n",
    "pretrain_lstm = rnn(pretrain_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT REPLACE KEYS?, QUERY? WITH THE CORRESPONDING TENSORS AS ATTENTION KEYS AND QUERY\n",
    "\n",
    "#att_context, att_weights = attention(KEYS?, QUERY?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_avg = Average(mask_zero=True)(pretrain_lstm)\n",
    "\n",
    "sentence_output = Dense(num_outputs, name='dense_1')(att_context)\n",
    "pretrain_output = Dense(num_outputs, name='dense_2')(pretrain_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_output = Reshape((num_outputs,))(sentence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_probs = Activation('softmax', name='aspect_model')(sentence_output)\n",
    "doc_probs = Activation('softmax', name='pretrain_model')(pretrain_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "c6ptr7iuWIYT",
    "outputId": "71eb3b04-ed9a-40f5-8203-75d2cdcd5d6c"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[sentence_input, aspect_input, pretrain_input], outputs=[aspect_probs, doc_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmPSF8IAENj_"
   },
   "outputs": [],
   "source": [
    "import keras.optimizers as opt\n",
    "\n",
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "eiFkEy-eVtoU",
    "outputId": "8e611845-9951-4f35-bcba-a55103743742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_input (InputLayer)     (None, 82)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aspect_input (InputLayer)       (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n",
      "                                                                 sentence_input[0][0]             \n",
      "                                                                 pretrain_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     multiple             721200      word_emb[1][0]                   \n",
      "                                                                 word_emb[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeator_att (RepeatVector)     (None, 82, 300)      0           aspect_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concator_att (Concatenate)      (None, 82, 600)      0           lstm[0][0]                       \n",
      "                                                                 repeator_att[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "densor1_att (Dense)             (None, 82, 300)      180300      concator_att[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "densor2_att (Dense)             (None, 82, 1)        301         densor1_att[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pretrain_input (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 82, 1)        0           densor2_att[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dotor_att (Dot)                 (None, 1, 300)       0           attention_weights[0][0]          \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 3)         903         dotor_att[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 300)          0           lstm[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 3)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            903         average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspect_model (Activation)       (None, 3)            0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pretrain_model (Activation)     (None, 3)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,904,507\n",
      "Trainable params: 3,904,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaNcPdHiC650"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss={'aspect_model': 'categorical_crossentropy', 'pretrain_model': 'categorical_crossentropy'},\n",
    "              loss_weights = {'aspect_model': 1, 'pretrain_model': 0.1},\n",
    "              metrics = {'aspect_model': 'categorical_accuracy', 'pretrain_model': 'categorical_accuracy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilIKUGn_DEgB"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xi0coTFsDWFG"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5Y3_eO4QgyC3",
    "outputId": "c2d4489d-8fee-4f9e-eed6-74278c1c264e"
   },
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x)/batch_size\n",
    "batch_train_iter = Dataiterator([train_x, train_y, train_aspect], \\\n",
    "                                [pretrain_data, pretrain_label], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps_epoch = len(dev_x)/batch_size\n",
    "batch_val_iter = Dataiterator([dev_x, dev_y, dev_aspect], \\\n",
    "                              [pretrain_data, pretrain_label], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    \n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "    \n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n",
    "                             aspect, pretrain_X, pretrain_y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "                \n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n",
    "                           aspect, pretrain_X, pretrain_y in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "                \n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 20, callbacks = earlystop_callbacks)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      " 5/57 [=>............................] - ETA: 7:16 - loss: 1.2199 - aspect_model_loss: 1.1142 - pretrain_model_loss: 1.0571 - aspect_model_categorical_accuracy: 0.3750 - pretrain_model_categorical_accuracy: 0.7312"
     ]
    }
   ],
   "source": [
    "train_generator(model, batch_train_iter, batch_val_iter)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Aspect_Level_res_14.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
