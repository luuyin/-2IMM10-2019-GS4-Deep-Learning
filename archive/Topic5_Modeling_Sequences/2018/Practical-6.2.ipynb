{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngzXe64RN6F5"
   },
   "source": [
    "# Practical 6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnNfIFdmN6F6"
   },
   "source": [
    "# Word-level Sequence-to-Sequence (Seq2Seq) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application-1: Machine Translation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybtRWxLPN6F9"
   },
   "source": [
    "Similar architecture and objectives with Practical 6.2, but we will train the translation model on word sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92ZLnJI_N6F-"
   },
   "source": [
    "![Image](rnn_word_translation.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2745,
     "status": "ok",
     "timestamp": 1521389725552,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "2O-4rElr4cK7",
    "outputId": "bcfb2b2e-40b0-4938-c824-6b7d0881edef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Lambda, Bidirectional, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 904,
     "output_extras": [
      {
       "item_id": 42
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30116,
     "status": "ok",
     "timestamp": 1521389764661,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "ELUSmfBR5OeB",
    "outputId": "e6b928c9-eb2b-44f9-a2c2-61dc6b865c26"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7WbEHLFN6GJ"
   },
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9UFPwqfdN6GR"
   },
   "outputs": [],
   "source": [
    "file_to_read = 'nld.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzMjSUzhN6GV"
   },
   "source": [
    "Function to tokenize text into words (array list of words). Notice that we discard all punctuation in original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0-7xouvqN6GW"
   },
   "outputs": [],
   "source": [
    "def tokenizeWords(text):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    clean_text = regex.sub('', text)\n",
    "    tokens = clean_text.split()\n",
    "   \n",
    "       \n",
    "    return [t.lower() for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xczSbmW0N6Ga"
   },
   "outputs": [],
   "source": [
    "def indexingVocabulary(array_of_words):\n",
    "    \n",
    "    # frequency of word across document corpus\n",
    "    tf = nltk.FreqDist(array_of_words)\n",
    "    wordIndex = list(tf.keys())\n",
    "    \n",
    "    wordIndex.insert(0,'<pad>')\n",
    "    wordIndex.append('<start>')\n",
    "    wordIndex.append('<end>')\n",
    "    wordIndex.append('<unk>')\n",
    "    # indexing word vocabulary : pairs of (index,word)\n",
    "    vocab=dict([(i,wordIndex[i]) for i in range(len(wordIndex))])\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l5Tzs-dHN6Gd"
   },
   "outputs": [],
   "source": [
    "#reading text line by line\n",
    "lines = open(os.path.join(local_download_path,file_to_read)).read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nB5VEeGN6Gl"
   },
   "source": [
    "### Tokenization and vocabulary indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we only use 10.000 samples from data. Training a Seq2Seq model is computationally expensive (memory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SiHn1xC_N6Gn"
   },
   "outputs": [],
   "source": [
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "input_str_tokens = []\n",
    "target_str_tokens = []\n",
    "\n",
    "ind_start = 10000\n",
    "ind_end = 10000 + min(num_samples, len(lines) - 1)\n",
    "\n",
    "for line in lines[ind_start : ind_end]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # tokenize text from source language (english text)\n",
    "    input_str_tokens.append(tokenizeWords(input_text))\n",
    "    # tokenize text from target language (dutch text)\n",
    "    target_str_tokens.append(tokenizeWords(target_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXfCi3lNN6G2"
   },
   "source": [
    "* `en_vocab` stores word index for encoder input sequences (english dictionary)\n",
    "* `nl_vocab` stores word index for decoder target sequences (dutch dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VizWlhZrN6G4"
   },
   "outputs": [],
   "source": [
    "# build vocabulary index\n",
    "input_words = []\n",
    "target_words = []\n",
    "\n",
    "for i, tokens in enumerate(input_str_tokens):\n",
    "    input_words.extend(tokens)\n",
    "# vocabulary index for english text (input)    \n",
    "en_vocab = indexingVocabulary(input_words)\n",
    "\n",
    "for i, tokens in enumerate(target_str_tokens):\n",
    "    target_words.extend(tokens)\n",
    "# vocabulary index for dutch text (output)\n",
    "nl_vocab = indexingVocabulary(target_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whO4KxJtN6HU"
   },
   "source": [
    "We also need to create reverse version of look up index to map text sequences into integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SwHwMyH3N6HV"
   },
   "outputs": [],
   "source": [
    "en_reversedvocab = dict((v,k) for (k,v) in en_vocab.items())\n",
    "nl_reversedvocab = dict((v,k) for (k,v) in nl_vocab.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsgA_CwiN6Ht"
   },
   "source": [
    "### Preparing training sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "926aTUknN6Hu"
   },
   "source": [
    "\n",
    "* `seq_int_input`: input sequences for encoder model \n",
    "* `seq_int_target`: input sequences for decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eYvxhiglN6Hu"
   },
   "outputs": [],
   "source": [
    "# integer format of sequence input \n",
    "seq_int_input = []\n",
    "for i, text in enumerate(input_str_tokens):\n",
    "    int_tokens = [en_reversedvocab[i] for i in text]\n",
    "    seq_int_input.append(int_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGYmgn7IN6Hx"
   },
   "source": [
    "For input and output sequences of decoder model, we will use `starting` sign (`'<start>'`) and `ending` sign (`'<end>'`) at the beginning and last part of sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xnaM-sEFN6Hy"
   },
   "outputs": [],
   "source": [
    "seq_int_target = []\n",
    "for i, text in enumerate(target_str_tokens):\n",
    "    targettext = list(text)\n",
    "    targettext.insert(0,'<start>')\n",
    "    targettext.append('<end>')\n",
    "  \n",
    "    int_tokens = [nl_reversedvocab[i] for i in targettext]\n",
    "    seq_int_target.append(int_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpN-jcazN6IH"
   },
   "source": [
    "## 2. Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aODyKVzVN6IJ"
   },
   "source": [
    "* In character level, we define input and output sequences as one-hot vector in 3D numpy arrays (number of samples, sequence length, vocabulary size). \n",
    "* For word-level, we have integer input sequences with 2D shape (number of samples, sequence length). Instead of one-hot encoding words, we will use embedding layer to project each word sequence to its embedding.\n",
    "* We will train our text with Word2Vec - Skipgram to provide initial weight for our embedding layer (may also use pretrained word embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bacbSkfIN6IM"
   },
   "outputs": [],
   "source": [
    "# for english text\n",
    "# skipgram model with hierarchical softmax and negative sampling\n",
    "word2vec_model_en = Word2Vec(size=256, min_count=0, window=5, sg=1, \n",
    "                          hs=1, negative=5, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BuyBFPI5N6IO"
   },
   "outputs": [],
   "source": [
    "word2vec_model_en.build_vocab(input_str_tokens)\n",
    "word2vec_vocab_en = dict([(v.index,k) for k, v in word2vec_model_en.wv.vocab.items()]) \n",
    "revert_w2v_vocab_en = dict((v,k) for (k,v) in word2vec_vocab_en.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QhDgmZF2N6IS"
   },
   "outputs": [],
   "source": [
    "# for dutch text\n",
    "# skipgram model with hierarchical softmax and negative sampling\n",
    "word2vec_model_nl = Word2Vec(size=256, min_count=0, window=5, sg=1, \n",
    "                          hs=1, negative=5, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lWixcEyDN6IU"
   },
   "outputs": [],
   "source": [
    "word2vec_model_nl.build_vocab(target_str_tokens)\n",
    "word2vec_vocab_nl = dict([(v.index,k) for k, v in word2vec_model_nl.wv.vocab.items()]) \n",
    "revert_w2v_vocab_nl = dict((v,k) for (k,v) in word2vec_vocab_nl.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28817,
     "status": "ok",
     "timestamp": 1521390779728,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "JU7yeMwCN6IW",
    "outputId": "57057507-205e-4297-b57d-8bfecd11574e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2vec model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4257792, 5946200)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training word2vec model...')\n",
    "\n",
    "# for english text\n",
    "# number of tokens\n",
    "n_tokens = sum([len(seq) for seq in input_str_tokens])\n",
    "# number of sentences/documents\n",
    "n_examples = len(input_str_tokens)\n",
    "word2vec_model_en.train(input_str_tokens, total_words=n_tokens, \n",
    "                        total_examples=n_examples, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29543,
     "status": "ok",
     "timestamp": 1521390809301,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "0EVh-IbTN6Ia",
    "outputId": "ccb25a26-4f6e-4667-cc07-40b8ef8aa9df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4297470, 6123900)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for dutch text\n",
    "# number of tokens\n",
    "n_tokens = sum([len(seq) for seq in target_str_tokens])\n",
    "# number of sentences/documents\n",
    "n_examples = len(target_str_tokens)\n",
    "word2vec_model_nl.train(target_str_tokens, total_words=n_tokens, \n",
    "                        total_examples=n_examples, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7f2RwH1MN6Ic"
   },
   "source": [
    "The following variables store our word embedding learnt from word2vec skipgram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1521390810207,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "aJJo_mWSN6Id",
    "outputId": "9412554c-e355-4baf-843b-7e68031c5a05"
   },
   "outputs": [],
   "source": [
    "# the resulting learnt word embedding \n",
    "# for input text sequence (english language)\n",
    "word2vec_we_en = word2vec_model_en.wv.syn0\n",
    "\n",
    "# for target text sequence (dutch language)\n",
    "word2vec_we_nl = word2vec_model_nl.wv.syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Toqk01MJN6If"
   },
   "source": [
    "Notice that vocabulary size of word embedding learnt by word2vec is less than our vocabulary size since we add additional word tokens: `'<pad>'`, `'<start>'`, `'<end>'`, `'<unk>'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1521390811389,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "mnKKsNZKN6Ig",
    "outputId": "d0e5a373-1376-4bf1-80e3-f175b0eca16f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4163, 256)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_we_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1521390812378,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "BUf5Jnq4N6Il",
    "outputId": "cf316a68-a011-4cb7-cdaf-834217ff428d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5280, 256)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_we_nl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fMv4Xq0VN6Ip"
   },
   "outputs": [],
   "source": [
    "embedding_en = np.zeros(shape=(len(en_vocab), 256), dtype='float32')\n",
    "embedding_nl = np.zeros(shape=(len(nl_vocab), 256), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1521390859828,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "04N_q8Dk9hjB",
    "outputId": "8898d131-b5df-44c1-9acb-8bd69ded0cad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4167, 256)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1521390872846,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "v2v5ANNN9joH",
    "outputId": "07df4836-50df-40c2-bc70-6ecfb6f20900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5284, 256)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_nl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2EQGsbAoN6Ix"
   },
   "outputs": [],
   "source": [
    "# for input sequences (text in english language)\n",
    "for i, w in en_vocab.items():\n",
    "    # this will assign default weight 0 for words: 'SOF', 'EOF', and 'UNK'\n",
    "    if w not in word2vec_vocab_en.values():\n",
    "        continue\n",
    "    embedding_en[i, :] = word2vec_we_en[revert_w2v_vocab_en[w], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gOb07ivBN6I1"
   },
   "outputs": [],
   "source": [
    "# for target output sequences (text in dutch language)\n",
    "for i, w in nl_vocab.items():\n",
    "    # this will assign default weight 0 for words: 'SOF', 'EOF', and 'UNK'\n",
    "    if w not in word2vec_vocab_nl.values():\n",
    "        continue\n",
    "    embedding_nl[i, :] = word2vec_we_nl[revert_w2v_vocab_nl[w], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNemFSnlN6JA"
   },
   "source": [
    "## 3. Word-based Translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZYcBt8liN6JC"
   },
   "outputs": [],
   "source": [
    "batch_size = 100  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "rnn_dim = 256  # Latent dimensionality of the encoding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-Ehpl88N6JH"
   },
   "source": [
    "## 3.1. Encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this model, set parameters in embedding layer to be trainable. \n",
    "* You may also try using empty embedding layer (without initialization from pretrained Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2Q64pDyQN6JJ"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8bEpzhh0N6JR"
   },
   "source": [
    "## 3.2. Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q0mXDNNeN6JT"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "acJ7avYwN6JV"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], prediction_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kL7yo8VvN6Ja"
   },
   "outputs": [],
   "source": [
    "# Compile & run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1521391326894,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "WHcbEdSSN6Jc",
    "outputId": "18f959f8-6a85-4c52-ec9a-ba08b4474f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_encoder (Embedding)   (None, None, 256)    1066752     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_decoder (Embedding)   (None, None, 256)    1352704     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_encoder (LSTM)             [(None, 256), (None, 525312      embedding_encoder[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lstm_decoder (LSTM)             [(None, None, 256),  525312      embedding_decoder[0][0]          \n",
      "                                                                 lstm_encoder[0][1]               \n",
      "                                                                 lstm_encoder[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer (Dense)        (None, None, 5284)   1357988     lstm_decoder[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,828,068\n",
      "Trainable params: 4,828,068\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gn5MJtl0N6Ji"
   },
   "source": [
    "## Training translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jm36l64oN6Jk"
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(sequences) for sequences in seq_int_input])\n",
    "max_decoder_seq_length = max([len(sequences) for sequences in seq_int_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yZWApsisN6J4"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(seq_int_input), max_encoder_seq_length), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uOGVMSRMN6J6"
   },
   "outputs": [],
   "source": [
    "decoder_input_data = np.zeros((len(seq_int_input), max_decoder_seq_length), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "Be aware that the output of decoder layer need to be in categorical format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBgRBSA9N6KO"
   },
   "source": [
    "### Padding input sequences for encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wUcWaLrMN6KP"
   },
   "outputs": [],
   "source": [
    "for i, seq_int in enumerate(seq_int_input):\n",
    "    for j, word_index in enumerate(seq_int):\n",
    "        encoder_input_data[i][j] = word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cxlPa5HDN6KW"
   },
   "outputs": [],
   "source": [
    "for i, seq_int in enumerate(seq_int_target):\n",
    "    for j, word_index in enumerate(seq_int):\n",
    "        decoder_input_data[i][j] = word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sk7hm_dxN6Kz"
   },
   "source": [
    "### Fitting sequences into model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJnUjLcWN6K0"
   },
   "source": [
    "### Important\n",
    "\n",
    "Note: creating 3D numpy arrays of decoder output (one-hot-encoding) might cause Memory Error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VR_VagKGN6K0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1521393626062,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "Wr_eRbh8N6K9",
    "outputId": "5428d760-dd67-4297-96ac-325b2619bc41"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('rnn_word_lstm_translation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ckMgNp76A1lI"
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights_rnn_word_lstm_translation.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WH-NaPoN6LA"
   },
   "source": [
    "## 4. Inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOZBaLw7N6LB"
   },
   "source": [
    "## 4.1. Re-define encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "P9SADoo0N6LF"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ShxnKd8FN6LH"
   },
   "outputs": [],
   "source": [
    "encoder_model.save('encoder_word_lstm_translation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MslR012dN6LK"
   },
   "source": [
    "## 4.2. Re-define decoder model to do the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "b-eWKM1FN6LL"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1521393806179,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "kW9utIPPN6LO",
    "outputId": "5b591812-5228-45b4-cf19-b8944ffdb3e9"
   },
   "outputs": [],
   "source": [
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "decoder_model.save(os.path.join('decoder_word_lstm_translation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Euy5qm56N6LR"
   },
   "source": [
    "## 4.3. Translate sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-word-translation.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
