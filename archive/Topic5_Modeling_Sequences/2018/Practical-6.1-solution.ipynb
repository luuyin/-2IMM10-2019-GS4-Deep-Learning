{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Sequence-to-Sequence (Seq2Seq) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvOOr-HbNCb8"
   },
   "source": [
    "# Application-1: Machine Translation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5AUsniPyNCcF"
   },
   "source": [
    "We will create a translation model with Recurrent Neural Networks (RNN) by using character sequences as the input of model. \n",
    "For building this model, we will need 2 sub models:\n",
    "* Encoder model: encode text input from source language (English) to a \"Neural codes\" \n",
    "* Decoder model: predict text in target language (Dutch), given the encoding state from encoder model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m98ZVEQMNCcH"
   },
   "source": [
    "![Image](rnn_char_translation.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "[1] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"Sequence to sequence learning with neural networks.\" Advances in neural information processing systems. 2014.\n",
    "\n",
    "[2] Cho, Kyunghyun, et al. \"Learning phrase representations using RNN encoder-decoder for statistical machine translation.\" arXiv preprint arXiv:1406.1078 (2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_2k4vJqNCcJ"
   },
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2763,
     "status": "ok",
     "timestamp": 1521385235006,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "yCpdp1UpOLfm",
    "outputId": "866dcca0-6b6a-410b-b601-5c2f954ae66e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Lambda, Bidirectional, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9otvuTNgNCci"
   },
   "source": [
    "Data set is originally from http://www.manythings.org/anki/.\n",
    "\n",
    "We will use bilingual sentence pairs of English - Dutch, provided here: https://storage.googleapis.com/trl_data/nld.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sriD2fCJNCcn"
   },
   "outputs": [],
   "source": [
    "file_to_read = 'nld.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zmRZyNrNCcr"
   },
   "source": [
    "Example of original format of text for training the model:\n",
    "\n",
    "```\n",
    "Hi.\tHoi.\n",
    "Run!\tRen!\n",
    "Who?\tWie?\n",
    "Wow!\tDa's niet gek!\n",
    "Fire!\tVuur!\n",
    "Fire!\tBrand!\n",
    "Help!\tHelp!\n",
    "Jump.\tSpring.\n",
    "Stop!\tStop!\n",
    "Stop!\tHalt!\n",
    "Hello!\tHallo.\n",
    "Hello!\tGoedemorgen!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aO1WmXfNCct"
   },
   "source": [
    "We will feed two (2) type of inputs for this model.\n",
    "\n",
    "* `input_texts` : input sequences for encoder model (English text)\n",
    "* `target_texts` : input sequences for decoder model (Dutch text)\n",
    "\n",
    "We also need two (2) look up dictionaries:\n",
    "\n",
    "* `input_characters` : dictionary index for encoder model\n",
    "* `target_characters` : dictionary index for decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dk06IHPNNCcu"
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zdZe7YgzNCcy"
   },
   "outputs": [],
   "source": [
    "#reading text line by line\n",
    "lines = open(file_to_read).read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9iyulkcNCdC"
   },
   "source": [
    "We only use 10000 samples (lines) from original text to train the model. \n",
    "\n",
    "* Notice that for `target_texts`, we add character `'\\t'` at the beginning of text and character `'\\n'` at the end of text sequences. \n",
    "\n",
    "Why do we need to add these two characters? \n",
    "\n",
    "The prediction layer in our RNN model need to predict one time step ahead when learn character in current time step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4wrvMtKzNCdD"
   },
   "outputs": [],
   "source": [
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    \n",
    "    english_text, dutch_text = line.split('\\t')\n",
    "    \n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + dutch_text + '\\n'\n",
    "    \n",
    "    input_texts.append(english_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    for char in english_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p_JLH_3sNCdG"
   },
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1521385262346,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "3sKrALVKNCdK",
    "outputId": "a5b76f22-5661-4732-a473-e9e9224c7793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of characters in input sequences\n",
    "len(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1521385266197,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "-FP3K4ecNCdV",
    "outputId": "ad685eef-5de4-4b3d-bd6f-6045aed80913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of characters in target sequences\n",
    "len(target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFpDRsSsNCdc"
   },
   "source": [
    "Notice that in this example we treat `uppercase` and `lowercase` characters as different characters even if they point to the same character. \n",
    "\n",
    "For instance, character `'W'` and `'w'` will be treated as 2 different characters in our input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Tw-IuV4xNCde"
   },
   "outputs": [],
   "source": [
    "#text in source language (english) as input of model\n",
    "input_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o1kk0d4FNCdk"
   },
   "outputs": [],
   "source": [
    "#text in target language (dutch) as input of model\n",
    "target_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RF5FTD2NCdq"
   },
   "source": [
    "### Look up index for encoder and decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hL6hWqzWNCds"
   },
   "source": [
    "* `enc_index_char` stores character index for input sequences (encoder model)\n",
    "* `dec_index_char` stores character index for target sequences (decoder model)\n",
    "\n",
    "You may also use one look-up index for both sub-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rMxekSN1NCdt"
   },
   "outputs": [],
   "source": [
    "#dictionary index (character-level) for model input\n",
    "enc_index_char = dict([(i, char) for i, char in enumerate(input_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0l23noLHNCdz"
   },
   "outputs": [],
   "source": [
    "#dictionary index (character-level) for target output\n",
    "dec_index_char = dict([(i, char) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcbOgH93NCeb"
   },
   "source": [
    "We also need to create reversed version of character-index dictionary to map text sequences into integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aLs9MIJpNCed"
   },
   "outputs": [],
   "source": [
    "enc_char_index = dict((char,i) for i, char in enc_index_char.items())\n",
    "dec_char_index = dict((char,i) for i, char in dec_index_char.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0gTW-3mONCei"
   },
   "outputs": [],
   "source": [
    "list(reverse_input_char_index.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "79kzrU5ONCet"
   },
   "outputs": [],
   "source": [
    "list(reverse_target_char_index.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgqCUHDRNCfB"
   },
   "source": [
    "### Preparing training sequences (one-hot vector format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H4-zILbqNCfD"
   },
   "outputs": [],
   "source": [
    "#number of unique character as model input\n",
    "num_encoder_tokens = len(input_characters)\n",
    "\n",
    "#number of unique character as target output\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "#maximum sequence length for encoder\n",
    "#based on maximum length of input text \n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "\n",
    "#maximum sequence length for decoder\n",
    "#based on maximum length of output text \n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O8qi-lyQNCff"
   },
   "source": [
    "* Notice that input and output sequences for our encoder and decoder models are matrices with 3D dimension size (number of samples, sequence length, vocabulary size). \n",
    "\n",
    "We will feed sequences as one-hot vector encoding, which represents the occurrence of character in corresponding sequence. The matrix will have value `1` at `i-th` `char_index` of current character.\n",
    "\n",
    "* Notice that this one-hot encoding step is interchangeble with Lambda layer in Practical 5.2 and 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OO6ZU4lwNCff"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "                              dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gG42tNGxNCfi"
   },
   "outputs": [],
   "source": [
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "                              dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FV2IuSFRNCfj"
   },
   "outputs": [],
   "source": [
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "                               dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oSNvjk0jNCfr"
   },
   "outputs": [],
   "source": [
    "text_pair = zip(input_texts, target_texts)\n",
    "for i, (input_text, target_text) in enumerate(text_pair):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, reverse_input_char_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, reverse_target_char_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "             decoder_target_data[i, t - 1, reverse_target_char_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REo2nDwJNCge"
   },
   "source": [
    "## 2. Translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uVMDLQ-HNCgg"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 200  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obpREcZKNCgj"
   },
   "source": [
    "## 2.a. Encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwSMknX_NCgk"
   },
   "source": [
    "We will use hidden state `h` and memory state `c` from recurrent layer of encoderas additional input of decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sDSphAUFNCgk"
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder-input')\n",
    "encoder = LSTM(latent_dim, name='lstm-encoder', return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3ugGn5iNCgm"
   },
   "source": [
    "## 2.b. Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9E6Npi2NCgm"
   },
   "source": [
    "* Set up the decoder, using `encoder_states` as initial state.\n",
    "* We won't use decoder states in training stage, but we will use them in inference stage later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kg8yd_30NCgm"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder-input')\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, name='lstm-decoder', return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='prediction-layer')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfh7yINKNCgp"
   },
   "source": [
    "## Encoder - Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ujo76D4BNCgr"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DkNi8G1kNCgx"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 340,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1521385350352,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "zC3Y_w7rNCg0",
    "outputId": "a64b7777-6fd8-4de7-eff9-b0192ab0cf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder-input (InputLayer)      (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder-input (InputLayer)      (None, None, 78)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm-encoder (LSTM)             [(None, 256), (None, 335872      encoder-input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm-decoder (LSTM)             [(None, None, 256),  343040      decoder-input[0][0]              \n",
      "                                                                 lstm-encoder[0][1]               \n",
      "                                                                 lstm-encoder[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "prediction-layer (Dense)        (None, None, 78)     20046       lstm-decoder[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 698,958\n",
      "Trainable params: 698,958\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztIS40DwNCg2"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 6871,
     "output_extras": [
      {
       "item_id": 200
      },
      {
       "item_id": 418
      },
      {
       "item_id": 611
      },
      {
       "item_id": 797
      },
      {
       "item_id": 984
      },
      {
       "item_id": 1171
      },
      {
       "item_id": 1358
      },
      {
       "item_id": 1544
      },
      {
       "item_id": 1730
      },
      {
       "item_id": 1914
      },
      {
       "item_id": 2097
      },
      {
       "item_id": 2281
      },
      {
       "item_id": 2464
      },
      {
       "item_id": 2646
      },
      {
       "item_id": 2826
      },
      {
       "item_id": 3006
      },
      {
       "item_id": 3186
      },
      {
       "item_id": 3360
      },
      {
       "item_id": 3537
      },
      {
       "item_id": 3715
      },
      {
       "item_id": 3890
      },
      {
       "item_id": 4066
      },
      {
       "item_id": 4242
      },
      {
       "item_id": 4416
      },
      {
       "item_id": 4591
      },
      {
       "item_id": 4764
      },
      {
       "item_id": 4936
      },
      {
       "item_id": 5109
      },
      {
       "item_id": 5280
      },
      {
       "item_id": 5451
      },
      {
       "item_id": 5621
      },
      {
       "item_id": 5790
      },
      {
       "item_id": 5959
      },
      {
       "item_id": 6126
      },
      {
       "item_id": 6293
      },
      {
       "item_id": 6461
      },
      {
       "item_id": 6627
      },
      {
       "item_id": 6794
      },
      {
       "item_id": 6959
      },
      {
       "item_id": 7124
      },
      {
       "item_id": 7286
      },
      {
       "item_id": 7451
      },
      {
       "item_id": 7615
      },
      {
       "item_id": 7778
      },
      {
       "item_id": 7938
      },
      {
       "item_id": 8100
      },
      {
       "item_id": 8261
      },
      {
       "item_id": 8421
      },
      {
       "item_id": 8581
      },
      {
       "item_id": 8741
      },
      {
       "item_id": 8901
      },
      {
       "item_id": 9061
      },
      {
       "item_id": 9220
      },
      {
       "item_id": 9377
      },
      {
       "item_id": 9533
      },
      {
       "item_id": 9687
      },
      {
       "item_id": 9843
      },
      {
       "item_id": 10000
      },
      {
       "item_id": 10156
      },
      {
       "item_id": 10312
      },
      {
       "item_id": 10466
      },
      {
       "item_id": 10621
      },
      {
       "item_id": 10775
      },
      {
       "item_id": 10928
      },
      {
       "item_id": 11082
      },
      {
       "item_id": 11236
      },
      {
       "item_id": 11294
      },
      {
       "item_id": 11295
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3357624,
     "status": "ok",
     "timestamp": 1521388712687,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "W8NW9P4GNCg2",
    "outputId": "20650dcc-e644-40b7-bfdd-7ca92a2699dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 1.1128 - val_loss: 1.2334\n",
      "Epoch 2/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.8864 - val_loss: 1.0471\n",
      "Epoch 3/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.7728 - val_loss: 0.9665\n",
      "Epoch 4/200\n",
      "1856/8000 [=====>........................] - ETA: 11s - loss: 0.73758000/8000 [==============================] - 17s 2ms/step - loss: 0.7186 - val_loss: 0.9256\n",
      "Epoch 5/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.6853 - val_loss: 0.8757\n",
      "Epoch 6/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.6510 - val_loss: 0.8403\n",
      "Epoch 7/200\n",
      "6336/8000 [======================>.......] - ETA: 3s - loss: 0.62828000/8000 [==============================] - 17s 2ms/step - loss: 0.6233 - val_loss: 0.8221\n",
      "Epoch 8/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5997 - val_loss: 0.7830\n",
      "Epoch 9/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5775 - val_loss: 0.7740\n",
      "Epoch 10/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.55938000/8000 [==============================] - 17s 2ms/step - loss: 0.5589 - val_loss: 0.7701\n",
      "Epoch 11/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5405 - val_loss: 0.7404\n",
      "Epoch 12/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5248 - val_loss: 0.7209\n",
      "Epoch 13/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.50848000/8000 [==============================] - 17s 2ms/step - loss: 0.5091 - val_loss: 0.7099\n",
      "Epoch 14/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4938 - val_loss: 0.6937\n",
      "Epoch 15/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4797 - val_loss: 0.7000\n",
      "Epoch 16/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.46728000/8000 [==============================] - 17s 2ms/step - loss: 0.4670 - val_loss: 0.6866\n",
      "Epoch 17/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4544 - val_loss: 0.6781\n",
      "Epoch 18/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4431 - val_loss: 0.6673\n",
      "Epoch 19/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.43268000/8000 [==============================] - 17s 2ms/step - loss: 0.4316 - val_loss: 0.6702\n",
      "Epoch 20/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4219 - val_loss: 0.6641\n",
      "Epoch 21/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4112 - val_loss: 0.6648\n",
      "Epoch 22/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.40208000/8000 [==============================] - 17s 2ms/step - loss: 0.4018 - val_loss: 0.6639\n",
      "Epoch 23/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3922 - val_loss: 0.6583\n",
      "Epoch 24/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3831 - val_loss: 0.6634\n",
      "Epoch 25/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.37568000/8000 [==============================] - 17s 2ms/step - loss: 0.3763 - val_loss: 0.6611\n",
      "Epoch 26/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3670 - val_loss: 0.6607\n",
      "Epoch 27/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3582 - val_loss: 0.6604\n",
      "Epoch 28/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.34938000/8000 [==============================] - 17s 2ms/step - loss: 0.3498 - val_loss: 0.6609\n",
      "Epoch 29/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3416 - val_loss: 0.6680\n",
      "Epoch 30/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3339 - val_loss: 0.6705\n",
      "Epoch 31/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.32528000/8000 [==============================] - 17s 2ms/step - loss: 0.3260 - val_loss: 0.6715\n",
      "Epoch 32/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3194 - val_loss: 0.6780\n",
      "Epoch 33/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3116 - val_loss: 0.6834\n",
      "Epoch 34/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.30488000/8000 [==============================] - 17s 2ms/step - loss: 0.3043 - val_loss: 0.6894\n",
      "Epoch 35/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2982 - val_loss: 0.6949\n",
      "Epoch 36/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2916 - val_loss: 0.6992\n",
      "Epoch 37/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.28578000/8000 [==============================] - 17s 2ms/step - loss: 0.2853 - val_loss: 0.7056\n",
      "Epoch 38/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2790 - val_loss: 0.7098\n",
      "Epoch 39/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2730 - val_loss: 0.7167\n",
      "Epoch 40/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.26708000/8000 [==============================] - 17s 2ms/step - loss: 0.2674 - val_loss: 0.7215\n",
      "Epoch 41/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2618 - val_loss: 0.7259\n",
      "Epoch 42/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2557 - val_loss: 0.7349\n",
      "Epoch 43/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.24968000/8000 [==============================] - 17s 2ms/step - loss: 0.2506 - val_loss: 0.7441\n",
      "Epoch 44/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2480 - val_loss: 0.7494\n",
      "Epoch 45/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2420 - val_loss: 0.7594\n",
      "Epoch 46/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.23588000/8000 [==============================] - 17s 2ms/step - loss: 0.2368 - val_loss: 0.7592\n",
      "Epoch 47/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2307 - val_loss: 0.7729\n",
      "Epoch 48/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2266 - val_loss: 0.7721\n",
      "Epoch 49/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.22138000/8000 [==============================] - 17s 2ms/step - loss: 0.2221 - val_loss: 0.7842\n",
      "Epoch 50/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2180 - val_loss: 0.7923\n",
      "Epoch 51/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2136 - val_loss: 0.7960\n",
      "Epoch 52/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.20888000/8000 [==============================] - 17s 2ms/step - loss: 0.2093 - val_loss: 0.8022\n",
      "Epoch 53/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2051 - val_loss: 0.8115\n",
      "Epoch 54/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2015 - val_loss: 0.8139\n",
      "Epoch 55/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.19728000/8000 [==============================] - 17s 2ms/step - loss: 0.1975 - val_loss: 0.8273\n",
      "Epoch 56/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1942 - val_loss: 0.8380\n",
      "Epoch 57/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1900 - val_loss: 0.8398\n",
      "Epoch 58/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.18618000/8000 [==============================] - 17s 2ms/step - loss: 0.1866 - val_loss: 0.8487\n",
      "Epoch 59/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1834 - val_loss: 0.8608\n",
      "Epoch 60/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1806 - val_loss: 0.8701\n",
      "Epoch 61/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.17708000/8000 [==============================] - 17s 2ms/step - loss: 0.1774 - val_loss: 0.8736\n",
      "Epoch 62/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1740 - val_loss: 0.8863\n",
      "Epoch 63/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1711 - val_loss: 0.8844\n",
      "Epoch 64/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.16788000/8000 [==============================] - 17s 2ms/step - loss: 0.1683 - val_loss: 0.8917\n",
      "Epoch 65/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1651 - val_loss: 0.9037\n",
      "Epoch 66/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1625 - val_loss: 0.9071\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.15858000/8000 [==============================] - 17s 2ms/step - loss: 0.1592 - val_loss: 0.9136\n",
      "Epoch 68/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1571 - val_loss: 0.9309\n",
      "Epoch 69/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1547 - val_loss: 0.9351\n",
      "Epoch 70/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.15108000/8000 [==============================] - 17s 2ms/step - loss: 0.1520 - val_loss: 0.9360\n",
      "Epoch 71/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1493 - val_loss: 0.9456\n",
      "Epoch 72/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1465 - val_loss: 0.9538\n",
      "Epoch 73/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.14618000/8000 [==============================] - 17s 2ms/step - loss: 0.1482 - val_loss: 0.9573\n",
      "Epoch 74/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1452 - val_loss: 0.9595\n",
      "Epoch 75/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1425 - val_loss: 0.9695\n",
      "Epoch 76/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.13918000/8000 [==============================] - 17s 2ms/step - loss: 0.1396 - val_loss: 0.9814\n",
      "Epoch 77/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1386 - val_loss: 0.9819\n",
      "Epoch 78/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1346 - val_loss: 0.9899\n",
      "Epoch 79/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.13168000/8000 [==============================] - 17s 2ms/step - loss: 0.1322 - val_loss: 1.0025\n",
      "Epoch 80/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1300 - val_loss: 1.0081\n",
      "Epoch 81/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1281 - val_loss: 1.0100\n",
      "Epoch 82/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.12558000/8000 [==============================] - 17s 2ms/step - loss: 0.1262 - val_loss: 1.0162\n",
      "Epoch 83/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1239 - val_loss: 1.0194\n",
      "Epoch 84/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1222 - val_loss: 1.0397\n",
      "Epoch 85/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.12098000/8000 [==============================] - 17s 2ms/step - loss: 0.1213 - val_loss: 1.0325\n",
      "Epoch 86/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1188 - val_loss: 1.0347\n",
      "Epoch 87/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1166 - val_loss: 1.0492\n",
      "Epoch 88/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.11568000/8000 [==============================] - 17s 2ms/step - loss: 0.1157 - val_loss: 1.0472\n",
      "Epoch 89/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1139 - val_loss: 1.0579\n",
      "Epoch 90/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1118 - val_loss: 1.0620\n",
      "Epoch 91/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.10928000/8000 [==============================] - 17s 2ms/step - loss: 0.1099 - val_loss: 1.0683\n",
      "Epoch 92/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1078 - val_loss: 1.0757\n",
      "Epoch 93/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1065 - val_loss: 1.0818\n",
      "Epoch 94/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.10448000/8000 [==============================] - 17s 2ms/step - loss: 0.1049 - val_loss: 1.0899\n",
      "Epoch 95/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1029 - val_loss: 1.0959\n",
      "Epoch 96/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.1014 - val_loss: 1.1038\n",
      "Epoch 97/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.09938000/8000 [==============================] - 17s 2ms/step - loss: 0.1000 - val_loss: 1.1121\n",
      "Epoch 98/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0982 - val_loss: 1.1129\n",
      "Epoch 99/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0969 - val_loss: 1.1169\n",
      "Epoch 100/200\n",
      "7104/8000 [=========================>....] - ETA: 1s - loss: 0.09448000/8000 [==============================] - 17s 2ms/step - loss: 0.0952 - val_loss: 1.1283\n",
      "Epoch 101/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0939 - val_loss: 1.1315\n",
      "Epoch 102/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0925 - val_loss: 1.1422\n",
      "Epoch 103/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.09028000/8000 [==============================] - 17s 2ms/step - loss: 0.0911 - val_loss: 1.1363\n",
      "Epoch 104/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0898 - val_loss: 1.1488\n",
      "Epoch 105/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0885 - val_loss: 1.1589\n",
      "Epoch 106/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.08658000/8000 [==============================] - 17s 2ms/step - loss: 0.0873 - val_loss: 1.1609\n",
      "Epoch 107/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0863 - val_loss: 1.1716\n",
      "Epoch 108/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0845 - val_loss: 1.1692\n",
      "Epoch 109/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.08308000/8000 [==============================] - 17s 2ms/step - loss: 0.0836 - val_loss: 1.1744\n",
      "Epoch 110/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0820 - val_loss: 1.1930\n",
      "Epoch 111/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0809 - val_loss: 1.1939\n",
      "Epoch 112/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.07868000/8000 [==============================] - 17s 2ms/step - loss: 0.0792 - val_loss: 1.2011\n",
      "Epoch 113/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0784 - val_loss: 1.1957\n",
      "Epoch 114/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0774 - val_loss: 1.2100\n",
      "Epoch 115/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.07548000/8000 [==============================] - 17s 2ms/step - loss: 0.0761 - val_loss: 1.2216\n",
      "Epoch 116/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0753 - val_loss: 1.2202\n",
      "Epoch 117/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0740 - val_loss: 1.2296\n",
      "Epoch 118/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.07188000/8000 [==============================] - 17s 2ms/step - loss: 0.0725 - val_loss: 1.2402\n",
      "Epoch 119/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0720 - val_loss: 1.2382\n",
      "Epoch 120/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0704 - val_loss: 1.2434\n",
      "Epoch 121/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.06918000/8000 [==============================] - 17s 2ms/step - loss: 0.0698 - val_loss: 1.2518\n",
      "Epoch 122/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0687 - val_loss: 1.2441\n",
      "Epoch 123/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0675 - val_loss: 1.2616\n",
      "Epoch 124/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.06638000/8000 [==============================] - 17s 2ms/step - loss: 0.0667 - val_loss: 1.2626\n",
      "Epoch 125/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0655 - val_loss: 1.2704\n",
      "Epoch 126/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0651 - val_loss: 1.2703\n",
      "Epoch 127/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.06288000/8000 [==============================] - 17s 2ms/step - loss: 0.0638 - val_loss: 1.2724\n",
      "Epoch 128/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0627 - val_loss: 1.2737\n",
      "Epoch 129/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0620 - val_loss: 1.2790\n",
      "Epoch 130/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.06058000/8000 [==============================] - 17s 2ms/step - loss: 0.0613 - val_loss: 1.2892\n",
      "Epoch 131/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0601 - val_loss: 1.3006\n",
      "Epoch 132/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0593 - val_loss: 1.3094\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.05788000/8000 [==============================] - 17s 2ms/step - loss: 0.0583 - val_loss: 1.3064\n",
      "Epoch 134/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0577 - val_loss: 1.3110\n",
      "Epoch 135/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0572 - val_loss: 1.3103\n",
      "Epoch 136/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.05498000/8000 [==============================] - 17s 2ms/step - loss: 0.0557 - val_loss: 1.3168\n",
      "Epoch 137/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0560 - val_loss: 1.3193\n",
      "Epoch 138/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0545 - val_loss: 1.3272\n",
      "Epoch 139/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.05398000/8000 [==============================] - 17s 2ms/step - loss: 0.0545 - val_loss: 1.3355\n",
      "Epoch 140/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0533 - val_loss: 1.3439\n",
      "Epoch 141/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0525 - val_loss: 1.3421\n",
      "Epoch 142/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.05098000/8000 [==============================] - 17s 2ms/step - loss: 0.0513 - val_loss: 1.3446\n",
      "Epoch 143/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0507 - val_loss: 1.3488\n",
      "Epoch 144/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0500 - val_loss: 1.3522\n",
      "Epoch 145/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04898000/8000 [==============================] - 17s 2ms/step - loss: 0.0492 - val_loss: 1.3655\n",
      "Epoch 146/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0488 - val_loss: 1.3647\n",
      "Epoch 147/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0484 - val_loss: 1.3671\n",
      "Epoch 148/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04728000/8000 [==============================] - 17s 2ms/step - loss: 0.0479 - val_loss: 1.3709\n",
      "Epoch 149/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0468 - val_loss: 1.3737\n",
      "Epoch 150/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0465 - val_loss: 1.3818\n",
      "Epoch 151/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04558000/8000 [==============================] - 17s 2ms/step - loss: 0.0457 - val_loss: 1.3844\n",
      "Epoch 152/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0457 - val_loss: 1.3872\n",
      "Epoch 153/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0449 - val_loss: 1.3859\n",
      "Epoch 154/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04398000/8000 [==============================] - 17s 2ms/step - loss: 0.0446 - val_loss: 1.3821\n",
      "Epoch 155/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0436 - val_loss: 1.3940\n",
      "Epoch 156/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0433 - val_loss: 1.4046\n",
      "Epoch 157/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04208000/8000 [==============================] - 17s 2ms/step - loss: 0.0425 - val_loss: 1.4009\n",
      "Epoch 158/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0419 - val_loss: 1.4121\n",
      "Epoch 159/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0419 - val_loss: 1.4141\n",
      "Epoch 160/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04078000/8000 [==============================] - 17s 2ms/step - loss: 0.0410 - val_loss: 1.4175\n",
      "Epoch 161/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0411 - val_loss: 1.4137\n",
      "Epoch 162/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0446 - val_loss: 1.4251\n",
      "Epoch 163/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.04428000/8000 [==============================] - 17s 2ms/step - loss: 0.0452 - val_loss: 1.4159\n",
      "Epoch 164/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0430 - val_loss: 1.4334\n",
      "Epoch 165/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0411 - val_loss: 1.4643\n",
      "Epoch 166/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.07058000/8000 [==============================] - 17s 2ms/step - loss: 0.0674 - val_loss: 1.4210\n",
      "Epoch 167/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0407 - val_loss: 1.4234\n",
      "Epoch 168/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0407 - val_loss: 1.4316\n",
      "Epoch 169/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.03848000/8000 [==============================] - 17s 2ms/step - loss: 0.0398 - val_loss: 1.4286\n",
      "Epoch 170/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0378 - val_loss: 1.4414\n",
      "Epoch 171/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0386 - val_loss: 1.4346\n",
      "Epoch 172/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.03728000/8000 [==============================] - 17s 2ms/step - loss: 0.0375 - val_loss: 1.4390\n",
      "Epoch 173/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0375 - val_loss: 1.4473\n",
      "Epoch 174/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0367 - val_loss: 1.4512\n",
      "Epoch 175/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.03578000/8000 [==============================] - 17s 2ms/step - loss: 0.0362 - val_loss: 1.4610\n",
      "Epoch 176/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0358 - val_loss: 1.4548\n",
      "Epoch 177/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0358 - val_loss: 1.4596\n",
      "Epoch 178/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.03458000/8000 [==============================] - 17s 2ms/step - loss: 0.0349 - val_loss: 1.4714\n",
      "Epoch 179/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0349 - val_loss: 1.4745\n",
      "Epoch 180/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0348 - val_loss: 1.4657\n",
      "Epoch 181/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.03368000/8000 [==============================] - 17s 2ms/step - loss: 0.0340 - val_loss: 1.4706\n",
      "Epoch 182/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0336 - val_loss: 1.4736\n",
      "Epoch 183/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0335 - val_loss: 1.4839\n",
      "Epoch 184/200\n",
      "6976/8000 [=========================>....] - ETA: 1s - loss: 0.03318000/8000 [==============================] - 17s 2ms/step - loss: 0.0333 - val_loss: 1.4865\n",
      "Epoch 185/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0329 - val_loss: 1.4866\n",
      "Epoch 186/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0327 - val_loss: 1.4918\n",
      "Epoch 187/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.03158000/8000 [==============================] - 17s 2ms/step - loss: 0.0319 - val_loss: 1.4908\n",
      "Epoch 188/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0315 - val_loss: 1.4978\n",
      "Epoch 189/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0314 - val_loss: 1.4934\n",
      "Epoch 190/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.03078000/8000 [==============================] - 17s 2ms/step - loss: 0.0312 - val_loss: 1.5007\n",
      "Epoch 191/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0312 - val_loss: 1.5076\n",
      "Epoch 192/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0306 - val_loss: 1.4996\n",
      "Epoch 193/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.03008000/8000 [==============================] - 17s 2ms/step - loss: 0.0306 - val_loss: 1.5158\n",
      "Epoch 194/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0302 - val_loss: 1.5123\n",
      "Epoch 195/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0299 - val_loss: 1.5102\n",
      "Epoch 196/200\n",
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.02938000/8000 [==============================] - 17s 2ms/step - loss: 0.0298 - val_loss: 1.5142\n",
      "Epoch 197/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0294 - val_loss: 1.5125\n",
      "Epoch 198/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0295 - val_loss: 1.5215\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976/8000 [=========================>....] - ETA: 2s - loss: 0.02948000/8000 [==============================] - 17s 2ms/step - loss: 0.0297 - val_loss: 1.5245\n",
      "Epoch 200/200\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0292 - val_loss: 1.5160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f523e7b79e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "          batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1521388713094,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "kje1gzCbNCg5",
    "outputId": "ceb256a4-1c8b-4311-c04d-809a1c305c11"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('char_translation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Wr_lOVUdeXOT"
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights_char_translation_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ce_X8qEDNCg6"
   },
   "source": [
    "## 3. Inference mode: Teacher forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1pPAJLwNCg6"
   },
   "source": [
    "### 3.1. Re-define encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "S-GaRZe-NCg8"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GonISH5aNCg9"
   },
   "outputs": [],
   "source": [
    "encoder_model.save('encoder_char_translation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ij196vwiNCg_"
   },
   "source": [
    "### 3.2. Re-define decoder model to do the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "B8WpQGNzNChA"
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=\n",
    "                                                 decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, \n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1521389095559,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "nhy2cCpNNChC",
    "outputId": "a856aab5-a363-48f7-b1b8-b2684846801a"
   },
   "outputs": [],
   "source": [
    "decoder_model.save(os.path.join('decoder_char_translation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFPEnVckNChH"
   },
   "source": [
    "### 3.3. Translate sentence (English to Dutch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are updating the inference by feeding one-by-one character into decoder model as `teacher forcing` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G56m-jdvNChI"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, reverse_target_char_index['\\t']] = 1.\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = target_token_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "            len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6-TrDvRNChK"
   },
   "source": [
    "Example of encoding-decoding from 10 first samples of training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3417,
     "output_extras": [
      {
       "item_id": 7
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2305,
     "status": "ok",
     "timestamp": 1521389364291,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "dnwYKGZkNChK",
    "outputId": "29bcbdc4-d652-4e99-d567-1ea6f9913095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I'm home.\n",
      "Decoded sentence: Ik ben thuis.\n",
      "\n",
      "-\n",
      "Input sentence: I'm lost.\n",
      "Decoded sentence: Ik ben de weg kwijt.\n",
      "\n",
      "-\n",
      "Input sentence: I'm sick.\n",
      "Decoded sentence: Ik ben ziek.\n",
      "\n",
      "-\n",
      "Input sentence: I'm tall.\n",
      "Decoded sentence: Ik ben lang.\n",
      "\n",
      "-\n",
      "Input sentence: I'm weak.\n",
      "Decoded sentence: Ik ben zwak.\n",
      "\n",
      "-\n",
      "Input sentence: It hurts.\n",
      "Decoded sentence: Het doet pijn.\n",
      "\n",
      "-\n",
      "Input sentence: It's his.\n",
      "Decoded sentence: Het is de zijne.\n",
      "\n",
      "-\n",
      "Input sentence: It's his.\n",
      "Decoded sentence: Het is de zijne.\n",
      "\n",
      "-\n",
      "Input sentence: It's hot.\n",
      "Decoded sentence: Het is niet kamorie.\n",
      "\n",
      "-\n",
      "Input sentence: It's new.\n",
      "Decoded sentence: Het is nieuw.\n",
      "\n",
      "-\n",
      "Input sentence: Keep out!\n",
      "Decoded sentence: Verboden toegang.\n",
      "\n",
      "-\n",
      "Input sentence: Keep out!\n",
      "Decoded sentence: Verboden toegang.\n",
      "\n",
      "-\n",
      "Input sentence: Let's go!\n",
      "Decoded sentence: Laten we gaan!\n",
      "\n",
      "-\n",
      "Input sentence: Let's go!\n",
      "Decoded sentence: Laten we gaan!\n",
      "\n",
      "-\n",
      "Input sentence: Let's go.\n",
      "Decoded sentence: Laten we gaan.\n",
      "\n",
      "-\n",
      "Input sentence: Let's go.\n",
      "Decoded sentence: Laten we gaan.\n",
      "\n",
      "-\n",
      "Input sentence: Look out!\n",
      "Decoded sentence: Kijk uit!\n",
      "\n",
      "-\n",
      "Input sentence: Marry me.\n",
      "Decoded sentence: Maria kwam binnen.\n",
      "\n",
      "-\n",
      "Input sentence: She runs.\n",
      "Decoded sentence: Zij rent.\n",
      "\n",
      "-\n",
      "Input sentence: Sit down!\n",
      "Decoded sentence: Ga zitten!\n",
      "\n",
      "-\n",
      "Input sentence: Sit down.\n",
      "Decoded sentence: Zet u.\n",
      "\n",
      "-\n",
      "Input sentence: Sit down.\n",
      "Decoded sentence: Zet u.\n",
      "\n",
      "-\n",
      "Input sentence: Stand up!\n",
      "Decoded sentence: Sta op!\n",
      "\n",
      "-\n",
      "Input sentence: Terrific!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: Terrific!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: Terrific!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: Terrific!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: They won.\n",
      "Decoded sentence: Zij wonnen.\n",
      "\n",
      "-\n",
      "Input sentence: Tom died.\n",
      "Decoded sentence: Tom is gestorven.\n",
      "\n",
      "-\n",
      "Input sentence: Tom lied.\n",
      "Decoded sentence: Tom loog.\n",
      "\n",
      "-\n",
      "Input sentence: Too late.\n",
      "Decoded sentence: Te laat.\n",
      "\n",
      "-\n",
      "Input sentence: Try this.\n",
      "Decoded sentence: Probeer dit.\n",
      "\n",
      "-\n",
      "Input sentence: Warn Tom.\n",
      "Decoded sentence: Waarschuw Tom.\n",
      "\n",
      "-\n",
      "Input sentence: We agree.\n",
      "Decoded sentence: We zijn het eens.\n",
      "\n",
      "-\n",
      "Input sentence: Who am I?\n",
      "Decoded sentence: Wie ben ik?\n",
      "\n",
      "-\n",
      "Input sentence: Who fell?\n",
      "Decoded sentence: Wie viel?\n",
      "\n",
      "-\n",
      "Input sentence: After you.\n",
      "Decoded sentence: Gij eerst.\n",
      "\n",
      "-\n",
      "Input sentence: Answer me.\n",
      "Decoded sentence: Antwoord.\n",
      "\n",
      "-\n",
      "Input sentence: Calm down!\n",
      "Decoded sentence: Kalmeer je!\n",
      "\n",
      "-\n",
      "Input sentence: Calm down.\n",
      "Decoded sentence: Kalmeer je.\n",
      "\n",
      "-\n",
      "Input sentence: Calm down.\n",
      "Decoded sentence: Kalmeer je.\n",
      "\n",
      "-\n",
      "Input sentence: Catch him.\n",
      "Decoded sentence: Pak hem.\n",
      "\n",
      "-\n",
      "Input sentence: Dogs bark.\n",
      "Decoded sentence: De honden blaffen.\n",
      "\n",
      "-\n",
      "Input sentence: Excuse me.\n",
      "Decoded sentence: Pardon.\n",
      "\n",
      "-\n",
      "Input sentence: Excuse me?\n",
      "Decoded sentence: Wat zegt u?\n",
      "\n",
      "-\n",
      "Input sentence: Fantastic!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: Fantastic!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: Fantastic!\n",
      "Decoded sentence: Briljant!\n",
      "\n",
      "-\n",
      "Input sentence: Follow me.\n",
      "Decoded sentence: Volg hem.\n",
      "\n",
      "-\n",
      "Input sentence: Forget it.\n",
      "Decoded sentence: Vergeet dat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100,150):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-char-translation.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
