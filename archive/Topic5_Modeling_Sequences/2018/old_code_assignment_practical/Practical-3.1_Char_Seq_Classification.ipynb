{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-level Sequence Model for Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use IMDB review data set for generating the encoding of sentence (i.e text review from user) to classify sentiment polarity of this text. Data is originally taken from https://www.kaggle.com/c/word2vec-nlp-tutorial/data. It contains 25000 reviews with labels 0 for \"negative\" sentiment and 1 for \"positive\" sentiment. For validation and testing set, the information about binary labels (0 and 1) can be seen in attribute \"id\" of the data set. Number after character '\\_' represents rating score. If rating <5, then the sentiment score is 0 or \"negative\" sentiment. If the rating >=7, then the score is 1 or \"positive\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of (part of) original text in data set:\n",
    "\n",
    "```\n",
    "id\tsentiment\treview\n",
    "\n",
    "\"7759_3\"\t0\t\"The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to Primal Park . A secret project mutating a primal animal using fossilized DNA, like ¨Jurassik Park¨, and some scientists resurrect one of nature's most fearsome predators, the Sabretooth tiger or Smilodon . Scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger .\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a text (e.g. a movie review), we need to predict whether this review is positive (class label=1) or negative (class label =0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "* Encode text from character level by using bidirectional LSTM as encoder model\n",
    "* Project the output of encoder model to dense prediction layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* remove HTML tags\n",
    "* remove non-informative characters\n",
    "* Take the first 1000 characters of text review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "import re\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "EMBEDDING_PATH = 'embedding'\n",
    "MODEL_PATH = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "# reading file in pickle format\n",
    "def readPickle(pickleFilename):\n",
    "\tf = open(pickleFilename, 'rb')\n",
    "\tobj = cPickle.load(f)\n",
    "\tf.close()\n",
    "\treturn obj\n",
    "\n",
    "def savePickle(dataToWrite,pickleFilename):\n",
    "\tf = open(pickleFilename, 'wb')\n",
    "\tcPickle.dump(dataToWrite, f)\n",
    "\tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(DATA_PATH,\"labeledTrainData.tsv\"), header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = pd.read_csv(os.path.join(DATA_PATH,\"testData.tsv\"), header=0, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striphtml(html):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    return re.sub(r'[^\\x00-\\x7f]', r'', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment with MJ i've started listening to his music, watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy Hines is a very entertaining film that obviously g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised this film (\\\"the greatest filmed opera ever,\\\" didn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious 80's exploitation, hooray! The pre-credits opening...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment  \\\n",
       "0  \"5814_8\"          1   \n",
       "1  \"2381_9\"          1   \n",
       "2  \"7759_3\"          0   \n",
       "3  \"3630_4\"          0   \n",
       "4  \"9495_8\"          1   \n",
       "\n",
       "                                                                                                review  \n",
       "0  \"With all this stuff going down at the moment with MJ i've started listening to his music, watch...  \n",
       "1  \"\\\"The Classic War of the Worlds\\\" by Timothy Hines is a very entertaining film that obviously g...  \n",
       "2  \"The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to P...  \n",
       "3  \"It must be assumed that those who praised this film (\\\"the greatest filmed opera ever,\\\" didn't...  \n",
       "4  \"Superbly trashy and wondrously unpretentious 80's exploitation, hooray! The pre-credits opening...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of mortality, nostalgia, and loss of innocence it is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster film. It is full of great action scenes, which are on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw it tonight and my child loved it. At one point my k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression that several different screenplays were written, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob life filmed in New Jersey. The story, characters and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  12311_10   \n",
       "1    8348_2   \n",
       "2    5828_4   \n",
       "3    7186_2   \n",
       "4   12128_7   \n",
       "\n",
       "                                                                                                review  \n",
       "0  Naturally in a film who's main themes are of mortality, nostalgia, and loss of innocence it is p...  \n",
       "1  This movie is a disaster within a disaster film. It is full of great action scenes, which are on...  \n",
       "2  All in all, this is a movie for kids. We saw it tonight and my child loved it. At one point my k...  \n",
       "3  Afraid of the Dark left me with the impression that several different screenplays were written, ...  \n",
       "4  A very accurate depiction of small time mob life filmed in New Jersey. The story, characters and...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create document corpus (array list of text documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "sentiments = []\n",
    "for cont, sentiment in zip(data.review, data.sentiment):\n",
    "    doc = clean(striphtml(cont))\n",
    "    doc = doc.lower() \n",
    "    docs.append(doc)\n",
    "    sentiments.append(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_docs =[]\n",
    "valid_labels = []\n",
    "i=0\n",
    "for docid,cont in zip(valid_data.id, valid_data.review):\n",
    "    id_label = docid.split('_')\n",
    "    if(int(id_label[1]) >= 7):\n",
    "        valid_labels.append(1)\n",
    "    else:\n",
    "        valid_labels.append(0)         \n",
    "    doc = clean(striphtml(cont))\n",
    "    doc = doc.lower() \n",
    "    valid_docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build character level vocabulary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    for s in doc:\n",
    "        txt += s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in valid_docs:\n",
    "    for s in doc:\n",
    "        txt += s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 71\n"
     ]
    }
   ],
   "source": [
    "chars = set(txt)\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_', 61), ('&', 0), ('i', 1), ('q', 2), ('[', 58)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(char_indices.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '&'), (1, 'i'), (2, 'q'), (3, 's'), (4, 'a')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(indices_char.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to store files\n",
    "\n",
    "#savePickle(char_indices, os.path.join(DATA_PATH,'char_indices'))\n",
    "#savePickle(indices_char, os.path.join(DATA_PATH,'indices_char'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chars = len(char_indices)\n",
    "num_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding training sets into fixed length (1000 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "\n",
    "X = np.zeros((len(docs), maxlen), dtype=np.int32)\n",
    "y = np.array(sentiments)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    len_doc = len(doc)\n",
    "    if len_doc > maxlen:\n",
    "        txt = doc[:maxlen]\n",
    "    else:\n",
    "        txt = doc\n",
    "    for j, char in enumerate(txt):\n",
    "        X[i, j] = char_indices[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding validation sets into fixed length (1000 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "\n",
    "X_valid = np.zeros((len(valid_docs), maxlen), dtype=np.int32) \n",
    "y_valid = np.array(valid_labels)\n",
    "\n",
    "for i, doc in enumerate(valid_docs):\n",
    "    len_doc = len(doc)\n",
    "    if len_doc > maxlen:\n",
    "        txt = doc[:maxlen]\n",
    "    else:\n",
    "        txt = doc\n",
    "    for j, char in enumerate(txt):\n",
    "        X_valid[i, j] = char_indices[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:10000]\n",
    "X_val = X_valid[:5000]\n",
    "\n",
    "y_train = y[:10000]\n",
    "y_val = y_valid[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Character-level sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.layers import LSTM, Lambda, merge, concatenate\n",
    "import tensorflow as tf\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(x, sz=71):\n",
    "    return tf.to_float(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_outshape(in_shape):\n",
    "    return in_shape[0], in_shape[1], 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: LSTM layer (Keras sequential model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(binarize, output_shape=binarize_outshape,name='embedding_encoder', input_shape=(1000,), dtype='int32'))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Bidirectional LSTM and dropout layers (Keras sequential model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_encoder (Lambda)   (None, 1000, 71)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               69632     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 86,273\n",
      "Trainable params: 86,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(binarize, output_shape=binarize_outshape,name='embedding_encoder', input_shape=(1000,), dtype='int32'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1400s 140ms/step - loss: 0.6992 - acc: 0.4921 - val_loss: 0.6931 - val_acc: 0.5080\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1505s 150ms/step - loss: 0.6991 - acc: 0.4960 - val_loss: 0.6930 - val_acc: 0.5080\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1548s 155ms/step - loss: 0.6976 - acc: 0.5036 - val_loss: 0.6934 - val_acc: 0.4920\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1577s 158ms/step - loss: 0.6990 - acc: 0.4922 - val_loss: 0.6945 - val_acc: 0.5080\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1446s 145ms/step - loss: 0.7005 - acc: 0.5014 - val_loss: 0.7017 - val_acc: 0.5080\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1659s 166ms/step - loss: 0.7015 - acc: 0.5113 - val_loss: 0.6931 - val_acc: 0.5080\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1524s 152ms/step - loss: 0.7093 - acc: 0.5051 - val_loss: 0.6953 - val_acc: 0.5080\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1418s 142ms/step - loss: 0.7113 - acc: 0.5029 - val_loss: 0.6932 - val_acc: 0.5080\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1580s 158ms/step - loss: 0.7189 - acc: 0.4965 - val_loss: 0.7738 - val_acc: 0.4920\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1369s 137ms/step - loss: 0.7283 - acc: 0.5030 - val_loss: 0.7796 - val_acc: 0.4920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd914963ac8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "* Why do you think this model does not converge? What could be the reason? Can you improve the performance by adding more training data? (e.g. 20.000 training sets instead of 10.000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectional LSTM with Keras fungsional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model, with modularity of Fungsional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=(None, ), name='encoder_input')\n",
    "char_embedding = Lambda(binarize, output_shape=binarize_outshape,name='embedding_encoder')(x_input)\n",
    "forwards = LSTM(32, return_sequences=False)(char_embedding)\n",
    "backwards = LSTM(32, return_sequences=False, go_backwards=True)(char_embedding)\n",
    "merged = concatenate([forwards, backwards],axis=-1)\n",
    "output = Dropout(0.5)(merged)\n",
    "output = Dense(128, activation='relu')(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "model = Model(inputs=encoder_input, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Hierarchical Model of Sentence-Document with CNN + LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create corpus of document as array list of sentences (3D matrix input, instead of 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_sents = []\n",
    "docs_sents_y = []\n",
    "for cont, sentiment in zip(data.review, data.sentiment):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', clean(striphtml(cont)))\n",
    "    sentences = [sent.lower() for sent in sentences]\n",
    "    docs_sents.append(sentences)\n",
    "    docs_sents_y.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_docs_sents = []\n",
    "val_docs_sents_y = []\n",
    "for docid,cont in zip(valid_data.id, valid_data.review):\n",
    "    \n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', clean(striphtml(cont)))\n",
    "    sentences = [sent.lower() for sent in sentences]\n",
    "    val_docs_sents.append(sentences)\n",
    "    \n",
    "    id_label = docid.split('_')\n",
    "    if(int(id_label[1]) >= 7):\n",
    "        val_docs_sents_y.append(1)\n",
    "    else:\n",
    "        val_docs_sents_y.append(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50 # maximum number of words in a sentence\n",
    "max_sentences = 15 # maximum number of sentence in a document\n",
    "\n",
    "X = np.zeros((len(docs_sents), max_sentences, maxlen), dtype=np.int32) \n",
    "y = np.array(docs_sents_y)\n",
    "\n",
    "for i, doc in enumerate(docs_sents):\n",
    "    for j, sentence in enumerate(doc):\n",
    "        if j < max_sentences:\n",
    "            len_sent = len(sentence) \n",
    "            if len_doc > maxlen:\n",
    "                sent = sentence[:maxlen]\n",
    "            else:\n",
    "                sent = sentence\n",
    "            \n",
    "            for t, char in enumerate(sent):\n",
    "                X[i, j, (maxlen - 1 - t)] = char_indices[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50 # maximum number of words in a sentence\n",
    "max_sentences = 15 # maximum number of sentence in a document\n",
    "\n",
    "X_val = np.zeros((len(val_docs_sents), max_sentences, maxlen), dtype=np.int32) \n",
    "y_val = np.array(val_docs_sents_y)\n",
    "\n",
    "for i, doc in enumerate(val_docs_sents):\n",
    "    for j, sentence in enumerate(doc):\n",
    "        if j < max_sentences:\n",
    "            len_sent = len(sentence) \n",
    "            if len_doc > maxlen:\n",
    "                sent = sentence[:maxlen]\n",
    "            else:\n",
    "                sent = sentence\n",
    "            \n",
    "            for t, char in enumerate(sent):\n",
    "                X_val[i, j, (maxlen - 1 - t)] = char_indices[char]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the input shape is in 3D: number of examples, max sentences, max words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 15, 50)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 15, 50)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X\n",
    "y_train = y\n",
    "\n",
    "x_valid = X_val[:5000]\n",
    "y_valid = y_val[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Character-level Hierarchical Model of Sentence-Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
    "from keras.layers import LSTM, Lambda, Bidirectional, concatenate, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document input\n",
    "document = Input(shape=(max_sentences, maxlen), dtype='int32')\n",
    "# sentence input\n",
    "in_sentence = Input(shape=(maxlen,), dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char indices to one hot matrix, 1D sequence to 2D \n",
    "embedded = Lambda(binarize, output_shape=binarize_outshape)(in_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedded: encodes sentence by character with CNN\n",
    "\n",
    "filter_length = [5, 3, 3]\n",
    "nb_filter = [196, 196, 256]\n",
    "pool_length = 2\n",
    "\n",
    "for i in range(len(nb_filter)):\n",
    "    embedded = Conv1D(filters=nb_filter[i],\n",
    "                      kernel_size=filter_length[i],\n",
    "                      padding='valid',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='glorot_normal',\n",
    "                      strides=1)(embedded)\n",
    "\n",
    "    embedded = Dropout(0.1)(embedded)\n",
    "    embedded = MaxPooling1D(pool_size=pool_length)(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_sent = Bidirectional(LSTM(128, return_sequences=False))(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 50, 71)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 46, 196)           69776     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 46, 196)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 23, 196)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 21, 196)           115444    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 21, 196)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 10, 196)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 256)            150784    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               394240    \n",
      "=================================================================\n",
      "Total params: 730,244\n",
      "Trainable params: 730,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sent_encoder = Model(inputs=in_sentence, outputs=bi_lstm_sent)\n",
    "sent_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = TimeDistributed(sent_encoder)(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_doc = Bidirectional(LSTM(128, return_sequences=False))(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 15, 50)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 15, 256)           730244    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,157,509\n",
      "Trainable params: 1,157,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output = Dropout(0.5)(bi_lstm_doc)\n",
    "output = Dense(128, activation='relu')(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "model = Model(inputs=document, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 3657s 146ms/step - loss: 0.6939 - acc: 0.5019 - val_loss: 0.6935 - val_acc: 0.4920\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 3686s 147ms/step - loss: 0.6325 - acc: 0.6250 - val_loss: 0.5502 - val_acc: 0.7214\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 3781s 151ms/step - loss: 0.4846 - acc: 0.7659 - val_loss: 0.4688 - val_acc: 0.7704\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 3575s 143ms/step - loss: 0.4329 - acc: 0.7979 - val_loss: 0.4413 - val_acc: 0.7900\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 3625s 145ms/step - loss: 0.3915 - acc: 0.8252 - val_loss: 0.4436 - val_acc: 0.7916\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 3768s 151ms/step - loss: 0.3540 - acc: 0.8466 - val_loss: 0.4536 - val_acc: 0.7948\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 3839s 154ms/step - loss: 0.3136 - acc: 0.8682 - val_loss: 0.4440 - val_acc: 0.7908\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 3642s 146ms/step - loss: 0.2750 - acc: 0.8882 - val_loss: 0.5203 - val_acc: 0.7816\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 3620s 145ms/step - loss: 0.2401 - acc: 0.9059 - val_loss: 0.4663 - val_acc: 0.7904\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 3560s 142ms/step - loss: 0.2132 - acc: 0.9168 - val_loss: 0.5680 - val_acc: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8ac7f1208>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(os.path.join(MODEL_PATH,'practical_3_1_model4.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weight parameters\n",
    "model.save_weights(os.path.join(MODEL_PATH, 'weights_practical_3_1_model4.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "* What is your overall conclusion after comparing different model architectures on character-level sentiment classification task? \n",
    "* What are advantages and disadvantages of character-level sequential (RNN) model for this specific task (or other possible tasks as well)?   \n",
    "\n",
    "(hints):\n",
    "* encoding process of input\n",
    "* sequence length\n",
    "* hyperparameters\n",
    "* training examples\n",
    "* computation resource"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
