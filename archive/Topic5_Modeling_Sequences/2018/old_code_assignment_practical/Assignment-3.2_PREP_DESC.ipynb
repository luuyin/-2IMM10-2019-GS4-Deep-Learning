{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description about data preprocessing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset (training, validation, and testing set) used in this experiment is based on the paper [\"Order-embeddings Of Images and Language\"](https://arxiv.org/pdf/1511.06361.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data before preprocessing:\n",
    "\n",
    "* Data with VGG19 features: [here](http://www.cs.toronto.edu/~vendrov/order/coco.zip)\n",
    "* Caption and information from COCO site: [here](https://storage.googleapis.com/trl_data/coco_annotations_2014.zip)\n",
    "\n",
    "Original source: [COCO website](http://cocodataset.org/#download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "EMBEDDING_PATH = 'embeddings'\n",
    "MODEL_PATH = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "# reading file in pickle format\n",
    "def readPickle(pickleFilename):\n",
    "    f = open(pickleFilename, 'rb')\n",
    "    obj = cPickle.load(f)\n",
    "    f.close()\n",
    "    return obj\n",
    "\n",
    "def savePickle(dataToWrite,pickleFilename):\n",
    "    f = open(pickleFilename, 'wb')\n",
    "    cPickle.dump(dataToWrite, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessed data (caption,images pairs) with VGG19 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, cnn, fold=0):\n",
    "    \"\"\"\n",
    "    Load captions and image features\n",
    "    Possible options: coco\n",
    "    \"\"\"\n",
    "    splits = ['train', 'test', 'dev']\n",
    "    \n",
    "    \n",
    "    dataset = {}\n",
    "\n",
    "    for split in splits:\n",
    "        dataset[split] = {}\n",
    "        caps = []\n",
    "        splitName = 'val' if split == 'dev' else split\n",
    "        with open('%s/%s.txt' % (path, splitName), 'rb') as f:\n",
    "            for line in f:\n",
    "                caps.append(line.strip())\n",
    "            dataset[split]['caps'] = caps\n",
    "\n",
    "        dataset[split]['ims'] = np.load('%s/images/%s/%s.npy' % (path, cnn, splitName))\n",
    "        \n",
    "       \n",
    "        \n",
    "        if split in ['train']:\n",
    "            dataset[split]['ims'] = dataset[split]['ims'][fold*10000:(fold+1)*10000]\n",
    "            dataset[split]['caps'] = dataset[split]['caps'][fold*50000:(fold+1)*50000]\n",
    "\n",
    "        # handle coco specially by only taking 1k or 5k captions/images\n",
    "        if split in ['dev', 'test']:\n",
    "            dataset[split]['ims'] = dataset[split]['ims'][fold*1000:(fold+1)*1000]\n",
    "            dataset[split]['caps'] = dataset[split]['caps'][fold*5000:(fold+1)*5000]\n",
    "        \n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('data', cnn='10crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = dataset['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save\n",
    "# savePickle(train_data, os.path.join(DATA_PATH, 'train_data'))\n",
    "# savePickle(val_data, os.path.join(DATA_PATH, 'val_data'))\n",
    "# savePickle(test_data, os.path.join(DATA_PATH, 'test_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Raw data from original source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instances information of validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH,'instances_val2014.json')) as json_file:\n",
    "    coco_instances_val = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['licenses', 'annotations', 'info', 'categories', 'images'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_instances_val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40504"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_instances_val['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_instances_val['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'person', 'supercategory': 'person'},\n",
       " {'id': 2, 'name': 'bicycle', 'supercategory': 'vehicle'},\n",
       " {'id': 3, 'name': 'car', 'supercategory': 'vehicle'},\n",
       " {'id': 4, 'name': 'motorcycle', 'supercategory': 'vehicle'},\n",
       " {'id': 5, 'name': 'airplane', 'supercategory': 'vehicle'},\n",
       " {'id': 6, 'name': 'bus', 'supercategory': 'vehicle'},\n",
       " {'id': 7, 'name': 'train', 'supercategory': 'vehicle'},\n",
       " {'id': 8, 'name': 'truck', 'supercategory': 'vehicle'},\n",
       " {'id': 9, 'name': 'boat', 'supercategory': 'vehicle'},\n",
       " {'id': 10, 'name': 'traffic light', 'supercategory': 'outdoor'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_instances_val['categories'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption information of validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH,'captions_val2014.json')) as json_file:\n",
    "    coco_caption_val = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['licenses', 'annotations', 'info', 'images'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_caption_val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40504"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_caption_val['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202520"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_caption_val['images']) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202654"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_caption_val['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'coco_url': 'http://images.cocodataset.org/val2014/COCO_val2014_000000391895.jpg',\n",
       "  'date_captured': '2013-11-14 11:18:45',\n",
       "  'file_name': 'COCO_val2014_000000391895.jpg',\n",
       "  'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg',\n",
       "  'height': 360,\n",
       "  'id': 391895,\n",
       "  'license': 3,\n",
       "  'width': 640}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_caption_val['images'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'caption': 'A bicycle replica with a clock as the front wheel.',\n",
       "  'id': 37,\n",
       "  'image_id': 203564},\n",
       " {'caption': 'A black Honda motorcycle parked in front of a garage.',\n",
       "  'id': 38,\n",
       "  'image_id': 179765},\n",
       " {'caption': 'A room with blue walls and a white sink and door.',\n",
       "  'id': 49,\n",
       "  'image_id': 322141},\n",
       " {'caption': 'A car that seems to be parked illegally behind a legally parked car',\n",
       "  'id': 89,\n",
       "  'image_id': 16977},\n",
       " {'caption': 'A large passenger airplane flying through the air.',\n",
       "  'id': 98,\n",
       "  'image_id': 106140}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_caption_val['annotations'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(DATA_PATH, 'sampled_images_coco/COCO_val2014_000000015260.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(filepath, target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing information to make pairs of raw images and captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# dict format of (image-id, filename)\n",
    "img_data = OrderedDict()\n",
    "# dict format of (caption-id, caption-text)\n",
    "cap_data = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_ids = set()\n",
    "img_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coco_caption_val['images'])):\n",
    "    #raw image data\n",
    "    img_id = coco_caption_val['images'][i]['id']\n",
    "    img_filename = coco_caption_val['images'][i]['file_name']\n",
    "    img_data[img_id] = img_filename\n",
    "\n",
    "for i in range(len(coco_caption_val['annotations'])):\n",
    "    # caption text data\n",
    "    cap_id = coco_caption_val['annotations'][i]['id']\n",
    "    cap_ids.add(cap_id)\n",
    "    \n",
    "    cap_img_id = coco_caption_val['annotations'][i]['image_id']\n",
    "    img_ids.add(cap_img_id)\n",
    "    \n",
    "    cap_text = coco_caption_val['annotations'][i]['caption']\n",
    "    cap_data[cap_id] = cap_text\n",
    "    \n",
    "    cap_imgs.append((cap_id,cap_img_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_caps = [(id2,id1) for (id1,id2) in cap_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for storing files\n",
    "\n",
    "# savePickle(img_data, os.path.join(DATA_PATH, 'img_val_data'))\n",
    "# savePickle(cap_data, os.path.join(DATA_PATH, 'cap_val_data'))\n",
    "# savePickle(cap_imgs, os.path.join(DATA_PATH, 'cap_imgs'))\n",
    "# savePickle(img_caps, os.path.join(DATA_PATH, 'img_caps'))\n",
    "# savePickle(cap_ids, os.path.join(DATA_PATH, 'cap_ids'))\n",
    "# savePickle(img_ids, os.path.join(DATA_PATH, 'img_ids'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare raw set and preprocessed VGG19 data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use validation set for our retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cap_dec = []\n",
    "for capid, txt in enumerate(val_data['caps']):\n",
    "    val_cap_dec.append((capid, txt.decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_element_in_list(element, list_element):\n",
    "    try:\n",
    "        index_element = list_element.index(element)\n",
    "        return index_element\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cap = np.array(val_cap_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_matched = []\n",
    "for (capid, cap) in cap_data.items():\n",
    "    txt = cap.lower().strip('.')\n",
    "    list_val_caps = list(val_cap[:,1])\n",
    "    idx_cap = find_element_in_list(txt,list_val_caps)\n",
    "    val_matched.append((capid, idx_cap, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to store file\n",
    "# savePickle(val_matched, os.path.join(DATA_PATH, 'val_matched'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_matched_data = []\n",
    "for (id1,id2,txt) in val_matched:\n",
    "    if id2 != None:\n",
    "        val_matched_data.append((id1,id2,txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to store file\n",
    "# savePickle(val_matched_data, os.path.join(DATA_PATH, 'val_matched_data'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
