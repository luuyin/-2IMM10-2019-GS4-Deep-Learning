{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "syVS1Y5NQ9jg"
   },
   "source": [
    "# Practical 6.0 : Bidirectional, CNN + RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7z3M8z2CQ9ji"
   },
   "source": [
    "# Character-level Sequence classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1kD5Y1yOQ9jj"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrhE95xgQ9jo"
   },
   "source": [
    "### IMDB user review data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4guNwKMjQ9jp"
   },
   "source": [
    "We will use character sequences of IMDB text reviews to predict whether the review is positive (class label=1) or negative (class label =0). Download data set from https://storage.googleapis.com/trl_data/imdb_dataset.zip. Run Practical 5.1 to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MAxSXVroQ9jq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "EMBEDDING_PATH = 'embedding'\n",
    "MODEL_PATH = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2xPrWVMQ9ju"
   },
   "source": [
    "## Read preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OQBJXzmeQ9jv"
   },
   "outputs": [],
   "source": [
    "# reading stored character-level vocabulary index\n",
    "\n",
    "np_indices_char = np.load(os.path.join(DATA_PATH,'indices_char.npy'))\n",
    "\n",
    "import collections\n",
    "\n",
    "indices_char = collections.OrderedDict()\n",
    "for i in range(len(np_indices_char.item())):\n",
    "    index_val =  np_indices_char.item()[i]\n",
    "    indices_char[i] = index_val\n",
    "    \n",
    "char_indices = dict((c, i) for i, c in (indices_char.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sugqrSicQ9jy"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(DATA_PATH,'X_train_char.npy'))\n",
    "y_train = np.load(os.path.join(DATA_PATH,'y_train_char.npy'))\n",
    "\n",
    "X_valid = np.load(os.path.join(DATA_PATH,'X_valid_char.npy'))\n",
    "y_valid = np.load(os.path.join(DATA_PATH,'y_valid_char.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5HacVhADQ9j1"
   },
   "outputs": [],
   "source": [
    "# here we only use smaller set to train our model \n",
    "# original set consists of 25.000 reviews\n",
    "\n",
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "\n",
    "X_valid = X_valid[:5000]\n",
    "y_valid = y_valid[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viCwmNzfQ9j5"
   },
   "source": [
    "## Character-level Recurrent Neural Networks (RNN) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N7wxF011Q9j7"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.layers import LSTM, Lambda, Bidirectional, concatenate\n",
    "import tensorflow as tf\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H6RoBpyFQ9kB"
   },
   "outputs": [],
   "source": [
    "num_chars = len(char_indices)\n",
    "max_sequence_length = 100\n",
    "rnn_dim = 32\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a9hGWfXKQ9kD"
   },
   "outputs": [],
   "source": [
    "def binarize(x, sz=num_chars):\n",
    "    return tf.to_float(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gPAseaGUQ9kG"
   },
   "outputs": [],
   "source": [
    "def binarize_outshape(in_shape):\n",
    "    return in_shape[0], in_shape[1], num_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTvAjC9gQ9kI"
   },
   "source": [
    "## 1. Bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be included in model architecture:\n",
    "\n",
    "* Input layer\n",
    "* Lambda layer as projection layer for one hot encoding of character input\n",
    "* Bidirectional LSTM\n",
    "* Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ubgkn30Q9kJ"
   },
   "source": [
    "#### Example-1: using Bidirectional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 666,
     "output_extras": [
      {
       "item_id": 95
      },
      {
       "item_id": 412
      },
      {
       "item_id": 731
      },
      {
       "item_id": 798
      },
      {
       "item_id": 799
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 272519,
     "status": "ok",
     "timestamp": 1521565805974,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "afgxW7XoQ9kK",
    "outputId": "a2879690-172a-4853-d3a7-2335cad707d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_encoder (Lambda)   (None, 100, 71)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 64)                26624     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 26,689\n",
      "Trainable params: 26,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.6926 - acc: 0.5106 - val_loss: 0.6924 - val_acc: 0.5118\n",
      "Epoch 2/10\n",
      " 1920/10000 [====>.........................] - ETA: 20s - loss: 0.6874 - acc: 0.562010000/10000 [==============================] - 28s 3ms/step - loss: 0.6904 - acc: 0.5315 - val_loss: 0.6899 - val_acc: 0.5352\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.6860 - acc: 0.5511 - val_loss: 0.6908 - val_acc: 0.5424\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.6831 - acc: 0.5604 - val_loss: 0.6912 - val_acc: 0.5312\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.6817 - acc: 0.5627 - val_loss: 0.6860 - val_acc: 0.5460\n",
      "Epoch 6/10\n",
      " 1664/10000 [===>..........................] - ETA: 19s - loss: 0.6762 - acc: 0.579910000/10000 [==============================] - 27s 3ms/step - loss: 0.6789 - acc: 0.5650 - val_loss: 0.6867 - val_acc: 0.5436\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.6769 - acc: 0.5717 - val_loss: 0.6845 - val_acc: 0.5558\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6742 - acc: 0.5739 - val_loss: 0.6856 - val_acc: 0.5432\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6751 - acc: 0.5819 - val_loss: 0.6841 - val_acc: 0.5530\n",
      "Epoch 10/10\n",
      " 1536/10000 [===>..........................] - ETA: 20s - loss: 0.6660 - acc: 0.585310000/10000 [==============================] - 26s 3ms/step - loss: 0.6697 - acc: 0.5792 - val_loss: 0.6857 - val_acc: 0.5558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f756334df60>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct architecture\n",
    "char_input = # YOUR CODE HERE\n",
    "onehot_layer = # YOUR CODE HERE\n",
    "bilstm_layer = # YOUR CODE HERE\n",
    "sentiment_prediction = # YOUR CODE HERE\n",
    "\n",
    "# define and load model\n",
    "bilstm_model = Model(inputs=char_input, outputs=sentiment_prediction)\n",
    "bilstm_model.summary()\n",
    "\n",
    "# compile model\n",
    "bilstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "bilstm_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jr4bXO2xQ9kO"
   },
   "source": [
    "#### Example-2: using concatenate layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be included in model architecture:\n",
    "\n",
    "* Input layer\n",
    "* Lambda layer as projection layer for one hot encoding of character input\n",
    "* Forwards LSTM\n",
    "* Backwards LSTM\n",
    "* Concatenation layer\n",
    "* Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 751,
     "output_extras": [
      {
       "item_id": 50
      },
      {
       "item_id": 337
      },
      {
       "item_id": 649
      },
      {
       "item_id": 795
      },
      {
       "item_id": 796
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262642,
     "status": "ok",
     "timestamp": 1521566105050,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "LFEizbjtQ9kP",
    "outputId": "dea958f0-19aa-4b62-b7b0-58cfbe3c5253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_encoder (Lambda)      (None, 100, 71)      0           encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 32)           13312       embedding_encoder[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 32)           13312       embedding_encoder[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_8[0][0]                     \n",
      "                                                                 lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            65          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 26,689\n",
      "Trainable params: 26,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 10000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " 6400/10000 [==================>...........] - ETA: 9s - loss: 0.6939 - acc: 0.498310000/10000 [==============================] - 28s 3ms/step - loss: 0.6935 - acc: 0.5060 - val_loss: 0.6925 - val_acc: 0.5138\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6910 - acc: 0.5247 - val_loss: 0.6919 - val_acc: 0.5186\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6883 - acc: 0.5451 - val_loss: 0.6882 - val_acc: 0.5268\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6843 - acc: 0.5602 - val_loss: 0.6892 - val_acc: 0.5410\n",
      "Epoch 5/10\n",
      " 2176/10000 [=====>........................] - ETA: 18s - loss: 0.6841 - acc: 0.568510000/10000 [==============================] - 26s 3ms/step - loss: 0.6814 - acc: 0.5633 - val_loss: 0.6849 - val_acc: 0.5524\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.6782 - acc: 0.5701 - val_loss: 0.6845 - val_acc: 0.5510\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6766 - acc: 0.5628 - val_loss: 0.6840 - val_acc: 0.5510\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.6739 - acc: 0.5740 - val_loss: 0.6843 - val_acc: 0.5584\n",
      "Epoch 9/10\n",
      " 1664/10000 [===>..........................] - ETA: 18s - loss: 0.6752 - acc: 0.576910000/10000 [==============================] - 25s 3ms/step - loss: 0.6718 - acc: 0.5777 - val_loss: 0.6862 - val_acc: 0.5546\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 0.6703 - acc: 0.5818 - val_loss: 0.6844 - val_acc: 0.5544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7561e2fd68>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct architecture\n",
    "\n",
    "\n",
    "char_input = # YOUR CODE HERE\n",
    "onehot_layer = # YOUR CODE HERE\n",
    "forwards = # YOUR CODE HERE\n",
    "backwards = # YOUR CODE HERE\n",
    "merged = # YOUR CODE HERE\n",
    "sentiment_prediction = # YOUR CODE HERE\n",
    "\n",
    "# define and load model\n",
    "bilstm_model = Model(inputs=char_input, outputs=sentiment_prediction)\n",
    "bilstm_model.summary()\n",
    "\n",
    "# compile model\n",
    "bilstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bilstm_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zT43JDfMQ9kW"
   },
   "source": [
    "## 2. CNN + RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBoej4nuQ9kX"
   },
   "source": [
    "### Preprocessing documents into splitted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YaX8nflcQ9kY"
   },
   "outputs": [],
   "source": [
    "def striphtml(html):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', html)\n",
    "\n",
    "def clean(s):\n",
    "    return re.sub(r'[^\\x00-\\x7f]', r'', s)\n",
    "\n",
    "data = pd.read_csv(os.path.join(local_download_path,\"trainingData.tsv\"), header=0, delimiter=\"\\t\")\n",
    "valid_data = pd.read_csv(os.path.join(local_download_path,\"validationData.tsv\"), header=0, delimiter=\"\\t\")\n",
    "\n",
    "docs_sents = []\n",
    "docs_sents_y = []\n",
    "for cont, sentiment in zip(data.review, data.sentiment):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', clean(striphtml(cont)))\n",
    "    sentences = [sent.lower() for sent in sentences]\n",
    "    docs_sents.append(sentences)\n",
    "    docs_sents_y.append(sentiment)\n",
    "    \n",
    "\n",
    "val_docs_sents = []\n",
    "val_docs_sents_y = []\n",
    "for docid,cont in zip(valid_data.id, valid_data.review):\n",
    "    \n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', clean(striphtml(cont)))\n",
    "    sentences = [sent.lower() for sent in sentences]\n",
    "    val_docs_sents.append(sentences)\n",
    "    \n",
    "    id_label = docid.split('_')\n",
    "    if(int(id_label[1]) >= 7):\n",
    "        val_docs_sents_y.append(1)\n",
    "    else:\n",
    "        val_docs_sents_y.append(0)   \n",
    "\n",
    "# reading stored character-level vocabulary index\n",
    "\n",
    "np_indices_char = np.load(os.path.join(local_download_path,'indices_char.npy'))\n",
    "\n",
    "import collections\n",
    "\n",
    "indices_char = collections.OrderedDict()\n",
    "for i in range(len(np_indices_char.item())):\n",
    "    index_val =  np_indices_char.item()[i]\n",
    "    indices_char[i] = index_val\n",
    "    \n",
    "char_indices = dict((c, i) for i, c in (indices_char.items()))\n",
    "\n",
    "maxlen = 50 # maximum number of words in a sentence\n",
    "max_sentences = 15 # maximum number of sentence in a document\n",
    "\n",
    "X = np.zeros((len(docs_sents), max_sentences, maxlen), dtype=np.int32) \n",
    "y = np.array(docs_sents_y)\n",
    "\n",
    "for i, doc in enumerate(docs_sents):\n",
    "    for j, sentence in enumerate(doc):\n",
    "        if j < max_sentences:\n",
    "            len_sent = len(sentence) \n",
    "            if len_sent > maxlen:\n",
    "                sent = sentence[:maxlen]\n",
    "            else:\n",
    "                sent = sentence\n",
    "            \n",
    "            for t, char in enumerate(sent):\n",
    "                X[i, j, (maxlen - 1 - t)] = char_indices[char]\n",
    "\n",
    "X_val = np.zeros((len(val_docs_sents), max_sentences, maxlen), dtype=np.int32) \n",
    "y_val = np.array(val_docs_sents_y)\n",
    "\n",
    "for i, doc in enumerate(val_docs_sents):\n",
    "    for j, sentence in enumerate(doc):\n",
    "        if j < max_sentences:\n",
    "            len_sent = len(sentence) \n",
    "            if len_sent > maxlen:\n",
    "                sent = sentence[:maxlen]\n",
    "            else:\n",
    "                sent = sentence\n",
    "            \n",
    "            for t, char in enumerate(sent):\n",
    "                X_val[i, j, (maxlen - 1 - t)] = char_indices[char]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTg7KC88Q9kb"
   },
   "source": [
    "## CNN + RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Y6dqXZAlQ9kc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
    "from keras.layers import LSTM, Lambda, Bidirectional, concatenate, BatchNormalization\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QZWuAMtQ9ke"
   },
   "source": [
    "### Hierarchical input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OgnzPt3fQ9kg"
   },
   "outputs": [],
   "source": [
    "# sentence input\n",
    "in_sentence = Input(shape=(maxlen,), dtype='int32')\n",
    "\n",
    "# document input\n",
    "in_document = Input(shape=(max_sentences, maxlen), dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZOcjuqqQ9kk"
   },
   "source": [
    "### Sentence encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xdRM-VpQ9kn"
   },
   "source": [
    "#### One-hot projection layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be included:\n",
    "* Lambda layer as projection layer for mapping input into one hot encoding\n",
    "* Input for this lambda layer is `in_sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5jO0pJcQQ9kn"
   },
   "outputs": [],
   "source": [
    "char_embedded = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTfv-HWkQ9kr"
   },
   "source": [
    "#### Temporal Convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be included in this convolutional layer (Notice that we have 3 different filter length: iterate)\n",
    "\n",
    "* Conv1D layer: \n",
    "   - number filter : according to number filter for each filter length\n",
    "   - kernel size : according to filter length\n",
    "   - no padding\n",
    "   - activation : RELU\n",
    "   - kernel_initializer='glorot_normal'\n",
    "   - strides=1\n",
    "* Dropout layer\n",
    "* MaxPooling1D layer:\n",
    "   - pool_size: pool_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zGbTm_LyQ9ks"
   },
   "outputs": [],
   "source": [
    "encodes sentence by character sequences with CNN\n",
    "\n",
    "filter_length = [7, 5, 3]\n",
    "nb_filter = [64, 128, 256]\n",
    "pool_length = 2\n",
    "\n",
    "for i in range(len(nb_filter)):\n",
    "    char_embedded = # YOUR CODE HERE (Conv1D layer)\n",
    "\n",
    "    char_embedded = # YOUR CODE HERE (Dropout layer)\n",
    "    char_embedded = # YOUR CODE HERE (MaxPooling1D layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be included:\n",
    "* Bidirectional LSTM/GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7sPv1kRfQ9ku"
   },
   "outputs": [],
   "source": [
    "bilstm_sent = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 544,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1521565073411,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "FSiofm-6Q9ky",
    "outputId": "9b242390-3bf5-48e4-f4cc-0b7d9b6fc726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 50, 71)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 44, 64)            31872     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 44, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 18, 128)           41088     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 256)               394240    \n",
      "=================================================================\n",
      "Total params: 565,760\n",
      "Trainable params: 565,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sent_encoder = Model(inputs=in_sentence, outputs=bilstm_sent)\n",
    "sent_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYtzI-4ZQ9k1"
   },
   "source": [
    "### Document encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HBnSV5UTQ9k2"
   },
   "outputs": [],
   "source": [
    "encoded = TimeDistributed(sent_encoder)(in_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdiD6pkLQ9k5"
   },
   "source": [
    "### Document decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be included:\n",
    "* Bidirectional LSTM/GRU layer\n",
    "* Optional : Dropouts and Dense layer\n",
    "* Dense layer as prediction layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1521565081410,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "TJwguKevQ9k7",
    "outputId": "5ae376f4-41cd-49e4-810f-5b38063d6764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 15, 50)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 15, 256)           565760    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 993,025\n",
      "Trainable params: 993,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "model = Model(inputs=in_document, outputs=sentiment_prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "90Bms8BQQ9lB"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3rjD4P_hQ9lE"
   },
   "outputs": [],
   "source": [
    "X_train = X[:10000]\n",
    "y_train = y[:10000]\n",
    "\n",
    "X_valid = X_val[:5000]\n",
    "y_valid = y_val[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 411,
     "output_extras": [
      {
       "item_id": 95
      },
      {
       "item_id": 222
      },
      {
       "item_id": 357
      },
      {
       "item_id": 457
      },
      {
       "item_id": 461
      },
      {
       "item_id": 462
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 183199,
     "status": "ok",
     "timestamp": 1521565293347,
     "user": {
      "displayName": "Iftitahu Nimah",
      "photoUrl": "//lh5.googleusercontent.com/-2H8SGwD_zvc/AAAAAAAAAAI/AAAAAAAAPGY/qh04HjJj8ZQ/s50-c-k-no/photo.jpg",
      "userId": "111575679600498524578"
     },
     "user_tz": -60
    },
    "id": "gkCl5qFnQ9lI",
    "outputId": "06578ac3-7f40-483e-9b46-a9111fa9292e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.6938 - acc: 0.5042 - val_loss: 0.6930 - val_acc: 0.5080\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.4920\n",
      "Epoch 3/10\n",
      " 3968/10000 [==========>...................] - ETA: 9s - loss: 0.6935 - acc: 0.500010000/10000 [==============================] - 18s 2ms/step - loss: 0.6937 - acc: 0.5029 - val_loss: 0.6930 - val_acc: 0.5080\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.6935 - acc: 0.5053 - val_loss: 0.6902 - val_acc: 0.4960\n",
      "Epoch 5/10\n",
      " 9344/10000 [===========================>..] - ETA: 1s - loss: 0.6627 - acc: 0.604110000/10000 [==============================] - 18s 2ms/step - loss: 0.6572 - acc: 0.6116 - val_loss: 0.5857 - val_acc: 0.6864\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.5504 - acc: 0.7225 - val_loss: 0.5288 - val_acc: 0.7410\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.4429 - acc: 0.7931 - val_loss: 0.5015 - val_acc: 0.7506\n",
      "Epoch 8/10\n",
      "  576/10000 [>.............................] - ETA: 14s - loss: 0.3920 - acc: 0.842010000/10000 [==============================] - 18s 2ms/step - loss: 0.3859 - acc: 0.8287 - val_loss: 0.5289 - val_acc: 0.7552\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3223 - acc: 0.8606 - val_loss: 0.5799 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " 8640/10000 [========================>.....] - ETA: 2s - loss: 0.2648 - acc: 0.891810000/10000 [==============================] - 18s 2ms/step - loss: 0.2669 - acc: 0.8909 - val_loss: 0.5808 - val_acc: 0.7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75670a9780>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylqjMYkoQ9lP"
   },
   "source": [
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngg-DLHuQ9lR"
   },
   "source": [
    "#### CNN for character sequences: \n",
    "\n",
    "[1] Zhang, Xiang, and Yann LeCun. \"Text understanding from scratch.\" arXiv preprint arXiv:1502.01710 (2015). https://arxiv.org/pdf/1502.01710v5.pdf\n",
    "\n",
    "[2] Kim, Yoon. \"Convolutional neural networks for sentence classification.\" arXiv preprint arXiv:1408.5882 (2014). http://www.aclweb.org/anthology/D14-1181\n",
    "\n",
    "[3] Conneau, Alexis, et al. \"Very deep convolutional networks for text classification.\" Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. Vol. 1. 2017. http://www.aclweb.org/anthology/E17-1104\n",
    "\n",
    "#### CNN + LSTM for character sequences:\n",
    "\n",
    "[1] Vosoughi, Soroush, Prashanth Vijayaraghavan, and Deb Roy. \"Tweet2vec: Learning tweet embeddings using character-level cnn-lstm encoder-decoder.\" Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2016. https://arxiv.org/pdf/1607.07514.pdf\n",
    "\n",
    "[2] Kim, Yoon, et al. \"Character-Aware Neural Language Models.\" AAAI. 2016. https://arxiv.org/pdf/1508.06615.pdf "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Practical-6.0-solution.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
