{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_assignment_blank.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TONiNcxCgrPC",
        "colab_type": "text"
      },
      "source": [
        "# Question 1: Variational Autoencoder\n",
        "**Make sure you have read the theoretical assignment, and answered the questions there, before working on this practical assignment.**\n",
        "\n",
        "In this task, we will implement a Variational Autoencoder (VAE) step by step, using the model and results from the theoretical assignment. Some code is already provided, the task is to fill in the gaps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDZL3HpiOS79",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTn5y3IpOQN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Lambda, Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, BatchNormalization\n",
        "from keras.models import Model, load_model\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwIb7sAROYLj",
        "colab_type": "text"
      },
      "source": [
        "### Data\n",
        "We will train a VAE for the MNIST data. This code loads the data, and increases the canvas size to 32x32 by padding zeros. This makes it easier to design convolutional autoencoder architectures with striding or pooling/upsampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8EzVe91OxfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalise\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# change shape: (n, 28, 28) -> (n, 28, 28, 1)\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "# pad zeros to obtain canvas size of 32x32, i.e. shape is now (n, 32, 32, 1)\n",
        "x_train = np.pad(x_train, pad_width=((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\", constant_values=0)\n",
        "x_test = np.pad(x_test, pad_width=((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\", constant_values=0)\n",
        "\n",
        "# get height, width, and depth values\n",
        "height, width, depth = x_train.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fREKLbO12R",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.1: Encoder architecture\n",
        "**(a)** *Choose and implement a suitable architecture for the encoder. The encoder should have two outputs, which we will interpret as the mean and log variance of the approximate posterior distribution $q(z|x)$ (a Gaussian, as defined in the theoretical assignment). In this task, use a latent space dimension of 2 such that we can easily plot the latent space.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25uNluOUPAGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network parameters\n",
        "input_shape = (height, width, depth)\n",
        "latent_dim = 2\n",
        "\n",
        "\n",
        "# VAE model = encoder + decoder\n",
        "# build encoder model\n",
        "x_in = Input(shape=input_shape, name='encoder_input')\n",
        "\n",
        "#### INSERT CODE HERE\n",
        "...\n",
        "####\n",
        "\n",
        "z_mean = Dense(latent_dim, name='z_mean')(h)  # mean parameter of q(z|x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(h)  # log of variance parameter of q(z|x)\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(x_in, [z_mean, z_log_var], name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33N4zLJCifXR",
        "colab_type": "text"
      },
      "source": [
        "**(b)** *Motivate your choice of architecture.*\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcdqHXJJitXW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v-AuemKFs5O",
        "colab_type": "text"
      },
      "source": [
        "**(c)** *What is the reason to model the logarithm of the variance, instead of the variance (or standard deviation) itself?*\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMqk6sYVGEVu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9QVvgvdPy44",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.2: Decoder architecture\n",
        "**(a)** *Choose and implement a suitable architecture for the decoder. Input is a sample of latent variables, the output represents the parameters of the generative distribution $p(x|z)$, i.e. the mean of a Gaussian distribution (for continuous data) or Bernoulli distribution (for binary data).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_5CScG5P_53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build decoder model\n",
        "z_in = Input(shape=(latent_dim,), name='z_in')\n",
        "\n",
        "#### INSERT CODE HERE\n",
        "...\n",
        "####\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(z_in, dec_out, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PluBLCf8oljy",
        "colab_type": "text"
      },
      "source": [
        "**(b)** *Motivate your choice of architecture.*\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HP4dgPsonkx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE5XKb7QhB4q",
        "colab_type": "text"
      },
      "source": [
        "## Load previously trained encoder & decoder\n",
        "The following code should not be used the first time, if you haven't trained a VAE yet. After training a VAE, you can save your encoder & decoder model. This code can then be used to load these models again, such that you won't need to retrain a new model in each new session.\n",
        "\n",
        "Note that we only load the separate encoder & decoder model, not the entire VAE model. The reason for this is that the VAE will contain a lambda layer, and Keras can have trouble saving/loading models with lambda layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwdfcZp5gxK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: DO NOT RUN THIS CODE THE FIRST TIME! Only use this to load encoder\n",
        "#       and decoder models that you have trained before, to prevent having to\n",
        "#       train a new VAE from scratch in each new session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "encoder_path = \"/content/gdrive/My Drive/RecSys/vae_encoder_mnist.h5\"\n",
        "decoder_path = \"/content/gdrive/My Drive/RecSys/vae_decoder_mnist.h5\"\n",
        "\n",
        "encoder = load_model(encoder_path)\n",
        "decoder = load_model(decoder_path)\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "\n",
        "x_in = encoder.input\n",
        "z_mean, z_log_var = encoder.output\n",
        "latent_dim = int(z_mean.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecNxGd_UPFEa",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.3: Reparametrisation trick\n",
        "*To implement sampling with the reparametrisation trick, we will define a custom lambda layer. It takes the mean and log variance of $q(z|x)$ as input, and outputs a sample from $q(z|x)$. This is done by first sampling from a standard Gaussian (Normal) distribution, and then applying the proper transformation to obtain a sample from $q(z|x)$ with the given mean and variance. Implement this transformation.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRN2PIMqPeUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling(args):\n",
        "    \"\"\"Reparametrisation trick by sampling from an isotropic unit Gaussian.\n",
        "\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of q(z|x)\n",
        "\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "\n",
        "    z_mean, z_log_var = args\n",
        "    batch_dim = K.shape(z_mean)[0]\n",
        "    z_dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch_dim, z_dim))\n",
        "    \n",
        "    #### INSERT CODE HERE\n",
        "    return ...\n",
        "    ####\n",
        "\n",
        "\n",
        "# use reparametrisation trick to push the sampling out as input\n",
        "z = Lambda(sampling, name='z')([z_mean, z_log_var])\n",
        "\n",
        "\n",
        "# instantiate full VAE model\n",
        "x_mean = decoder(z)\n",
        "vae = Model(x_in, x_mean, name='vae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-serMp6YQMfI",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.4: Loss function\n",
        "*Now we define the loss function, which you have derived in the theoretical part of the assignment. Note: we wish to maximise the ELBO, but Keras formulates training objectives as a loss function to minimise, so the loss function is the negative ELBO:*\n",
        "$-\\mathbb{E}_{q_\\phi(z|x)} [\\log p_\\theta(x|z)] + KL(q_\\phi(z|x) || p(z))$.\n",
        "\n",
        "*We split this into two terms, the reconstruction loss and the KL loss.*\n",
        "\n",
        "\n",
        "### Reconstruction loss\n",
        "*We start with the first term: $-\\mathbb{E}_{q_\\phi(z|x)} [\\log p_\\theta(x|z)]$.*\n",
        "\n",
        "*We approximate the expectation with a single Monte Carlo sample (using the reparametrisation trick such that the loss function is differentiable), which we can readily obtain from the sampling layer of our encoder model (output `z`). So all you need to implement is the loss function $-\\log p_\\theta(x|z_{sample})$. You've derived the formula for this in the theoretical part of the assignment, for both a Bernoulli distribution (for discrete data) and a Gaussian distribution with fixed standard deviation (for continuous data). Implement both versions here. Choose a suitable standard deviation value for the Gaussian.*\n",
        "\n",
        "### KL loss\n",
        "*The second term of the loss is the KL Divergence $KL(q_\\phi(z|x) || p(z))$, which as we saw has a closed form for our choice of posterior and prior (both Gaussians):\n",
        "$ \\frac{1}{2} \\sum_{k=1}^K (m_k^2 + s_k^2 - \\log s_k^2 - 1)$ (see the theoretical part of the assignment for explanation of the notations). Implement it here.*\n",
        "\n",
        "\n",
        "##### Implementation notes:\n",
        "* Always use functions from the Keras backend (available through `from keras import backend as K`) for Tensor operations in your loss function. This way, Keras can perform automatic differentiation to compute the gradients for training. E.g. `K.sum(), K.square(), K.exp()`. You can use operators such as `+` and `*`, they will automatically convert to Tensor operations.\n",
        "* Make sure to use `K.flatten(x_in)` and `K.flatten(x_mean)` whenever you need them in your loss functions, don't use `x_in` or `x_mean`. The `(height, width, depth)` structure of the data is only needed for convolutional layers, but not in the loss function.\n",
        "* Note that the formulas you derived in the theoretical assignment are for a single data point or latent variable. Keras however expects a batch of data points or latent variables, so the first dimension in a Tensor is always the batch dimension. For most operations, broadcasting will automatically make computations operate on each data point in a batch individually, but for operations such as `K.sum` you need to make sure you specify the correct axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCpi9zCTmxmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reconstruction loss\n",
        "gen_model = \"gaussian\"  # \"bernoulli\" or \"gaussian\"\n",
        "\n",
        "if gen_model == \"bernoulli\":\n",
        "    #### insert code here\n",
        "    reconstruction_loss = ...\n",
        "    ####\n",
        "elif gen_model == \"gaussian\":\n",
        "    #### insert code here\n",
        "    dec_std = 1 / math.sqrt(2)\n",
        "    reconstruction_loss = ...\n",
        "    ####\n",
        "\n",
        "\n",
        "# KL loss\n",
        "#### insert code here\n",
        "kl_loss = ...\n",
        "####\n",
        "\n",
        "# combine both losses\n",
        "vae_loss = reconstruction_loss + kl_loss\n",
        "# we use .add_loss instead of including a loss function in .compile, such that\n",
        "#     we don't have to supply any \"true labels\", as training is unsupervised\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipMseQFctElS",
        "colab_type": "text"
      },
      "source": [
        "## Task 1.5: Training & evaluating the model\n",
        "*Train the model for 50 epochs with batch size 100. Choose whether to use the Bernoulli or Gaussian generative distribution. On Google Colab, go to Edit > Notebook settings and make sure to select \"GPU\" as hardware accelerator.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6tj2fZZN4Mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 50\n",
        "\n",
        "# train the autoencoder\n",
        "vae.fit(x_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amZQDJoWl2SZ",
        "colab_type": "text"
      },
      "source": [
        "Save the trained encoder and decoder for later use, so you don't have to retrain it for every new session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkmS1Z9El10m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.makedirs('/content/gdrive/My Drive/RecSys/', exist_ok=True)\n",
        "encoder_path = \"/content/gdrive/My Drive/RecSys/vae_encoder_mnist.h5\"\n",
        "decoder_path = \"/content/gdrive/My Drive/RecSys/vae_decoder_mnist.h5\"\n",
        "\n",
        "encoder.save(encoder_path)\n",
        "decoder.save(decoder_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLWolFYTugRC",
        "colab_type": "text"
      },
      "source": [
        "*Use the following functions to generate plots of the latent space (note that they only work for a 2-dimensional latent space).*\n",
        "\n",
        "*The first plot shows the mean representations in latent space for data points from the test set. Although VAEs are unsupervised, we do have label information for the MNIST data, so we can use this give data points a different colour depending on their label.*\n",
        "\n",
        "*The second plot takes linearly spaced coordinates in latent space, decodes them into data space representations, and plots them in a grid according to the latent space coordinates. So each of the images are generated, not reconstructed from data.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk0NZBPVOHzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "def plot_results(encoder, decoder,\n",
        "                 x_test, y_test,\n",
        "                 batch_size=128):\n",
        "    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n",
        "\n",
        "    # Arguments\n",
        "        encoder (keras Model): encoder model\n",
        "        decoder (keras Model): decoder model\n",
        "        x_test (np.array): test data\n",
        "        y_test (np.array): test labels\n",
        "        batch_size (int): prediction batch size\n",
        "    \"\"\"\n",
        "\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _ = encoder.predict(x_test,\n",
        "                                   batch_size=batch_size)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "\n",
        "    # display a 30x30 2D manifold of digits\n",
        "    n = 30\n",
        "    digit_size = x_test.shape[1]  # assume square images, i.e. height == width\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-4, 4, n)\n",
        "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = decoder.predict(z_sample)\n",
        "            x_decoded = np.reshape(x_decoded, (x_decoded.shape[0], -1))\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size: (i + 1) * digit_size,\n",
        "                   j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range + 1\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap='Greys_r')\n",
        "    plt.show()\n",
        "\n",
        "# plot results\n",
        "plot_results(encoder, decoder,\n",
        "             x_test, y_test,\n",
        "             batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4_DDpcEwz8a",
        "colab_type": "text"
      },
      "source": [
        "*These latent space plots can give an insight into the (latent) representations that are learned by the VAE. Evaluate what you see:*\n",
        "\n",
        "**(a)** *Did you successfully train a generative model for this data? Motivate your answer.*\n",
        "\n",
        "\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmFhA6dpnxWI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbC-eWiDnxZ5",
        "colab_type": "text"
      },
      "source": [
        "**(b)** *Discuss how the latent space is populated by the test data. What happens in \"gaps\" in the latent space? I.e. areas in latent space near the origin (so with high prior likelihood) but without any data points being mapped to them. What do images generated from such latent points look like?*\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqQWzmB75X7R",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5juKi05LoUWB",
        "colab_type": "text"
      },
      "source": [
        "# Question 2: FashionMNIST VAE, semi-supervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yjgvJM19-7g",
        "colab_type": "text"
      },
      "source": [
        "In this question, we will investigate the usefulness of VAE latent representations in semi-supervised learning. Since the VAE is an unsupervised method, we don't need any labels to learn latent representations. Often, it is easy to obtain a lot of unlabelled data, but labelling this data is expensive. Thus, methods that can leverage unsupervised training to learn a supervised goal (such as classification) may be very powerful. This is the idea behind semi-supervised learning.\n",
        "\n",
        "You will evaluate this on the FashionMNIST dataset. Although all labels are available for this dataset, we can \"hide\" some labels from a model, simply by not using all of them.\n",
        "\n",
        "Besides representations learned with a VAE, you will also compare with another representation learning method: a denoising autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIJEQSA_G0c0",
        "colab_type": "text"
      },
      "source": [
        "## Task 2.1: Unsupervised training\n",
        "**(a)** *Train two representation learning methods on the FashionMNIST dataset; a variational autoencoder (VAE) and a denoising autoencoder. Choose a suitable architecture, and encoding/latent dimension (hint: for good results a dimension of 2 will likely be too small). For fairness, use similar architectures for each of the models.*\n",
        "\n",
        "*Use each of the models to obtain encoded representations for the full dataset (training and test set).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhG4QXJ2Miye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### insert code here\n",
        "\n",
        "####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjI2sgQ7zlBN",
        "colab_type": "text"
      },
      "source": [
        "**(b)** *Motivate your architectural choices.*\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H8U1Z_IKjo1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viSTJbhbXTcm",
        "colab_type": "text"
      },
      "source": [
        "## Task 2.2: Qualitative evaluation\n",
        "Plotting the population of the latent space only works for a 2-dimensional latent space. For higher dimensions, we need different ways to qualitatively evaluate the models.\n",
        "\n",
        "**(a)** *Reconstruct some images from the test set with both the VAE and DAE. Plot the reconstructions alongside the original images. Briefly discuss the results.*\n",
        "\n",
        "**(b)** *The VAE is a generative model; generate some images with the VAE and visualise them. Also try to generate images with the DAE (even though it is not intended as a generative model) and visualise them. Discuss the results, in particular the difference between VAE and DAE.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzuSt9KjXTtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### insert code here\n",
        "\n",
        "####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUC-xLHHfa8Q",
        "colab_type": "text"
      },
      "source": [
        "*Discuss the results:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aQW6ETbfc1l",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw6n7iOpzqXM",
        "colab_type": "text"
      },
      "source": [
        "## Task 2.3: Semi-supervised learning\n",
        "*Perform a thorough evaluation of semi-supervised learning for representations learned with your variational and denoising autoencoders.*\n",
        "\n",
        "*Guidelines:*\n",
        "* For various suitable values of $l$, randomly select $l$ instances from the training dataset, these will represent your labelled data and are the only data points that may be used for supervised learning. Make sure to include $l=60000$ (i.e. the entire dataset).\n",
        "* For each value of $l$, train a few off-the-shelf methods from scikit-learn (e.g. random forest, SVM) as well as a simple multilayer perception (MLP) on representations from both the VAE and DAE, using only the $l$ available labels.\n",
        "* For each value of $l$, also train an MLP on the original image data, using only the $l$ available labels.\n",
        "* Visualise your results in a clear way, and report your conclusions. Was it beneficial to use unlabelled data as well as labelled data? Which representations worked best?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPeLQ4uMlX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### insert code here\n",
        "\n",
        "####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuQKnLlZKYkW",
        "colab_type": "text"
      },
      "source": [
        "**Motivation & Conclusions:** *Explain your analysis, and draw conclusions:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7LhYwWfKh6s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}