{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3.2. Image Caption Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an image caption generator model, as described in Vinyals, Oriol, et al. \"Show and tell: A neural image caption generator.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2015. The model shall consist of:\n",
    "\n",
    "- Image encoder (image feature extractor)\n",
    "- Caption generator (RNN-based)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13GNLSaWu7np"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image input\n",
    "image_in = Input(shape=(2048,), name='image_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image encoder\n",
    "fe1 = Dropout(0.5, name='dropout_img_feats')(image_in)\n",
    "image_dense = Dense(rnn_dim, activation='relu', name = 'dense_img_feats')\n",
    "fe2 = image_dense(fe1) # reduce the dimension with FC projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption input\n",
    "cap_in = ### YOUR CODE HERE\n",
    "\n",
    "# caption embedding representation (word-based embedding)\n",
    "embed_cap = ### YOUR CODE HERE\n",
    "\n",
    "# state input for each decoder time step\n",
    "s0 = Input(shape=(rnn_dim,), name='s0') # with a dimension of (, rnn_dim)\n",
    "s = [s0]\n",
    "\n",
    "# LSTM/GRU decoder as caption generator\n",
    "decoder = ### YOUR CODE HERE\n",
    "\n",
    "# Prediction layer with softmax activation\n",
    "pred_layer = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "\n",
    "# process the training per time step (following the max length of captions)\n",
    "for t in range(decoder_length):\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    ### ... HOW DO YOU REPRESENT JOINT-REPRESENTATION OF IMAGE-CAPTION AS DECODER INPUT? \n",
    "    \n",
    "    ### ... HOW DO YOU INITIALIZE THE RNN-BASED DECODER STATE IN TIME STEP=0? \n",
    "    \n",
    "    if t == 0:\n",
    "        \n",
    "    ### ... WHAT IS THE INPUT OF THE DECODER? \n",
    "    \n",
    "    \n",
    "    s, _ = ### YOUR CODE HERE\n",
    "    \n",
    "    # softmax probability output\n",
    "    prob = pred_layer(s)\n",
    "    \n",
    "    probs.append(prob)\n",
    "    s = [s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model shall be constructed based on the following inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "model = Model(inputs=[image_in, cap_in, s0], outputs=probs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the completed encoder-decoder, build a decoder model for generating captions using two approaches:\n",
    "- Greedy search\n",
    "- Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Doc_level_model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
