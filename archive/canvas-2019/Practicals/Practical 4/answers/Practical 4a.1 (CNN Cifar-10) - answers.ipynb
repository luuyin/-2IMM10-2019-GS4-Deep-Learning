{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA (Cifar-10)\n",
    "We obtain the Cifar-10 dataset directly through Keras, given as fully labelled training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example is an image of 32x32 pixels, given as triples (RGB) of integer values from 0 to 255. Each example has a label, an integer 0 to 9. The training set contains 50,000 examples, the test set 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each label is in fact an array of length one, as opposed to a simple integer (as it was for MNIST). To solve this, we flatten the label sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each label represents a different class:\n",
    "\n",
    "0: airplane\t\t\t\t\t\t\t\t\t\t\n",
    "1: automobile\t\t\t\t\t\t\t\t\t\t\n",
    "2: bird\t\t\t\t\t\t\t\t\t\t\n",
    "3: cat\t\t\t\t\t\t\t\t\t\t\n",
    "4: deer\t\t\t\t\t\t\t\t\t\t\n",
    "5: dog\t\t\t\t\t\t\t\t\t\t\n",
    "6: frog\t\t\t\t\t\t\t\t\t\t\n",
    "7: horse\t\t\t\t\t\t\t\t\t\t\n",
    "8: ship\t\t\t\t\t\t\t\t\t\t\n",
    "9: truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to quickly visualise some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_id = 0  # pick any integer from 0 to 49999 to visualize a training example\n",
    "example = x_train[example_id]\n",
    "label = y_train[example_id]\n",
    "print(\"Class label:\", class_labels[label])\n",
    "plt.imshow(example)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cifar-10 images have 32\\*32 pixels, with 3 channels each (RGB), and belong to one of 10 possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, chns = 32, 32, 3\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are going to build a convolutional neural network that starts with convolutional layers. The shape expected by such layers depends on the settings of the backend used with Keras.\n",
    "* The channel values are given by integer values from 0 to 255, we normalise this to obtain float values from 0 to 1.\n",
    "* Labels are given as values 0 to 9, but here we need so-called \"one-hot\" encodings, e.g. 3 becomes [0,0,0,1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], chns, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], chns, img_rows, img_cols)\n",
    "    input_shape = (chns, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, chns)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, chns)\n",
    "    input_shape = (img_rows, img_cols, chns)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "example one-hot encoding: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"example one-hot encoding:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture & settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a CNN with two Convolutional layers, followed by MaxPooling, followed by some Dense layers (with Dropout).\n",
    "* Initialise a Keras Sequential Model\n",
    "* Add a Convolutional layer (with a 3x3 kernel and ReLU activations), followed by Batch Normalization and Dropout. The first layer must explicitly receive the shape of the input, following layers can do automatice shape inference.\n",
    "* Add another Convolutional layer, followed by a single MaxPooling layer (with a 2x2 patch) for down-scaling, and then again Batch Normalization and Dropout. \n",
    "* We now wish to add Dense layers, but those expect samples to be given as (flat) vectors. To transform the data into this shape we use the Flatten layer. We then add a Dense layer, Batch Normalization, Dropout, and a final Dense layer with softmax activation to obtain class probabilities/predictions.\n",
    "* Optional: print a summary of the model\n",
    "* Compile the model with the following settings:\n",
    "    * use the \"adam\" optimizer to train the model\n",
    "    * MNIST is a multi-class classification problem, use categorical cross entropy loss function\n",
    "    * output accuracy (% of correctly classified instances) when evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cocuser\\AppData\\Local\\Continuum\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\cocuser\\AppData\\Local\\Continuum\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,627,338\n",
      "Trainable params: 1,626,890\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Train the model (using stochastic gradient descent) with given batch size, for given number of epochs. We split of 1/10-th of the data (5,000 of the 50,000 samples) as validation data, such that we can use the validation accuracy for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cocuser\\AppData\\Local\\Continuum\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 1.7197 - acc: 0.4180 - val_loss: 1.3558 - val_acc: 0.5198\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 1.2436 - acc: 0.5586 - val_loss: 1.5970 - val_acc: 0.4820\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 1.0938 - acc: 0.6122 - val_loss: 1.1953 - val_acc: 0.5874\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 1.0221 - acc: 0.6379 - val_loss: 1.3118 - val_acc: 0.5602\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.9692 - acc: 0.6599 - val_loss: 1.0298 - val_acc: 0.6494\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.9215 - acc: 0.6767 - val_loss: 0.9542 - val_acc: 0.6682\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.8837 - acc: 0.6888 - val_loss: 0.8770 - val_acc: 0.6930\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.8572 - acc: 0.6975 - val_loss: 0.8489 - val_acc: 0.7046\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 7s 162us/step - loss: 0.8281 - acc: 0.7079 - val_loss: 0.8430 - val_acc: 0.7034\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 7s 162us/step - loss: 0.8040 - acc: 0.7174 - val_loss: 0.8463 - val_acc: 0.7126\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 7s 164us/step - loss: 0.7840 - acc: 0.7229 - val_loss: 0.8063 - val_acc: 0.7156\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.7593 - acc: 0.7318 - val_loss: 0.8479 - val_acc: 0.7176\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.7454 - acc: 0.7369 - val_loss: 0.8912 - val_acc: 0.7038\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 7s 163us/step - loss: 0.7211 - acc: 0.7448 - val_loss: 0.7549 - val_acc: 0.7468\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 7s 163us/step - loss: 0.7060 - acc: 0.7484 - val_loss: 0.9275 - val_acc: 0.6912\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 7s 162us/step - loss: 0.6958 - acc: 0.7552 - val_loss: 0.7898 - val_acc: 0.7274\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 7s 163us/step - loss: 0.6816 - acc: 0.7598 - val_loss: 0.7751 - val_acc: 0.7338\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.6632 - acc: 0.7646 - val_loss: 0.7524 - val_acc: 0.7438\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.6514 - acc: 0.7693 - val_loss: 0.9065 - val_acc: 0.7028\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 7s 162us/step - loss: 0.6491 - acc: 0.7684 - val_loss: 0.7522 - val_acc: 0.7456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25225db2438>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model using the test set, obtaining the test loss and accuracy (% examples correctly classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7874380835533142\n",
      "Test accuracy: 0.7347\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Saving the model\n",
    "We save the model to a .h5 file, such that we can load it later in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"models\", \"cnn_cifar10.h5\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
