{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical-5.1.3-Aspect-Level-Sentiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "uaWk1GuHvpB1",
        "-ZIcsq-SvpCF"
      ]
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph91TE5lvthU",
        "colab_type": "code",
        "outputId": "b1bb839b-5ddc-45ba-96aa-3f359a11f96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7BivIvvvzaW",
        "colab_type": "code",
        "outputId": "3f1c0e75-f429-4feb-9f71-46e2191759e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# You will need to change the following directory path according to your own path\n",
        "#cd drive/My Drive/Recsys-2019/sequence_classifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Recsys-2019/sequence_classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P0VnIJhDRpvc",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import operator\n",
        "import numpy as np\n",
        "import re\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM1cs7o-vpAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import _pickle as cPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPslRReavpAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aspect_path = 'data/aspect_level-sentiment/aspect_level'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkm19_52vpAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_path = 'data/doc_level-sentiment/doc_level'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gl50euzvDcQP",
        "colab": {}
      },
      "source": [
        "### Reading preprocess data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sk_RKQSvpAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_pickle(data_path, file_name):\n",
        "\n",
        "    f = open(os.path.join(data_path, file_name), 'rb')\n",
        "    read_file = cPickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    return read_file\n",
        "\n",
        "def save_pickle(data_path, file_name, data):\n",
        "\n",
        "    f = open(os.path.join(data_path, file_name), 'wb')\n",
        "    cPickle.dump(data, f)\n",
        "    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwVGqOSavpAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n",
        "\n",
        "train_x = read_pickle(aspect_path, 'train_x.pkl')\n",
        "train_y = read_pickle(aspect_path, 'train_y.pkl')\n",
        "dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n",
        "dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n",
        "test_x = read_pickle(aspect_path, 'test_x.pkl')\n",
        "test_y = read_pickle(aspect_path, 'test_y.pkl')\n",
        "\n",
        "train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n",
        "dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n",
        "test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n",
        "\n",
        "\n",
        "pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n",
        "pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBmfsDKdvpAu",
        "colab_type": "text"
      },
      "source": [
        "### Batch generator and data iterator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_b-5_EPvpAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataiterator():\n",
        "    '''\n",
        "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
        "      2) Access to the entire dataset using all()\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, aspect_data, doc_data, seq_length=32, decoder_dim=300, batch_size=32):\n",
        "        \n",
        "        len_aspect_data = len(aspect_data[0])\n",
        "        len_doc_data = len(doc_data[0])\n",
        "        \n",
        "        self.X_aspect = aspect_data[0] \n",
        "        self.y_aspect = aspect_data[1]\n",
        "        self.aspect_terms = aspect_data[2]\n",
        "        \n",
        "        self.X_doc = doc_data[0]\n",
        "        self.y_doc = doc_data[1]\n",
        "        \n",
        "        self.num_data = len_aspect_data\n",
        "        self.batch_size = batch_size # batch size\n",
        "        self.reset() # initial: shuffling examples and set index to 0\n",
        "    \n",
        "    def __iter__(self): # iterates data\n",
        "        return self\n",
        "\n",
        "\n",
        "    def reset(self): # initials\n",
        "        self.idx = 0\n",
        "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
        "        \n",
        "    def __next__(self): # return model inputs - outputs per batch\n",
        "        \n",
        "        X_ids = [] # hold ids per batch \n",
        "        while len(X_ids) < self.batch_size:\n",
        "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
        "            X_ids.append(X_id)\n",
        "            self.idx += 1 # \n",
        "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
        "                self.reset()\n",
        "                raise StopIteration()\n",
        "                \n",
        "        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n",
        "        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n",
        "        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n",
        "        batch_X_doc = self.X_doc[np.array(X_ids)]\n",
        "        batch_y_doc = self.y_doc[np.array(X_ids)]\n",
        "        \n",
        "        \n",
        "        return batch_X_aspect, batch_y_aspect, batch_aspect_terms, batch_X_doc, batch_y_doc\n",
        "\n",
        "          \n",
        "    def all(self): # return all data examples\n",
        "        return self.X_aspect, self.y_aspect, self.aspect_terms, self.X_doc, self.y_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sklA6jSUWDS6"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vDU0hXVJ1PR5",
        "outputId": "ab8e3451-535f-45ea-d678-3178dc939b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM\n",
        "from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pvg-Uf2h_6Qm",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dnbn0_O0XlGf"
      },
      "source": [
        "### Attention Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yraOrwX3vpA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overal_maxlen = 82\n",
        "overal_maxlen_aspect = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zjiAsayW1zx9",
        "colab": {}
      },
      "source": [
        "def custom_softmax(x, axis=1):\n",
        "            \"\"\"Softmax activation function.\n",
        "            # Arguments\n",
        "                x : Tensor.\n",
        "                axis: Integer, axis along which the softmax normalization is applied.\n",
        "            # Returns\n",
        "                Tensor, output of softmax transformation.\n",
        "            # Raises\n",
        "                ValueError: In case `dim(x) == 1`.\n",
        "            \"\"\"\n",
        "            ndim = K.ndim(x)\n",
        "            if ndim == 2:\n",
        "                return K.softmax(x)\n",
        "            elif ndim > 2:\n",
        "                e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "                s = K.sum(e, axis=axis, keepdims=True)\n",
        "                return e / s\n",
        "            else:\n",
        "                raise ValueError('Cannot apply softmax to a tensor that is 1D')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bp5xh27GXmva",
        "colab": {}
      },
      "source": [
        "repeator = RepeatVector(overal_maxlen, name='repeator_att')\n",
        "concatenator = Concatenate(axis=-1, name='concator_att')\n",
        "densor1 = Dense(300, activation = \"tanh\", name='densor1_att')\n",
        "densor2 = Dense(1, activation = \"relu\", name='densor2_att')\n",
        "activator = Activation(custom_softmax, name='attention_weights')\n",
        "dotor = Dot(axes = 1, name='dotor_att')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VH3g4z6R8O3_",
        "colab": {}
      },
      "source": [
        "def attention(keys, query):\n",
        "    \n",
        "    query = repeator(query)\n",
        "    print(\"query shape: %s\" %str(query._keras_shape))\n",
        "    concat = concatenator([keys, query])\n",
        "    print(\"concat shape: %s\" %str(concat._keras_shape))\n",
        "    e1 = densor1(concat)\n",
        "    print(\"e1 shape: %s\" %str(e1._keras_shape))\n",
        "    e2 = densor2(e1)\n",
        "    print(\"e2 shape: %s\" %str(e2._keras_shape))\n",
        "    alphas = activator(e2)\n",
        "    print(\"alphas shape: %s\" %str(alphas._keras_shape))\n",
        "    context = dotor([alphas, keys])\n",
        "    print(\"context shape: %s\" %str(context._keras_shape))\n",
        "    \n",
        "    return context, alphas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVmvIn0X_0Ji",
        "colab": {}
      },
      "source": [
        "class Average(Layer):\n",
        "  \n",
        "    def __init__(self, mask_zero=True, **kwargs):\n",
        "        self.mask_zero = mask_zero\n",
        "        self.supports_masking = True\n",
        "        super(Average, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        if self.mask_zero:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            mask = K.expand_dims(mask)\n",
        "            x = x * mask\n",
        "            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n",
        "        else:\n",
        "            return K.mean(x, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "    \n",
        "    def compute_mask(self, x, mask):\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TsyFHokczuvO"
      },
      "source": [
        "### Main model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBdo6q2QvpBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = 0.5     \n",
        "recurrent_dropout = 0.1\n",
        "vocab_size = len(vocab)\n",
        "num_outputs = 3 # labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQVV-MRRvpBc",
        "colab_type": "text"
      },
      "source": [
        "### Inputs: How many inputs do you need for the current task?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ7tv-7GvpBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Inputs #####\n",
        "sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')\n",
        "aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input')\n",
        "pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58PLwihDvpBk",
        "colab_type": "text"
      },
      "source": [
        "### Word-level embedding (shareable between all model inputs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJxzja4GvpBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### construct word embedding layer #####\n",
        "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaWk1GuHvpB1",
        "colab_type": "text"
      },
      "source": [
        "### Aspect-level representation (averaged)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9q7v6TyvpB2",
        "colab_type": "code",
        "outputId": "e884be8c-b75c-4959-94de-de9208e5318f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "### represent aspect as averaged word embedding ###\n",
        "print ('use average term embs as aspect embedding')\n",
        "aspect_term_embs = word_emb(aspect_input)\n",
        "aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use average term embs as aspect embedding\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7hkr5k9vpCA",
        "colab_type": "code",
        "outputId": "2f7c7bbb-0d07-476f-ac8b-013d6211ee61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "aspect_embs.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(300)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZIcsq-SvpCF",
        "colab_type": "text"
      },
      "source": [
        "### Sentence-level representation from two domains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRCN6JX4vpCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sentence representation ###\n",
        "sentence_embs = word_emb(sentence_input) # from aspect-level domain\n",
        "pretrain_embs = word_emb(pretrain_input) # from document-level domain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wvA7CahvpCL",
        "colab_type": "text"
      },
      "source": [
        "### LSTM layer (shared between three representations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEJg_StjvpCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout, name='lstm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JpWf9bQvpCR",
        "colab_type": "code",
        "outputId": "0ce77402-d166-4615-908a-48da1e722f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "sentence_lstm = rnn(sentence_embs)\n",
        "pretrain_lstm = rnn(pretrain_embs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtrvodzrvpCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNCOMMENT REPLACE KEYS?, QUERY? WITH THE CORRESPONDING TENSORS AS ATTENTION KEYS AND QUERY\n",
        "\n",
        "#att_context, att_weights = attention(KEYS?, QUERY?)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnYbFaqPvpCX",
        "colab_type": "code",
        "outputId": "eb2d8e70-bb2a-4702-a544-a400483c1e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "att_context, att_weights = attention(sentence_lstm, aspect_embs)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "query shape: (None, 82, 300)\n",
            "concat shape: (None, 82, 600)\n",
            "e1 shape: (None, 82, 300)\n",
            "e2 shape: (None, 82, 1)\n",
            "alphas shape: (None, 82, 1)\n",
            "context shape: (None, 1, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmAFYpc5vpCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrain_avg = Average(mask_zero=True)(pretrain_lstm)\n",
        "\n",
        "sentence_output = Dense(num_outputs, name='dense_1')(att_context)\n",
        "pretrain_output = Dense(num_outputs, name='dense_2')(pretrain_avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAlpreOvvpCd",
        "colab_type": "code",
        "outputId": "10928f38-6fdf-427a-93b5-4b823f903a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"sentence_output shape: %s\" % str(sentence_output._keras_shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_output shape: (None, 1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T74EglluvpCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_output = Reshape((num_outputs,))(sentence_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAFar6sZvpCl",
        "colab_type": "code",
        "outputId": "7d5ec568-cd98-4424-a7f6-2d0aa09e01d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"sentence_output shape: %s\" % str(sentence_output._keras_shape))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_output shape: (None, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_EmohJBvpCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aspect_probs = Activation('softmax', name='aspect_model')(sentence_output)\n",
        "doc_probs = Activation('softmax', name='pretrain_model')(pretrain_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c6ptr7iuWIYT",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[sentence_input, aspect_input, pretrain_input], outputs=[aspect_probs, doc_probs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bmPSF8IAENj_",
        "colab": {}
      },
      "source": [
        "import keras.optimizers as opt\n",
        "\n",
        "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eiFkEy-eVtoU",
        "outputId": "8c9e5287-3925-4dd9-dfd1-b90556de7444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "sentence_input (InputLayer)     (None, 82)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "aspect_input (InputLayer)       (None, 7)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n",
            "                                                                 sentence_input[0][0]             \n",
            "                                                                 pretrain_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     multiple             721200      word_emb[1][0]                   \n",
            "                                                                 word_emb[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "repeator_att (RepeatVector)     (None, 82, 300)      0           aspect_emb[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concator_att (Concatenate)      (None, 82, 600)      0           lstm[0][0]                       \n",
            "                                                                 repeator_att[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "densor1_att (Dense)             (None, 82, 300)      180300      concator_att[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "densor2_att (Dense)             (None, 82, 1)        301         densor1_att[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "pretrain_input (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_weights (Activation)  (None, 82, 1)        0           densor2_att[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dotor_att (Dot)                 (None, 1, 300)       0           attention_weights[0][0]          \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1, 3)         903         dotor_att[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_1 (Average)             (None, 300)          0           lstm[1][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 3)            0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            903         average_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "aspect_model (Activation)       (None, 3)            0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pretrain_model (Activation)     (None, 3)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,904,507\n",
            "Trainable params: 3,904,507\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaNcPdHiC650",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss={'aspect_model': 'categorical_crossentropy', 'pretrain_model': 'categorical_crossentropy'},\n",
        "              loss_weights = {'aspect_model': 1, 'pretrain_model': 0.1},\n",
        "              metrics = {'aspect_model': 'categorical_accuracy', 'pretrain_model': 'categorical_accuracy'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ilIKUGn_DEgB"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xi0coTFsDWFG",
        "colab": {}
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xETYnVpgvpC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a78fe0ea-c4b5-4e56-bcf1-dde8b86ae5ef"
      },
      "source": [
        "pretrain_data.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HviIfa5lvpC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrain_data= np.array(pretrain_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Y3_eO4QgyC3",
        "colab": {}
      },
      "source": [
        "train_steps_epoch = len(train_x)/batch_size\n",
        "batch_train_iter = Dataiterator([train_x, train_y, train_aspect], \\\n",
        "                                [pretrain_data, pretrain_label], batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NvFUoJlvpDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_steps_epoch = len(dev_x)/batch_size\n",
        "batch_val_iter = Dataiterator([dev_x, dev_y, dev_aspect], \\\n",
        "                              [pretrain_data, pretrain_label], batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVb-obDevpDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def train_generator(model, batch_train_iter, batch_val_iter):\n",
        "    \n",
        "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
        "                                     monitor='val_loss', save_best_only=False, \\\n",
        "                                     save_weights_only=True)\n",
        "                     ]\n",
        "    \n",
        "    def train_gen():\n",
        "        while True:\n",
        "            train_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n",
        "                             aspect, pretrain_X, pretrain_y in batch_train_iter]\n",
        "            for train_batch in train_batches:\n",
        "                yield train_batch\n",
        "                \n",
        "    def val_gen():\n",
        "        while True:\n",
        "            val_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n",
        "                           aspect, pretrain_X, pretrain_y in batch_val_iter]\n",
        "            for val_batch in val_batches:\n",
        "                yield val_batch\n",
        "                \n",
        "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
        "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
        "                                  epochs = 20, callbacks = earlystop_callbacks)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFyKY0ngvpDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "5ca95149-6314-4d5f-e342-63072dd11960"
      },
      "source": [
        "train_generator(model, batch_train_iter, batch_val_iter)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/20\n",
            "58/57 [==============================] - 82s 1s/step - loss: 1.1186 - aspect_model_loss: 1.0475 - pretrain_model_loss: 0.7114 - aspect_model_categorical_accuracy: 0.5178 - pretrain_model_categorical_accuracy: 0.7748 - val_loss: 0.9623 - val_aspect_model_loss: 0.8971 - val_pretrain_model_loss: 0.6519 - val_aspect_model_categorical_accuracy: 0.6375 - val_pretrain_model_categorical_accuracy: 0.7771\n",
            "Epoch 2/20\n",
            "58/57 [==============================] - 74s 1s/step - loss: 0.8389 - aspect_model_loss: 0.7805 - pretrain_model_loss: 0.5834 - aspect_model_categorical_accuracy: 0.6945 - pretrain_model_categorical_accuracy: 0.7915 - val_loss: 0.9419 - val_aspect_model_loss: 0.8880 - val_pretrain_model_loss: 0.5391 - val_aspect_model_categorical_accuracy: 0.6583 - val_pretrain_model_categorical_accuracy: 0.7875\n",
            "Epoch 3/20\n",
            "58/57 [==============================] - 81s 1s/step - loss: 0.7267 - aspect_model_loss: 0.6706 - pretrain_model_loss: 0.5610 - aspect_model_categorical_accuracy: 0.7344 - pretrain_model_categorical_accuracy: 0.7899 - val_loss: 1.0020 - val_aspect_model_loss: 0.9426 - val_pretrain_model_loss: 0.5934 - val_aspect_model_categorical_accuracy: 0.6062 - val_pretrain_model_categorical_accuracy: 0.7708\n",
            "Epoch 4/20\n",
            "58/57 [==============================] - 77s 1s/step - loss: 0.6384 - aspect_model_loss: 0.5864 - pretrain_model_loss: 0.5204 - aspect_model_categorical_accuracy: 0.7818 - pretrain_model_categorical_accuracy: 0.8050 - val_loss: 1.0512 - val_aspect_model_loss: 0.9914 - val_pretrain_model_loss: 0.5978 - val_aspect_model_categorical_accuracy: 0.6125 - val_pretrain_model_categorical_accuracy: 0.7667\n",
            "Epoch 5/20\n",
            "58/57 [==============================] - 58s 992ms/step - loss: 0.5856 - aspect_model_loss: 0.5361 - pretrain_model_loss: 0.4948 - aspect_model_categorical_accuracy: 0.7990 - pretrain_model_categorical_accuracy: 0.8060 - val_loss: 1.0514 - val_aspect_model_loss: 1.0031 - val_pretrain_model_loss: 0.4825 - val_aspect_model_categorical_accuracy: 0.5604 - val_pretrain_model_categorical_accuracy: 0.7979\n",
            "Epoch 6/20\n",
            "58/57 [==============================] - 61s 1s/step - loss: 0.5101 - aspect_model_loss: 0.4651 - pretrain_model_loss: 0.4494 - aspect_model_categorical_accuracy: 0.8281 - pretrain_model_categorical_accuracy: 0.8276 - val_loss: 1.1131 - val_aspect_model_loss: 1.0676 - val_pretrain_model_loss: 0.4558 - val_aspect_model_categorical_accuracy: 0.5938 - val_pretrain_model_categorical_accuracy: 0.8187\n",
            "Epoch 7/20\n",
            "58/57 [==============================] - 78s 1s/step - loss: 0.5206 - aspect_model_loss: 0.4748 - pretrain_model_loss: 0.4572 - aspect_model_categorical_accuracy: 0.8206 - pretrain_model_categorical_accuracy: 0.8287 - val_loss: 1.1729 - val_aspect_model_loss: 1.1270 - val_pretrain_model_loss: 0.4584 - val_aspect_model_categorical_accuracy: 0.5771 - val_pretrain_model_categorical_accuracy: 0.8187\n",
            "Epoch 8/20\n",
            "58/57 [==============================] - 78s 1s/step - loss: 0.4787 - aspect_model_loss: 0.4358 - pretrain_model_loss: 0.4284 - aspect_model_categorical_accuracy: 0.8486 - pretrain_model_categorical_accuracy: 0.8411 - val_loss: 1.2758 - val_aspect_model_loss: 1.2355 - val_pretrain_model_loss: 0.4028 - val_aspect_model_categorical_accuracy: 0.5333 - val_pretrain_model_categorical_accuracy: 0.8625\n",
            "Epoch 9/20\n",
            "58/57 [==============================] - 79s 1s/step - loss: 0.4309 - aspect_model_loss: 0.3889 - pretrain_model_loss: 0.4199 - aspect_model_categorical_accuracy: 0.8551 - pretrain_model_categorical_accuracy: 0.8438 - val_loss: 1.2270 - val_aspect_model_loss: 1.1873 - val_pretrain_model_loss: 0.3975 - val_aspect_model_categorical_accuracy: 0.5917 - val_pretrain_model_categorical_accuracy: 0.8500\n",
            "Epoch 10/20\n",
            "58/57 [==============================] - 78s 1s/step - loss: 0.4019 - aspect_model_loss: 0.3637 - pretrain_model_loss: 0.3826 - aspect_model_categorical_accuracy: 0.8696 - pretrain_model_categorical_accuracy: 0.8572 - val_loss: 1.1881 - val_aspect_model_loss: 1.1515 - val_pretrain_model_loss: 0.3658 - val_aspect_model_categorical_accuracy: 0.6042 - val_pretrain_model_categorical_accuracy: 0.8438\n",
            "Epoch 11/20\n",
            "58/57 [==============================] - 79s 1s/step - loss: 0.3710 - aspect_model_loss: 0.3353 - pretrain_model_loss: 0.3573 - aspect_model_categorical_accuracy: 0.8798 - pretrain_model_categorical_accuracy: 0.8648 - val_loss: 1.2776 - val_aspect_model_loss: 1.2376 - val_pretrain_model_loss: 0.4003 - val_aspect_model_categorical_accuracy: 0.5729 - val_pretrain_model_categorical_accuracy: 0.8458\n",
            "Epoch 12/20\n",
            "58/57 [==============================] - 80s 1s/step - loss: 0.3555 - aspect_model_loss: 0.3198 - pretrain_model_loss: 0.3569 - aspect_model_categorical_accuracy: 0.8825 - pretrain_model_categorical_accuracy: 0.8588 - val_loss: 1.3592 - val_aspect_model_loss: 1.3259 - val_pretrain_model_loss: 0.3330 - val_aspect_model_categorical_accuracy: 0.5729 - val_pretrain_model_categorical_accuracy: 0.8604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRm_R9Nd1RU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}