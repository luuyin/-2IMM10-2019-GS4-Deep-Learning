{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical-5.1.1-Doc-Level-Sentiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP7gc5hgwVsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5263c8c5-abdd-4aad-b30b-16e351ea6dd9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZZvLUOjwW0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "723d051d-b240-42bf-f384-3e1b966f7a10"
      },
      "source": [
        "cd drive/My Drive/Recsys-2019/sequence_classifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Recsys-2019/sequence_classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m5jVTO9v5FO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import operator\n",
        "import numpy as np\n",
        "import re\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbMfdG7Vv5FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import _pickle as cPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOAXiNJov5FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'data/doc_level-sentiment/doc_level'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqnyCf-Iv5Fc",
        "colab_type": "text"
      },
      "source": [
        "### Reading preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ-8y1Ppv5Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_pickle(data_path, file_name):\n",
        "\n",
        "    f = open(os.path.join(data_path, file_name), 'rb')\n",
        "    read_file = cPickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    return read_file\n",
        "\n",
        "def save_pickle(data_path, file_name, data):\n",
        "\n",
        "    f = open(os.path.join(data_path, file_name), 'wb')\n",
        "    cPickle.dump(data, f)\n",
        "    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuF5ST-nyc5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_idx = read_pickle(data_path, 'words_idx.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjazKEjCv5Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_words = read_pickle(data_path, 'idx_words.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s8ZpQ1Kv5Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_pickle(data_path, 'data.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSn6Vf3iv5Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = read_pickle(data_path, 'label.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi2WcltTv5Fy",
        "colab_type": "text"
      },
      "source": [
        "### Preparing training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCrgFUrPv5Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7ed197f-dc71-4e18-fb3f-18bae8635951"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wix5IbPUv5F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand_idx = np.arange(len(data))\n",
        "np.random.shuffle(rand_idx)\n",
        "\n",
        "data = data[rand_idx]\n",
        "label = to_categorical(label)[rand_idx]\n",
        "\n",
        "data_size = len(data)\n",
        "\n",
        "test_x = data[0:1000]\n",
        "test_y = label[0:1000]\n",
        "\n",
        "dev_x = data[1000:5000]\n",
        "dev_y = label[1000:5000]\n",
        "\n",
        "train_x = data[5000:int(data_size)]\n",
        "train_y = label[5000:int(data_size)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeW7CeBkv5F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 300\n",
        "\n",
        "import operator\n",
        "words_idx = [x for (x, _) in sorted(words_idx.items(), key=operator.itemgetter(1))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10RZiZVIv5GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_ = sequence.pad_sequences(train_x, maxlen)\n",
        "dev_x_ = sequence.pad_sequences(dev_x, maxlen)\n",
        "test_x_ = sequence.pad_sequences(test_x, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyeT_Jljv5GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_ = np.array(train_x_)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "dev_x_ = np.array(dev_x_)\n",
        "dev_y = np.array(dev_y)\n",
        "\n",
        "test_x_ = np.array(test_x_)\n",
        "test_y = np.array(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJbIvmlv5GF",
        "colab_type": "text"
      },
      "source": [
        "### Data iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2j6mvnuv5GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataiterator():\n",
        "    '''\n",
        "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
        "      2) Access to the entire dataset using all()\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n",
        "        self.X = X \n",
        "        self.y = y \n",
        "        self.num_data = len(X) # total number of examples\n",
        "        self.batch_size = batch_size # batch size\n",
        "        self.reset() # initial: shuffling examples and set index to 0\n",
        "    \n",
        "    def __iter__(self): # iterates data\n",
        "        return self\n",
        "\n",
        "\n",
        "    def reset(self): # initials\n",
        "        self.idx = 0\n",
        "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
        "        \n",
        "    def __next__(self): # return model inputs - outputs per batch\n",
        "        X_ids = [] # hold ids per batch \n",
        "        while len(X_ids) < self.batch_size:\n",
        "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
        "            X_ids.append(X_id)\n",
        "            self.idx += 1 # \n",
        "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
        "                self.reset()\n",
        "                raise StopIteration()\n",
        "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
        "        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n",
        "        return batch_X, batch_y\n",
        "\n",
        "          \n",
        "    def all(self): # return all data examples\n",
        "        return self.X, self.y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od298ABQv5GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "13GNLSaWu7np"
      },
      "source": [
        "### LSTM Model for document level sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p0I4Ob1uvL3O",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSsbDQICv5GQ",
        "colab_type": "text"
      },
      "source": [
        "### Input Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us7DBc-wv5GR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "sentence_input = Input(shape=(None,), dtype='int32', name='sentence_input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_pVCWpfv5GV",
        "colab_type": "text"
      },
      "source": [
        "### Layer to train embedding weights of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-I0dhPwv5GZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "57552aa7-0ead-4772-ee5e-0f252261d2a2"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "vocab_size = len(words_idx)\n",
        "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
        "emb_output = word_emb(sentence_input)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhAN6hEsv5Gc",
        "colab_type": "text"
      },
      "source": [
        "### RNN-based layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlGhmKVYv5Gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e08d2ce7-e3cf-48b5-e545-2ef2d2eee6db"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "dropout= 0.5\n",
        "recurrent_dropout = 0.1 \n",
        "lstm_layer = LSTM(300, return_sequences=False, dropout=dropout, \\\n",
        "              recurrent_dropout=recurrent_dropout, name='lstm')(emb_output)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--kl4d4qv5Gh",
        "colab_type": "text"
      },
      "source": [
        "### Prediction layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBuZg8Y-v5Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "densed = Dense(3, name='dense')(lstm_layer)\n",
        "probs = Activation('softmax')(densed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPFfcyudv5Gk",
        "colab_type": "text"
      },
      "source": [
        "### Construct the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaNEjSv5v5Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "model = Model(inputs=[sentence_input], outputs=probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UAaC4TwKvVrF",
        "colab": {}
      },
      "source": [
        "import keras.optimizers as opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RaKx1llGv0Zp",
        "colab": {}
      },
      "source": [
        "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yUv6dojGv5ZR",
        "outputId": "aaf4f035-2d35-42b3-83f3-8ab2c9e86811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sentence_input (InputLayer)  (None, None)              0         \n",
            "_________________________________________________________________\n",
            "word_emb (Embedding)         (None, None, 300)         3000900   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 300)               721200    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 903       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 3,723,003\n",
            "Trainable params: 3,723,003\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI3oPgXyv5G0",
        "colab_type": "text"
      },
      "source": [
        "### Training with batch generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsPRC4wyv5G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H_apU4dZyFYE",
        "colab": {}
      },
      "source": [
        "train_steps_epoch = len(train_x_)/batch_size\n",
        "batch_train_iter = Dataiterator(train_x_, train_y, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RW7o0eEv5G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_steps_epoch = len(dev_x_)/batch_size\n",
        "batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMsnuBs_v5G_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def train_generator(model, batch_train_iter, batch_val_iter):\n",
        "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
        "                                     monitor='val_loss', save_best_only=False, \\\n",
        "                                     save_weights_only=True)\n",
        "                     ]\n",
        "    \n",
        "    def train_gen():\n",
        "        while True:\n",
        "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
        "            for train_batch in train_batches:\n",
        "                yield train_batch\n",
        "                \n",
        "    def val_gen():\n",
        "        while True:\n",
        "            val_batches = [[X, y] for X, y in batch_val_iter]\n",
        "            for val_batch in val_batches:\n",
        "                yield val_batch\n",
        "                \n",
        "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
        "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
        "                                  epochs = 20, callbacks = earlystop_callbacks)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcQqbbKnv5HC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "a5b45544-6e22-44f8-ca73-a59538ddac5e"
      },
      "source": [
        "train_generator(model, batch_train_iter, batch_val_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "782/781 [==============================] - 715s 914ms/step - loss: 0.9223 - categorical_accuracy: 0.5567 - val_loss: 0.8120 - val_categorical_accuracy: 0.6368\n",
            "Epoch 2/20\n",
            "782/781 [==============================] - 477s 609ms/step - loss: 0.7661 - categorical_accuracy: 0.6603 - val_loss: 0.7728 - val_categorical_accuracy: 0.6510\n",
            "Epoch 3/20\n",
            "782/781 [==============================] - 477s 610ms/step - loss: 0.6955 - categorical_accuracy: 0.7026 - val_loss: 0.7257 - val_categorical_accuracy: 0.6787\n",
            "Epoch 4/20\n",
            "782/781 [==============================] - 476s 609ms/step - loss: 0.6364 - categorical_accuracy: 0.7314 - val_loss: 0.7092 - val_categorical_accuracy: 0.6915\n",
            "Epoch 5/20\n",
            "782/781 [==============================] - 477s 610ms/step - loss: 0.5833 - categorical_accuracy: 0.7578 - val_loss: 0.7426 - val_categorical_accuracy: 0.6827\n",
            "Epoch 6/20\n",
            "782/781 [==============================] - 473s 605ms/step - loss: 0.5360 - categorical_accuracy: 0.7801 - val_loss: 0.7204 - val_categorical_accuracy: 0.6907\n",
            "Epoch 7/20\n",
            "478/781 [=================>............] - ETA: 2:56 - loss: 0.4784 - categorical_accuracy: 0.8087"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}