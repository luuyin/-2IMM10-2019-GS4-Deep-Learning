{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical-5.2.1.Seq2Seq-MT2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngzXe64RN6F5"
      },
      "source": [
        "# Practical 5.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fnNfIFdmN6F6"
      },
      "source": [
        "## Word-level Sequence-to-Sequence (Seq2Seq) Model For Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ZQpQ6daJBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CByfA7VNaOwb",
        "colab_type": "code",
        "outputId": "e5354d3d-6871-481e-8249-7f1a4a92fc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#cd drive/My Drive/Recsys-2019/Seq2Seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Recsys-2019/Seq2Seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2O-4rElr4cK7",
        "outputId": "8703f9fd-ffcd-460f-b9d1-c5348add85e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Lambda, Bidirectional, concatenate\n",
        "from keras.layers import Reshape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELUSmfBR5OeB",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q7WbEHLFN6GJ"
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9UFPwqfdN6GR",
        "colab": {}
      },
      "source": [
        "file_to_read = 'data/nld.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zzMjSUzhN6GV"
      },
      "source": [
        "Function to tokenize text into words (array list of words). Notice that we discard all punctuation in original text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-7xouvqN6GW",
        "colab": {}
      },
      "source": [
        "def tokenizeWords(text):\n",
        "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "    clean_text = regex.sub('', text)\n",
        "    tokens = clean_text.split()\n",
        "   \n",
        "       \n",
        "    return [t.lower() for t in tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xczSbmW0N6Ga",
        "colab": {}
      },
      "source": [
        "def indexingVocabulary(array_of_words):\n",
        "    \n",
        "    # frequency of word across document corpus\n",
        "    tf = nltk.FreqDist(array_of_words)\n",
        "    wordIndex = list(tf.keys())\n",
        "    \n",
        "    wordIndex.insert(0,'<pad>')\n",
        "    wordIndex.append('<start>')\n",
        "    wordIndex.append('<end>')\n",
        "    wordIndex.append('<unk>')\n",
        "    # indexing word vocabulary : pairs of (index,word)\n",
        "    vocab=dict([(i,wordIndex[i]) for i in range(len(wordIndex))])\n",
        "    \n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l5Tzs-dHN6Gd",
        "colab": {}
      },
      "source": [
        "#reading text line by line\n",
        "lines = open(os.path.join('./',file_to_read)).read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0nB5VEeGN6Gl"
      },
      "source": [
        "### Tokenization and vocabulary indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRXtiOIrZ1FK",
        "colab_type": "text"
      },
      "source": [
        "Notice that we only use 10.000 samples from data. Training a Seq2Seq model is computationally expensive (memory!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SiHn1xC_N6Gn",
        "colab": {}
      },
      "source": [
        "num_samples = 10000  # Number of samples to train on.\n",
        "\n",
        "input_str_tokens = []\n",
        "target_str_tokens = []\n",
        "\n",
        "ind_start = 10000\n",
        "ind_end = 10000 + min(num_samples, len(lines) - 1)\n",
        "\n",
        "for line in lines[ind_start : ind_end]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # tokenize text from source language (english text)\n",
        "    input_str_tokens.append(tokenizeWords(input_text))\n",
        "    # tokenize text from target language (dutch text)\n",
        "    target_str_tokens.append(tokenizeWords(target_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GXfCi3lNN6G2"
      },
      "source": [
        "* `en_vocab` stores word index for encoder input sequences (english dictionary)\n",
        "* `nl_vocab` stores word index for decoder target sequences (dutch dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VizWlhZrN6G4",
        "colab": {}
      },
      "source": [
        "# build vocabulary index\n",
        "input_words = []\n",
        "target_words = []\n",
        "\n",
        "for i, tokens in enumerate(input_str_tokens):\n",
        "    input_words.extend(tokens)\n",
        "# vocabulary index for english text (input)    \n",
        "en_vocab = indexingVocabulary(input_words)\n",
        "\n",
        "for i, tokens in enumerate(target_str_tokens):\n",
        "    target_words.extend(tokens)\n",
        "# vocabulary index for dutch text (output)\n",
        "nl_vocab = indexingVocabulary(target_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "whO4KxJtN6HU"
      },
      "source": [
        "We also need to create reverse version of look up index to map text sequences into integer format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SwHwMyH3N6HV",
        "colab": {}
      },
      "source": [
        "en_reversedvocab = dict((v,k) for (k,v) in en_vocab.items())\n",
        "nl_reversedvocab = dict((v,k) for (k,v) in nl_vocab.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lsgA_CwiN6Ht"
      },
      "source": [
        "### Preparing training sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "926aTUknN6Hu"
      },
      "source": [
        "\n",
        "* `seq_int_input`: input sequences for encoder model \n",
        "* `seq_int_target`: input sequences for decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eYvxhiglN6Hu",
        "colab": {}
      },
      "source": [
        "# integer format of sequence input \n",
        "seq_int_input = []\n",
        "for i, text in enumerate(input_str_tokens):\n",
        "    int_tokens = [en_reversedvocab[i] for i in text]\n",
        "    seq_int_input.append(int_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eGYmgn7IN6Hx"
      },
      "source": [
        "For input and output sequences of decoder model, we add `starting` sign (`'<start>'`) and `ending` sign (`'<end>'`) at the beginning and last part of sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xnaM-sEFN6Hy",
        "colab": {}
      },
      "source": [
        "seq_int_target = []\n",
        "for i, text in enumerate(target_str_tokens):\n",
        "    targettext = list(text)\n",
        "    targettext.insert(0,'<start>')\n",
        "    targettext.append('<end>')\n",
        "  \n",
        "    int_tokens = [nl_reversedvocab[i] for i in targettext]\n",
        "    seq_int_target.append(int_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZpN-jcazN6IH"
      },
      "source": [
        "## 2. Word embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aODyKVzVN6IJ"
      },
      "source": [
        "* In character level, we define input and output sequences as one-hot vector in 3D numpy arrays (number of samples, sequence length, vocabulary size). \n",
        "* For word-level, we have integer input sequences with 2D shape (number of samples, sequence length). Instead of one-hot encoding words, we will use embedding layer to project each word sequence to its embedding.\n",
        "* We will train our text with Word2Vec - Skipgram to provide initial weight for our embedding layer (may also use pretrained word embedding)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bacbSkfIN6IM",
        "colab": {}
      },
      "source": [
        "# for english text\n",
        "# skipgram model with hierarchical softmax and negative sampling\n",
        "word2vec_model_en = Word2Vec(size=256, min_count=0, window=5, sg=1, \n",
        "                          hs=1, negative=5, iter=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BuyBFPI5N6IO",
        "colab": {}
      },
      "source": [
        "word2vec_model_en.build_vocab(input_str_tokens)\n",
        "word2vec_vocab_en = dict([(v.index,k) for k, v in word2vec_model_en.wv.vocab.items()]) \n",
        "revert_w2v_vocab_en = dict((v,k) for (k,v) in word2vec_vocab_en.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QhDgmZF2N6IS",
        "colab": {}
      },
      "source": [
        "# for dutch text\n",
        "# skipgram model with hierarchical softmax and negative sampling\n",
        "word2vec_model_nl = Word2Vec(size=256, min_count=0, window=5, sg=1, \n",
        "                          hs=1, negative=5, iter=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lWixcEyDN6IU",
        "colab": {}
      },
      "source": [
        "word2vec_model_nl.build_vocab(target_str_tokens)\n",
        "word2vec_vocab_nl = dict([(v.index,k) for k, v in word2vec_model_nl.wv.vocab.items()]) \n",
        "revert_w2v_vocab_nl = dict((v,k) for (k,v) in word2vec_vocab_nl.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JU7yeMwCN6IW",
        "outputId": "e02d848a-18ea-4050-db64-bb8334af14d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Training word2vec model...')\n",
        "\n",
        "# for english text\n",
        "# number of tokens\n",
        "n_tokens = sum([len(seq) for seq in input_str_tokens])\n",
        "# number of sentences/documents\n",
        "n_examples = len(input_str_tokens)\n",
        "word2vec_model_en.train(input_str_tokens, total_words=n_tokens, \n",
        "                        total_examples=n_examples, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training word2vec model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4257876, 5946200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0EVh-IbTN6Ia",
        "outputId": "f1c9180c-a6d9-4eba-b04a-2f35333930a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# for dutch text\n",
        "# number of tokens\n",
        "n_tokens = sum([len(seq) for seq in target_str_tokens])\n",
        "# number of sentences/documents\n",
        "n_examples = len(target_str_tokens)\n",
        "word2vec_model_nl.train(target_str_tokens, total_words=n_tokens, \n",
        "                        total_examples=n_examples, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4297542, 6123900)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7f2RwH1MN6Ic"
      },
      "source": [
        "The following variables store our word embedding learnt from word2vec skipgram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJJo_mWSN6Id",
        "outputId": "22b00ff9-3dac-4246-b485-3d2ebfbb837c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# the resulting learnt word embedding \n",
        "# for input text sequence (english language)\n",
        "word2vec_we_en = word2vec_model_en.wv.syn0\n",
        "\n",
        "# for target text sequence (dutch language)\n",
        "word2vec_we_nl = word2vec_model_nl.wv.syn0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Toqk01MJN6If"
      },
      "source": [
        "Notice that vocabulary size of word embedding learnt by word2vec is less than our vocabulary size since we add additional word tokens: `'<pad>'`, `'<start>'`, `'<end>'`, `'<unk>'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mnKKsNZKN6Ig",
        "outputId": "d4040632-9c93-4581-d0da-07fb3f423af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2vec_we_en.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4163, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BUf5Jnq4N6Il",
        "outputId": "c01ea35a-4402-4dfb-b20a-c710bd07c185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2vec_we_nl.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5280, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fMv4Xq0VN6Ip",
        "colab": {}
      },
      "source": [
        "embedding_en = np.zeros(shape=(len(en_vocab), 256), dtype='float32')\n",
        "embedding_nl = np.zeros(shape=(len(nl_vocab), 256), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04N_q8Dk9hjB",
        "outputId": "88e60a40-35af-4582-de09-69c3703403ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_en.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4167, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2v5ANNN9joH",
        "outputId": "d4cd48cd-078a-4f3e-95e6-3c703a2c463e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_nl.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5284, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EQGsbAoN6Ix",
        "colab": {}
      },
      "source": [
        "# for input sequences (text in english language)\n",
        "for i, w in en_vocab.items():\n",
        "    # this will assign default weight 0 for words: 'SOF', 'EOF', and 'UNK'\n",
        "    if w not in word2vec_vocab_en.values():\n",
        "        continue\n",
        "    embedding_en[i, :] = word2vec_we_en[revert_w2v_vocab_en[w], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gOb07ivBN6I1",
        "colab": {}
      },
      "source": [
        "# for target output sequences (text in dutch language)\n",
        "for i, w in nl_vocab.items():\n",
        "    # this will assign default weight 0 for words: 'SOF', 'EOF', and 'UNK'\n",
        "    if w not in word2vec_vocab_nl.values():\n",
        "        continue\n",
        "    embedding_nl[i, :] = word2vec_we_nl[revert_w2v_vocab_nl[w], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JNemFSnlN6JA"
      },
      "source": [
        "## 3. Word-based Translation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ceI7WPR9N6JC"
      },
      "source": [
        "Parameters initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZYcBt8liN6JC",
        "colab": {}
      },
      "source": [
        "batch_size = 100  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "#num_samples = 1000  # Number of samples to train on.\n",
        "\n",
        "EN_VOCAB_SIZE = len(en_vocab) # vocabulary size of english words\n",
        "EN_EMBEDDING_DIM = embedding_en.shape[1] # embedding size of english words\n",
        "NL_VOCAB_SIZE = len(nl_vocab) # vocabulary size of dutch words\n",
        "NL_EMBEDDING_DIM = embedding_nl.shape[1] # embedding size of dutch words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x-Ehpl88N6JH"
      },
      "source": [
        "## 3.1. Encoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJPQvwsvZ1Gy",
        "colab_type": "text"
      },
      "source": [
        "Notice that in this example, we set parameters in our embedding layer to be trainable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Q64pDyQN6JJ",
        "outputId": "b1cdf9be-69a2-40f5-b81b-06b747c8d602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# encoder model\n",
        "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
        "encoder_embedding = Embedding(EN_VOCAB_SIZE, EN_EMBEDDING_DIM, trainable = True, \n",
        "              weights=[embedding_en], name='embedding_encoder')(encoder_inputs)\n",
        "gru_encoder = GRU(latent_dim, name='lstm_encoder')\n",
        "encoder_states = gru_encoder(encoder_embedding)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8bEpzhh0N6JR"
      },
      "source": [
        "## 3.2. Decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q0mXDNNeN6JT",
        "colab": {}
      },
      "source": [
        "# decoder model\n",
        "decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
        "decoder_embedding = Embedding(NL_VOCAB_SIZE, NL_EMBEDDING_DIM, trainable = True, \n",
        "              weights=[embedding_nl], name='embedding_decoder')\n",
        "embedding_output = decoder_embedding(decoder_inputs)\n",
        "\n",
        "s0 = Input(shape=(latent_dim,), name='s0') \n",
        "s = [s0]\n",
        "    \n",
        "gru_decoder = GRU(latent_dim, return_state=True)\n",
        "\n",
        "\n",
        "decoder_dense = Dense(NL_VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "probs = []\n",
        "\n",
        "for t in range(16):\n",
        "  \n",
        "    x_dec = Lambda(lambda x: x[:,t,:], name='dec_embedding-%s'%t)(embedding_output)\n",
        "    x_dec = Reshape((1, NL_EMBEDDING_DIM))(x_dec)\n",
        "    \n",
        "    enc_state_reshape = Reshape((1, 256))(encoder_states)\n",
        "    \n",
        "    context_concat = concatenate([x_dec, enc_state_reshape],axis=-1)\n",
        "       \n",
        "    \n",
        "    if t==0:\n",
        "        s = encoder_states\n",
        "        \n",
        "        \n",
        "    s, _  = lstm_decoder(context_concat, initial_state=s)\n",
        "    \n",
        "    prob = decoder_dense(s)\n",
        "    probs.append(prob)\n",
        "    \n",
        "    s = [s]\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acJ7avYwN6JV",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[encoder_inputs, decoder_inputs, s0], outputs=probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kL7yo8VvN6Ja",
        "colab": {}
      },
      "source": [
        "# Compile & run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WHcbEdSSN6Jc",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn5MJtl0N6Ji"
      },
      "source": [
        "## Training translation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jm36l64oN6Jk",
        "colab": {}
      },
      "source": [
        "max_encoder_seq_length = max([len(sequences) for sequences in seq_int_input])\n",
        "max_decoder_seq_length = max([len(sequences) for sequences in seq_int_target])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPt7xGNzQXO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_int_target = np.array(seq_int_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRpa2H5_QTZC",
        "colab_type": "code",
        "outputId": "9b11001b-ae5f-4c92-e266-89f8805cec60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_int_target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN3DDywTQf8H",
        "colab_type": "code",
        "outputId": "fea942c7-e03c-4edc-ca76-7630b3b22b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(seq_int_target[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U-GH-SWSMS_",
        "colab_type": "code",
        "outputId": "e36bdf5c-97e3-4119-ee57-946bd38f6d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_int_target[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5281, 1, 2, 3, 4, 5282]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLV8OLnITESi",
        "colab_type": "code",
        "outputId": "599c2fcd-67a0-4648-ae2d-e0934fb751ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_int_target[0][:-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5281, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZjW-X4ITMEZ",
        "colab_type": "code",
        "outputId": "4c229f00-8a01-4d74-8998-c4469621db1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_int_target[0][1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5282]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDPKPmU3SN3c",
        "colab_type": "code",
        "outputId": "752ed425-e60e-4084-9766-bcd2cf5cb47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_int_target[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5281, 5, 6, 7, 8, 9, 5282]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-v1o6ntrN6Js",
        "outputId": "3788aac0-6f34-4aed-f2bc-671693ddeb85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_encoder_seq_length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtfgKmPPN6Jw",
        "outputId": "25af20b7-6629-4bfd-e248-2c4b317c7087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_decoder_seq_length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZWApsisN6J4",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros((len(seq_int_input), max_encoder_seq_length), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uOGVMSRMN6J6",
        "colab": {}
      },
      "source": [
        "decoder_input_data = np.zeros((len(seq_int_input), max_decoder_seq_length), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXALtItjQof5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_target = np.zeros((len(seq_int_input), max_decoder_seq_length), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4TxbALbN6J8",
        "outputId": "728275f5-4843-4edf-c73e-fd23eb63bc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder_input_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M0sebLykN6J_",
        "outputId": "ab910691-b48e-4316-d007-a5aaa00360b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G4RukunuN6KB",
        "outputId": "0b8d5eea-cd97-4600-8aef-99e8cf7abc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qBgRBSA9N6KO"
      },
      "source": [
        "### Padding input sequences for encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wUcWaLrMN6KP",
        "colab": {}
      },
      "source": [
        "for i, seq_int in enumerate(seq_int_input):\n",
        "    for j, word_index in enumerate(seq_int):\n",
        "        encoder_input_data[i][j] = word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cxlPa5HDN6KW",
        "colab": {}
      },
      "source": [
        "for i, seq_int in enumerate(seq_int_target):\n",
        "  \n",
        "  seq_in = seq_int[:-1]\n",
        "  seq_out = seq_int[1:]\n",
        "  \n",
        "  for j, word_index in enumerate(seq_in):\n",
        "    decoder_input_data[i][j] = word_index\n",
        "    \n",
        "  for j, word_index in enumerate(seq_out):\n",
        "    decoder_target[i][j] = word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wDzpnyh0N6Kn",
        "outputId": "ad207795-7a83-441d-9778-813922507937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H5CqVuDJN6Kq",
        "outputId": "4659d458-e9d7-4177-d4f5-30f8f2511645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMdT50YHw4im",
        "colab_type": "code",
        "outputId": "7f004aff-5f03-4027-c8f4-27202ef3b027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(nl_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5284"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sk7hm_dxN6Kz"
      },
      "source": [
        "### Fitting sequences into model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vJnUjLcWN6K0"
      },
      "source": [
        "* Note: creating 3D numpy arrays of decoder output (one-hot-encoding) might cause Memory Error. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf-Oav0JOPbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "class Dataiterator():\n",
        "\n",
        "    def __init__(self, X, y_in, y_out, vocab_size=5284, seq_length=10, decoder_dim=256, batch_size=32):\n",
        "        \n",
        "        self.X = X\n",
        "        self.y_in = y_in \n",
        "        self.y_out = y_out\n",
        "        self.states = np.zeros((len(X), decoder_dim)) \n",
        "        self.num_data = len(X) \n",
        "        self.vocab_size = vocab_size\n",
        "        self.batch_size = batch_size \n",
        "        self.seq_length = seq_length\n",
        "        self.reset() # initial: shuffling examples and set index to 0\n",
        "        \n",
        "    \n",
        "    def onehotencoding(self, data):\n",
        "      \n",
        "            \n",
        "        return to_categorical(data, num_classes=self.vocab_size, dtype='int32')\n",
        "    \n",
        "    def __iter__(self): # iterates data\n",
        "        \n",
        "        return self\n",
        "\n",
        "\n",
        "    def reset(self): # initials\n",
        "        \n",
        "        self.idx = 0\n",
        "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
        "        \n",
        "    def __next__(self): # return model inputs - outputs per batch\n",
        "        \n",
        "        X_ids = [] # hold ids per batch \n",
        "\n",
        "        while len(X_ids) < self.batch_size:\n",
        "\n",
        "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
        "            X_ids.append(X_id)\n",
        "\n",
        "            self.idx += 1 # \n",
        "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
        "                self.reset()\n",
        "                raise StopIteration()\n",
        "    \n",
        "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
        "        batch_y_in = self.y_in[np.array(X_ids)] # y_in values (decoder input) per batch\n",
        "        batch_y_out = self.y_out[np.array(X_ids)]\n",
        "        batch_states = self.states[np.array(X_ids)] # state values (decoder state input) per batch\n",
        "        batch_y = self.onehotencoding(batch_y_out)\n",
        "        \n",
        "      \n",
        "        \n",
        "        return batch_X, batch_y_in, batch_states, list(batch_y.swapaxes(0,1))\n",
        "\n",
        "    # return all data examples \n",
        "    def all(self):\n",
        "      \n",
        "        y = self.onehotencoding(self.y_out)\n",
        "        \n",
        "        return self.X, self.y_in, self.states, list(y.swapaxes(0,1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9edyT58lPzrl",
        "colab_type": "code",
        "outputId": "2256fddd-49f0-437c-ad6d-eba6a31953dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder_input_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vvl-RIhP246",
        "colab_type": "code",
        "outputId": "b0e00d23-a747-4877-aeb1-e5d768327096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZKjkbo4P5Qi",
        "colab_type": "code",
        "outputId": "00c82b4a-a730-4aee-ddc4-908252670bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4thJbYiTtZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = encoder_input_data[:8000]\n",
        "y_train_in = decoder_input_data[:8000]\n",
        "y_train_out = decoder_target[:8000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSb6OJ8hUNfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train_in = np.array(y_train_in)\n",
        "y_train_out = np.array(y_train_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZASl_yjUaMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_dev = encoder_input_data[8000:len(encoder_input_data)]\n",
        "y_dev_in = decoder_input_data[8000:len(encoder_input_data)]\n",
        "y_dev_out = decoder_target[8000:len(encoder_input_data)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvDSUUX2UoCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_dev = np.array(x_dev)\n",
        "y_dev_in = np.array(y_dev_in)\n",
        "y_dev_out = np.array(y_dev_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORJLBLWQPkRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKQTLZO_PenZ",
        "colab_type": "code",
        "outputId": "0ee409bf-0853-4741-e997-b314fa7cbd73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_steps_epoch = len(x_train)/batch_size\n",
        "print(\"train_steps_epoch : %s\" %train_steps_epoch)\n",
        "batch_train_iter = Dataiterator(x_train, y_train_in, y_train_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_steps_epoch : 250.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdp9b7aVbON",
        "colab_type": "code",
        "outputId": "3e91c796-32cb-499d-b631-41d3ea3b15e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dev_steps_epoch = len(x_dev)/batch_size\n",
        "print(\"dev_steps_epoch : %s\" %dev_steps_epoch)\n",
        "batch_dev_iter = Dataiterator(x_dev, y_dev_in, y_dev_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev_steps_epoch : 62.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMzoVLacV8Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def train_generator(model, batch_train_iter, batch_val_iter):\n",
        "    \n",
        "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
        "                                     monitor='val_loss', save_best_only=False, \\\n",
        "                                     save_weights_only=True)\n",
        "                     ]\n",
        "    \n",
        "    def train_gen():\n",
        "        while True:\n",
        "            train_batches = [[[X, y_in, state], y_out] for X, y_in, \\\n",
        "                             state, y_out in batch_train_iter]\n",
        "            for train_batch in train_batches:\n",
        "                yield train_batch\n",
        "                \n",
        "    def val_gen():\n",
        "        while True:\n",
        "            val_batches = [[[X, y_in, state], y_out] for X, y_in, \\\n",
        "                           state, y_out in batch_val_iter]\n",
        "            for val_batch in val_batches:\n",
        "                yield val_batch\n",
        "                \n",
        "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
        "                                  validation_steps=dev_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
        "                                  epochs = 20, callbacks = earlystop_callbacks)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTDgT8-WIkq",
        "colab_type": "code",
        "outputId": "255a602e-fbc2-4074-a998-ebd38c3bbab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "train_generator(model, batch_train_iter, batch_dev_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 134s 534ms/step - loss: 38.6090 - dense_1_loss: 0.1475 - val_loss: 39.1427 - val_dense_1_loss: 1.3952e-04\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 114s 458ms/step - loss: 29.2707 - dense_1_loss: 4.4578e-05 - val_loss: 34.7207 - val_dense_1_loss: 1.4256e-05\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 116s 466ms/step - loss: 25.1011 - dense_1_loss: 7.6310e-06 - val_loss: 32.1494 - val_dense_1_loss: 2.9824e-06\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 117s 470ms/step - loss: 22.2151 - dense_1_loss: 2.0628e-06 - val_loss: 30.2081 - val_dense_1_loss: 1.9956e-06\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 116s 463ms/step - loss: 19.9144 - dense_1_loss: 1.2927e-06 - val_loss: 29.9579 - val_dense_1_loss: 6.4900e-07\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 114s 456ms/step - loss: 18.0050 - dense_1_loss: 6.8415e-07 - val_loss: 28.2578 - val_dense_1_loss: 6.0143e-07\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 110s 439ms/step - loss: 16.3369 - dense_1_loss: 5.7730e-07 - val_loss: 28.2256 - val_dense_1_loss: 5.3857e-07\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 109s 436ms/step - loss: 14.8335 - dense_1_loss: 4.8213e-07 - val_loss: 27.5771 - val_dense_1_loss: 4.4582e-07\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 113s 451ms/step - loss: 13.6370 - dense_1_loss: 4.1845e-07 - val_loss: 27.6830 - val_dense_1_loss: 4.4177e-07\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 112s 450ms/step - loss: 12.4864 - dense_1_loss: 4.4022e-07 - val_loss: 27.3596 - val_dense_1_loss: 4.0050e-07\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 112s 446ms/step - loss: 11.5144 - dense_1_loss: 4.5096e-07 - val_loss: 27.5089 - val_dense_1_loss: 6.1796e-07\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 114s 456ms/step - loss: 10.7668 - dense_1_loss: 4.3147e-07 - val_loss: 27.5382 - val_dense_1_loss: 4.7601e-07\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 112s 446ms/step - loss: 10.0095 - dense_1_loss: 4.3508e-07 - val_loss: 27.7347 - val_dense_1_loss: 4.0378e-07\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 109s 436ms/step - loss: 9.4739 - dense_1_loss: 4.1254e-07 - val_loss: 27.9864 - val_dense_1_loss: 4.6321e-07\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 108s 433ms/step - loss: 9.0840 - dense_1_loss: 3.6388e-07 - val_loss: 28.0834 - val_dense_1_loss: 2.7600e-07\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 108s 432ms/step - loss: 8.7228 - dense_1_loss: 2.9691e-07 - val_loss: 28.0077 - val_dense_1_loss: 2.7473e-07\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 108s 431ms/step - loss: 8.3919 - dense_1_loss: 2.6645e-07 - val_loss: 28.6488 - val_dense_1_loss: 2.6411e-07\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 105s 422ms/step - loss: 8.0733 - dense_1_loss: 2.3287e-07 - val_loss: 28.9674 - val_dense_1_loss: 2.7564e-07\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 113s 452ms/step - loss: 7.7446 - dense_1_loss: 2.2560e-07 - val_loss: 28.6969 - val_dense_1_loss: 2.1766e-07\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 113s 452ms/step - loss: 7.5643 - dense_1_loss: 2.0549e-07 - val_loss: 28.8487 - val_dense_1_loss: 2.1459e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0sQnR_Pq_VG",
        "colab_type": "code",
        "outputId": "cea5643a-da2e-4b35-9f53-f96e28605857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train_generator(model, batch_train_iter, batch_dev_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 123s 492ms/step - loss: 7.3014 - dense_1_loss: 1.8635e-07 - val_loss: 29.1318 - val_dense_1_loss: 1.9744e-07\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 114s 456ms/step - loss: 7.1055 - dense_1_loss: 1.7848e-07 - val_loss: 29.4109 - val_dense_1_loss: 1.6054e-07\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 114s 456ms/step - loss: 6.9335 - dense_1_loss: 1.6829e-07 - val_loss: 29.3036 - val_dense_1_loss: 1.8136e-07\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 117s 468ms/step - loss: 6.7604 - dense_1_loss: 1.5932e-07 - val_loss: 29.5763 - val_dense_1_loss: 1.5427e-07\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 117s 468ms/step - loss: 6.6455 - dense_1_loss: 1.5340e-07 - val_loss: 29.8406 - val_dense_1_loss: 1.6356e-07\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 116s 464ms/step - loss: 6.5160 - dense_1_loss: 1.4863e-07 - val_loss: 30.0673 - val_dense_1_loss: 1.5460e-07\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 116s 464ms/step - loss: 6.4209 - dense_1_loss: 1.4891e-07 - val_loss: 30.1265 - val_dense_1_loss: 1.8065e-07\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 113s 452ms/step - loss: 6.2770 - dense_1_loss: 1.4623e-07 - val_loss: 30.0289 - val_dense_1_loss: 1.4682e-07\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 110s 440ms/step - loss: 6.2260 - dense_1_loss: 1.4190e-07 - val_loss: 30.8120 - val_dense_1_loss: 1.4842e-07\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 111s 444ms/step - loss: 6.1369 - dense_1_loss: 1.3783e-07 - val_loss: 30.6316 - val_dense_1_loss: 1.3609e-07\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 109s 436ms/step - loss: 6.0985 - dense_1_loss: 1.3883e-07 - val_loss: 30.3846 - val_dense_1_loss: 1.4189e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Pl0sMv64e2",
        "colab_type": "code",
        "outputId": "6c8920d3-6052-403e-d1fe-6673ae582d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train_generator(model, batch_train_iter, batch_dev_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 110s 438ms/step - loss: 6.0214 - dense_1_loss: 1.3753e-07 - val_loss: 30.8008 - val_dense_1_loss: 1.3967e-07\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 104s 418ms/step - loss: 5.9380 - dense_1_loss: 1.3423e-07 - val_loss: 31.0141 - val_dense_1_loss: 1.3541e-07\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 105s 420ms/step - loss: 5.8951 - dense_1_loss: 1.3192e-07 - val_loss: 31.2669 - val_dense_1_loss: 1.3520e-07\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 105s 421ms/step - loss: 5.8434 - dense_1_loss: 1.3077e-07 - val_loss: 31.3869 - val_dense_1_loss: 1.3059e-07\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 104s 415ms/step - loss: 5.7688 - dense_1_loss: 1.3029e-07 - val_loss: 31.2168 - val_dense_1_loss: 1.3151e-07\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 105s 421ms/step - loss: 5.7723 - dense_1_loss: 1.3074e-07 - val_loss: 31.2984 - val_dense_1_loss: 1.3361e-07\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 103s 412ms/step - loss: 5.7123 - dense_1_loss: 1.2887e-07 - val_loss: 31.6961 - val_dense_1_loss: 1.2997e-07\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 102s 410ms/step - loss: 5.6574 - dense_1_loss: 1.2866e-07 - val_loss: 31.4696 - val_dense_1_loss: 1.2699e-07\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 104s 415ms/step - loss: 5.6345 - dense_1_loss: 1.2713e-07 - val_loss: 31.8028 - val_dense_1_loss: 1.2837e-07\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 104s 414ms/step - loss: 5.6158 - dense_1_loss: 1.2729e-07 - val_loss: 31.9048 - val_dense_1_loss: 1.2903e-07\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 103s 412ms/step - loss: 5.5547 - dense_1_loss: 1.2688e-07 - val_loss: 31.9578 - val_dense_1_loss: 1.2725e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_PIy8t689b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('./weights_mt.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0WH-NaPoN6LA"
      },
      "source": [
        "## 4. Inference mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aOZBaLw7N6LB"
      },
      "source": [
        "## 4.1. Re-define encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P9SADoo0N6LF",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ShxnKd8FN6LH",
        "colab": {}
      },
      "source": [
        "encoder_model.save('encoder_word_lstm_translation.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MslR012dN6LK"
      },
      "source": [
        "## 4.2. Re-define decoder model to do the inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsa15zolkBp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_decoder = Input(shape=(1, ), name='decoder_input')\n",
        "in_state_decoder = Input(shape=(256,), name='dec_state_in')\n",
        "enc_out = Input(shape=(256,), name='enc_state')\n",
        "\n",
        "in_dec_embedded =  decoder_embedding(in_decoder)\n",
        "\n",
        "in_dec_embedded = Reshape((1,256))(in_dec_embedded)\n",
        "enc_out_ = Reshape((1,256))(enc_out)\n",
        "\n",
        "context_concat = concatenate([in_dec_embedded, enc_out_],axis=-1)\n",
        "\n",
        "\n",
        "s, _ = gru_decoder(context_concat, initial_state=[in_state_decoder])\n",
        "\n",
        "softmax_prob = decoder_dense(s)\n",
        "dec_states = [s]\n",
        "\n",
        "decoder_model = Model([in_decoder] + [enc_out] + [in_state_decoder] , [softmax_prob] + dec_states)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}