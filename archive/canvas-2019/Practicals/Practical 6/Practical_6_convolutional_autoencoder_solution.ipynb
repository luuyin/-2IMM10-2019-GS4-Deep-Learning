{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BruKfi2NCZM2",
    "outputId": "508f0162-e83b-4a92-8061-f75bc04db57c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeLLU7zA5xgN"
   },
   "source": [
    "# Practical: Convolutional autoencoder architectures\n",
    "In this practical we will look at how to design a convolutional autoencoder architecture. For the encoder, we can use similar architectures as for common classification/regression networks (e.g. VGG-style). Typically, the decoder is then designed to \"reverse\" the structure of the encoder. For fully connected layers this is straightforward, but for convolutional or pooling layers this leaves some options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_ghJwoMAOq9"
   },
   "source": [
    "## Data (MNIST)\n",
    "We'll use MNIST as a simple example. Images are 28x28 pixels, but for convolutional autoencoders with strides or pooling, it is very convenient if the image size is a multiple of the stride/pool size. Typically, we use 2x2 strides/pooling, so we rescale the canvas size of MNIST from 28x28 to 32x32 (since 32=2^5), by padding zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Xk9zHRsyAOMI",
    "outputId": "632f056d-c369-4a07-d65b-c2841a3cd9a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalise\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# change shape: (n, 28, 28) -> (n, 28, 28, 1)\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "# pad zeros to obtain canvas size of 32x32, i.e. shape is now (n, 32, 32, 1)\n",
    "x_train = np.pad(x_train, pad_width=((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "x_test = np.pad(x_test, pad_width=((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "# get height, width, and depth values\n",
    "height, width, depth = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSMvUpCcBJh-"
   },
   "source": [
    "## VGG-like encoder\n",
    "Let's make a simple VGG-like encoder with 2 convolutional blocks, each consisting of a single convolution and maxpooling, followed by two dense layers. We'll also include batch normalisation.\n",
    "\n",
    "Let's write the input and output shape of each layer in the comments, to get a better idea of the structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qWGPctQv5oKv",
    "outputId": "318cf454-8b92-4314-e625-bdc4e4183059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "x_in = Input(shape=(height, width, depth), name=\"encoder_input\")\n",
    "\n",
    "# conv block 1\n",
    "h = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\",\n",
    "           activation='relu')(x_in)                    # (32, 32, 1)  -> (32, 32, 64)\n",
    "h = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(h)  # (32, 32, 64) -> (16, 16, 64)\n",
    "h = BatchNormalization()(h)                            # no change\n",
    "\n",
    "# conv block 2\n",
    "h = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\",\n",
    "           activation='relu')(h)                       # (16, 16, 64)  -> (16, 16, 128)\n",
    "h = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(h)  # (16, 16, 128) -> (8, 8, 128)\n",
    "h = BatchNormalization()(h)                            # no change\n",
    "\n",
    "# dense layers\n",
    "h = Flatten()(h)                                       # (8, 8, 128) -> (8*8*128,)\n",
    "h = Dense(256, activation=\"relu\")(h)                   # (8*8*128,)  -> (256,)\n",
    "h = BatchNormalization()(h)                            # no change\n",
    "h = Dense(128, activation=\"relu\")(h)                   # (256,) -> (128,)\n",
    "h = BatchNormalization()(h)                            # no change\n",
    "encoded = Dense(32)(h)                                 # (128,) -> (32,) (encoding dimension)\n",
    "# NOTE: no activation for the last layer, encoded representations are vectors of real numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nt_45hfWGfjm"
   },
   "source": [
    "## Decoder architecture: reversing the structure\n",
    "For our decoder architecture, it seems natural to reverse the structure of the encoder, layer by layer. We could try some weight-tying between encoder and decoder, but typically this is not done; the encoder and decoder each have their own weights that are trained independently.\n",
    "\n",
    "Reversing the structure of a fully connected layer is simple; use the input size of the encoder layer as the number of output units for the decoder layer.\n",
    "\n",
    "To reverse convolutional layers (in particular when they are strided), we could use a transposed convolution (often mistakenly called \"deconvolution\") to reverse its structure. However, this is prone to creating unwanted artifacts, or the checkerboard effect (see https://distill.pub/2016/deconv-checkerboard/ for an excellent explanation). Therefore, we prefer to not use strided convolutions in the encoder, and we use MaxPooling to downsample the size of the activation maps. To reverse this downsampling, we can use the UpSampling layer in Keras (which is essentially nearest-neighbour interpolation as described and recommended in https://distill.pub/2016/deconv-checkerboard/). To \"reverse\" a non-strided convolution, we can then simply use another normal convolution, where we use the number of input activation maps (filters) in of the encoder conv-layer as the number of output activation maps (filters) for the decoder conv-layer.\n",
    "\n",
    "Now let's reverse the encoder architecture, making sure that we have the same change in shape for the hidden units, but reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RehLD1URrsnS"
   },
   "outputs": [],
   "source": [
    "# HOMEWORK: design the decoder architecture, by reversing the encoder architecture\n",
    "# the reversed order of the shapes is already given as a guide\n",
    "\n",
    "# (32,) -> (128,) (encoding dimension)\n",
    "# no change\n",
    "# (128, -> (256,)\n",
    "# no change\n",
    "# (256,)     -> (8*8*128,)\n",
    "# (8*8*128,) -> (8, 8, 128)\n",
    "\n",
    "# no change\n",
    "# (8, 8, 128  ) -> (16, 16, 128)\n",
    "# (16, 16, 128) -> (16, 16, 64)\n",
    "\n",
    "# no change\n",
    "# (16, 16, 64) -> (32, 32, 64)\n",
    "# (32, 32, 64) -> (32, 32, 1)\n",
    "# HINT: think about the activation for the last layer, which should represent\n",
    "#       pixel values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYhr2ZvlmKLV"
   },
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "# reverse dense layers\n",
    "h = Dense(128, activation=\"relu\")(encoded)  # (32,) -> (128,) (encoding dimension)\n",
    "h = BatchNormalization()(h)                 # no change\n",
    "h = Dense(256, activation=\"relu\")(h)        # (128, -> (256,)\n",
    "h = BatchNormalization()(h)                 # no change\n",
    "h = Dense(8*8*128, activation=\"relu\")(h)    # (256,)     -> (8*8*128,)\n",
    "h = Reshape((8, 8, 128))(h)                 # (8*8*128,) -> (8, 8, 128)\n",
    "\n",
    "# reverse conv block 2\n",
    "h = BatchNormalization()(h)                 # no change\n",
    "h = UpSampling2D(size=(2, 2))(h)            # (8, 8, 128  ) -> (16, 16, 128)\n",
    "h = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\",\n",
    "           activation='relu')(h)            # (16, 16, 128) -> (16, 16, 64)\n",
    "\n",
    "# reverse conv block 2\n",
    "h = BatchNormalization()(h)                 # no change\n",
    "h = UpSampling2D(size=(2, 2))(h)            # (16, 16, 64) -> (32, 32, 64)\n",
    "x_out = Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\",\n",
    "               activation='sigmoid')(h)     # (32, 32, 64) -> (32, 32, 1)\n",
    "# NOTE: sigmoid activation for the last layer, since it should represent\n",
    "#       pixel values between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_Gfx42fuHPy"
   },
   "source": [
    "## Compile, train, and test the model\n",
    "Let's setup and compile the autoencoder, and do a quick test. We use some loss function to compare the original data with its reconstruction, so we use the training set both as input and target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1751
    },
    "colab_type": "code",
    "id": "O34SRp8-uGfC",
    "outputId": "45780e0e-1b9e-4066-b4a2-4606038ff9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8192)              2105344   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 1)         577       \n",
      "=================================================================\n",
      "Total params: 4,430,497\n",
      "Trainable params: 4,428,193\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 19s 324us/step - loss: 0.1181 - val_loss: 0.0805\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0696 - val_loss: 0.0693\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0653 - val_loss: 0.0634\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0630 - val_loss: 0.0645\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0614 - val_loss: 0.0602\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.0604 - val_loss: 0.0581\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0598 - val_loss: 0.0586\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0591 - val_loss: 0.0579\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0586 - val_loss: 0.0582\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0585 - val_loss: 0.0587\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.0580 - val_loss: 0.0576\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0578 - val_loss: 0.0570\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0575 - val_loss: 0.0565\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0572 - val_loss: 0.0559\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0570 - val_loss: 0.0556\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0569 - val_loss: 0.0561\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0567 - val_loss: 0.0559\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.0566 - val_loss: 0.0554\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.0564 - val_loss: 0.0564\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.0563 - val_loss: 0.0558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f49d80137b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(x_in, x_out, name=\"autoencoder\")\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=100,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgT1vEyD24ay"
   },
   "source": [
    "Reconstruct and visualise some images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "9y7PSeOQz_Iy",
    "outputId": "308fc2c2-883d-41fe-c629-ee823135766e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  # number of images to plot\n",
    "indices = np.random.choice(len(x_test), size=n, replace=False)\n",
    "test_imgs = x_test[indices]\n",
    "reconstr_imgs = autoencoder.predict(test_imgs)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_imgs[i].reshape(32, 32))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstr_imgs[i].reshape(32, 32))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "practical_convolutional_autoencoder_solution.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
