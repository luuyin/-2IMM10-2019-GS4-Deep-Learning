\documentclass[a4paper,twoside,11pt]{article}
\usepackage{a4wide,graphicx,fancyhdr,amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}

%----------------------- Macros and Definitions --------------------------

\setlength\headheight{20pt}
\addtolength\topmargin{-10pt}
\addtolength\footskip{20pt}

\newcommand{\N}{\mathbb{N}}
\newcommand{\ch}{\mathcal{CH}}

\newcommand{\exercise}[2]{\noindent{\bf Question #1 (#2pt):} \\\\ }

\fancypagestyle{plain}{%
\fancyhf{}
\fancyhead[LO,RE]{\sffamily\bfseries\large Eindhoven University of Technology}
\fancyhead[RO,LE]{\sffamily\bfseries\large 2IMM10 Deep Learning}
\fancyfoot[LO,RE]{\sffamily\bfseries\large Department of Mathematics and Computer Science}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[RO,LE]{\sffamily\bfseries\large Eindhoven University of Technology}
\fancyhead[LO,RE]{\sffamily\bfseries\large 2IMM10 Deep Learning}
\fancyfoot[LO,RE]{\sffamily\bfseries\large Department of Mathematics and Computer Science}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{0pt}

%-------------------------------- Title ----------------------------------

\title{\vspace{-\baselineskip}\sffamily\bfseries Assignment 2 \\
\large Deadline: Friday, 29th May (23:59)}


\date{15th May, 2020}

%--------------------------------- Text ----------------------------------

\begin{document}
\maketitle


\exercise{1 - Neural Codes for Image Retrieval}{10}
Use the representations learned by a convolutional neural network (ConvNet) for image retrieval, as proposed in 
\begin{quote}
A.~Babenko, A.~Slesarev, A.~Chigorin, V.~Lempitsky, \textit{Neural Codes for Image Retrieval}, ECCV, 2014 (https://arxiv.org/abs/1404.1777).
\end{quote}
You can use the Jupyter notebook \verb!2IMM10_Assignment_2_1.ipynb!, which already downloads, loads and pre-processes the data, and provides some helper functions.
Write your code between all two consecutive occurrences of ``\verb!# ...!''.
See the text cells in the notebook for additional information.


\paragraph{Tiny Imagenet}
Use the training set of \emph{Tiny Imagenet},\footnote{https://tiny-imagenet.herokuapp.com/} consisting of $200$ classes, with $500$ images per class (total $100,000$ images), each image being of dimensions $64 \times 64$ RGB.
The Jupyter notebook already gets the data for you, and also performs the following steps.
\begin{itemize}
\item Split the $200$ classes into two sets, one containing $190$ classes and the other containing the remaining $10$ classes.
\item Shuffle the set with $190$ classes and divide it into \emph{training}, \emph{validation}, and \emph{test} sets, according to the proportions $80/10/10$.
\item The set with the remaining $10$ classes serves as \emph{out-of-domain} (ood) data, used for image retrieval.
\item Normalize pixel values to $[0,1]$.
\end{itemize}


\paragraph{Train ConvNet}
Reproduce the ConvNet architecture from Babenko et al., with two exceptions:
For \verb!Layer 1!, use kernel size $4 \times 4$ (instead of $11 \times 11$) and stride $1$ (instead of $4$).
For the hidden fully connected layers, \verb!Layer 6! and \verb!Layer 7!, use $2048$ units (instead of $4096$).
\begin{itemize}
\item Implement the model in Keras.
\item Train it by optimizing \emph{cross-entropy} with the \emph{Adam} optimizer, using a learning rate of $0.0001$ and a \emph{batch size} of $100$. Set the flag \emph{amsgrad} to \emph{True}.
\item Evaluate and report the \emph{train}, \emph{validation} and \emph{test} performance, in terms of \emph{cross-entropy}, \emph{classification accuracy} and \emph{top-5 classification accuracy}.
\item Name two techniques which would likely improve the test accuracy.
\end{itemize}


\paragraph{Image Retrieval}
Use the trained ConvNet to perform image retrieval on the ood data.
When using a certain image as query image, the remaining $4,999$ should serve as a retrieval date base.
\begin{itemize}
\item Obtain neural codes for each image in the ood data.
Use the same $3$ layers for neural codes which were used in the paper by Babenko et al.\footnote{The Jupyter notebook already provides functions to get these codes.}
\item Normalize the codes to have unit length.
\item For the first $10$ images in the ood set, find the respectively $5$ closest\footnote{Hint: You might want to exploit the relation between inner products and Euclidean distances.} images in the data base. 
Plot the query image next to the $5$ retrieved images (sorted from most to least similar) and mark the images which have the same class as the query image (see Fig.~2 and 3 in the paper).
\item What are the qualitative differences between the different layers for neural codes?
\item Compute and report the \emph{mean average precision} (mAP) over the whole ood set, for each of the $3$ layers. 
\item Do the observed mAP values (roughly) confirm the observations by Babenko et al.?
\end{itemize}




\vspace{\baselineskip}






\exercise{2 - Peer review}{0}
Finally, each group member must write a single paragraph outlining their opinion on the work distribution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly worked through the exercises? Do you think that some members of your group deserve a different grade from others?
\end{document}