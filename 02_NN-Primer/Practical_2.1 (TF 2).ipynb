{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practical_2.1 (TF 2).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMgVLmT6T3mvziNKHYFQarn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_TLQNpYmj6yT","colab_type":"text"},"source":["## Notebook MLP model for MNIST classification\n","\n","In this notebook we are going to train a neural network to classify digits.\n"]},{"cell_type":"code","metadata":{"id":"6mYVZoEpf25Q","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOpTXMVBk-bM","colab_type":"code","colab":{}},"source":["# import libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.utils import plot_model\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXdOthLdk-8D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"35aa7a1b-b0f1-40b1-b475-bec17262ba2c","executionInfo":{"status":"ok","timestamp":1587633753741,"user_tz":-120,"elapsed":1533,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["print(tf.__version__) #  check what version of TF is imported"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2.2.0-rc3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LdeJyCqumCCR","colab_type":"text"},"source":["## Import MNIST data\n","We obtain the MNIST data set directly through `Keras`, given a fully labelled training and test sets. Loading the dataset returns four `NumPy` arrays."]},{"cell_type":"code","metadata":{"id":"JGhghA7XlHs8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"970ebfce-87d0-4084-eb67-62f99f940cb5","executionInfo":{"status":"ok","timestamp":1587633760052,"user_tz":-120,"elapsed":1270,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["from keras.datasets import mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"LFz6toKamWbb","colab_type":"text"},"source":["Each example is an image of 28x28 pixels, given as integer grayscale values from 0 to 255. Each example has a label, an integer 0 to 9. `x_train` and `y_train` are the training data containing 60,000 samples, which the model uses to learn. `x_test` and `y_test` form the test set of 10,000 samples, which we use to evaluate the model performance."]},{"cell_type":"code","metadata":{"id":"WLIkVZvomUHf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"7103b5c6-ca3d-4ad2-a8f4-a715484a6bb0","executionInfo":{"status":"ok","timestamp":1587633773479,"user_tz":-120,"elapsed":805,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","(60000,)\n","(10000, 28, 28)\n","(10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fik1CKwYnQkT","colab_type":"text"},"source":["We can use `matplotlib` to quickly visualise some of the data."]},{"cell_type":"code","metadata":{"id":"Gcd5GtFfmZnD","colab_type":"code","colab":{}},"source":["def plot_digit(example_id, X, Y):\n","  example = X[example_id].reshape(width, height)\n","  label = Y[example_id]\n","  print(\"Class label:\", label)\n","  plt.matshow(example, cmap=\"gray\")\n","  plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqxawGR3nx4Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b92ac4a5-90d7-4ff2-e6ba-c351a3e6528b","executionInfo":{"status":"ok","timestamp":1587633791271,"user_tz":-120,"elapsed":842,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["np.random.seed(13) # set seed such that np.random.choice always returns same index\n","random_index = np.random.choice(len(x_test), 1)\n","random_index"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([338])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"5H8omywZoS42","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fd9be3c8-ad03-41d3-ddb1-9e190c72aa0d","executionInfo":{"status":"ok","timestamp":1587633792221,"user_tz":-120,"elapsed":581,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["width, height = x_train.shape[1], x_train.shape[2]\n","width, height"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"wWjaQFJKnlqD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"26843524-5e6f-4e83-cf13-8e8eca606f95","executionInfo":{"status":"ok","timestamp":1587633798556,"user_tz":-120,"elapsed":1085,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["plot_digit(random_index, x_test, y_test) # plot random image from the test dataset"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Class label: [8]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"vpntzKktot_m","colab_type":"text"},"source":["* The pixel values are given by integer values from 0 to 255, we normalise this to obtain float values from 0 to 1.\n","* Labels are given as values 0 to 9, but here we need so-called \"one-hot\" encodings, e.g. 3 becomes [0,0,0,1,0,0,0,0,0,0]"]},{"cell_type":"code","metadata":{"id":"jI-mxDJGou59","colab_type":"code","colab":{}},"source":["x_train = x_train.astype(\"float32\")\n","x_test = x_test.astype(\"float32\")\n","\n","# normalise data\n","x_train /= 255 \n","x_test /= 255\n","\n","n_classes = 10\n","\n","# convert labels to one-hot encodings\n","y_train = to_categorical(y_train, n_classes) \n","y_test = to_categorical(y_test, n_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tuQyHqczpH_H","colab_type":"text"},"source":["Observe how the shapes of the labels have changed."]},{"cell_type":"code","metadata":{"id":"m1aMNsWlow3J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"771587fb-4383-40b5-e0b3-96d4a99faf48","executionInfo":{"status":"ok","timestamp":1587633822898,"user_tz":-120,"elapsed":834,"user":{"displayName":"Joris","photoUrl":"","userId":"16387411804571903952"}}},"source":["print(y_train.shape)\n","print(y_test.shape)\n","print(\"example one-hot encoding:\", y_train[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(60000, 10)\n","(10000, 10)\n","example one-hot encoding: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mQKVR0DTqNM9","colab_type":"text"},"source":["# Model architecture & settings\n","\n","We build an MLP with two hidden layers, with the given number of hidden units. We also include Dropout for each of the layers, with the given dropout rate."]},{"cell_type":"code","metadata":{"id":"YuxUVihSpuPP","colab_type":"code","colab":{}},"source":["intermediate_dim1 = 256\n","intermediate_dim2 = 128\n","dropout_rate = 0.2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SmidM6FiqRgu","colab_type":"text"},"source":["* Initialise a Keras Sequential model\n","* Add a Flatten layer, which transforms the format of the images from a two dimensional array (28,28) to a one dimensional array of 28*28 = 784 elements. Dense layers (which we add after this Flatten layer) expect the data to be given as vectors, not matrices. The first layer  (i.e. the Flatten layer in this model) must explicitly receive the shape of the input (`width`, `height`) , following layers can do automatice shape inference.\n","* Add two hidden (Dense) layers with ReLU activations and dropout, then a (Dense) Softmax layer with 10 classes (to obtain classification predictions summing up to 1). \n","* Compile the model with the following settings:\n","    * use stochastic gradient descent with the \"adadelta\" optimizer to train the model\n","    * MNIST is a multi-class classification problem, use categorical cross entropy loss function\n","    * output accuracy (% of correctly classified instances) when evaluating the model\n","\n","    "]},{"cell_type":"code","metadata":{"id":"XIRMOl9BqQQ6","colab_type":"code","colab":{}},"source":["# TODO implement model here\n","model = ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gnsS8MWnEzxl","colab_type":"text"},"source":["We can use `Keras.utils.plot_model` to visualize the architecture of the model. This is very useful if you want to see an overview of the input and output shapes per layer."]},{"cell_type":"code","metadata":{"id":"AVK__Jc6Fej1","colab_type":"code","colab":{}},"source":["plot_model(model, show_shapes = True, show_layer_names=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1EJlVgoX52VE","colab_type":"code","colab":{}},"source":["model.summary() # shows the number of parameters in the model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGD4Gc5gsRkv","colab_type":"text"},"source":["## Training the model\n","\n","Train the model (using stochastic gradient descent) with given batch size, for given number of epochs. We split 1/12-th of the data (5,000 of the 60,000 samples) as validation data, such that we can use the validation accuracy for hyperparameter tuning.\n","\n","<b>HINT</b>: To increase training speed of your model, you can use the free available GPU power in Google Colab. Go to `Edit` --> `Notebook Settings` --> select `GPU` under `hardware accelerator`.\n","\n","Use [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) to train the model on the training data. Validate on 1/12th of the data and use the given batch size and number of epochs."]},{"cell_type":"code","metadata":{"id":"KT8oy7cusG1-","colab_type":"code","colab":{}},"source":["batch_size = 100\n","epochs = 20\n","\n","# TODO fit the model on training data\n","history = ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3PuYLttBcsU","colab_type":"text"},"source":["The returned `history` object holds a record of the loss values and metric values during training. We will use this object later to plot the loss and accuracy values for each epoch."]},{"cell_type":"markdown","metadata":{"id":"5KGMLlgisVsZ","colab_type":"text"},"source":["# Evaluating the model\n","\n","We evaluate the model using the test set, obtaining the test loss and accuracy (% examples correctly classified)\n","\n","Use [keras.Model.evaluate](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate) to evaluate the model on the test data. Note that `keras.model.evaluate` returns a list, where in this case the first element corresponds to the loss and the second element corresponds to the accuracy of the model on the given test data."]},{"cell_type":"code","metadata":{"id":"8N5FjSH-sfbM","colab_type":"code","colab":{}},"source":["# TODO evaluate on test data\n","...\n","\n","print('Test loss: {:.2f}'.format(loss))\n","print('Test accuracy: {:.2f}'.format(accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gejMvsJytLWV","colab_type":"text"},"source":["We can use the `history` object to plot the loss and accuracy values for each epoch."]},{"cell_type":"code","metadata":{"id":"W2_s4M6us81K","colab_type":"code","colab":{}},"source":["plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label = 'val_loss')\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train loss', 'Test loss'], loc='upper right')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_BAGoB9vat0","colab_type":"code","colab":{}},"source":["plt.plot(history.history['accuracy'], label='loss')\n","plt.plot(history.history['val_accuracy'], label = 'val_loss')\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train accuracy', 'Test accuracy'], loc='upper right')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-_oQI5MdvkSN","colab_type":"text"},"source":["## Make predictions\n","\n","When the model is trained, we can use it to make predictions about some images. We can use [keras.Model.predict](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) on the model object defined earlier in this notebook. The model expects input as a <i>batch</i>, i.e. the input shape is (batch_size, `width`, `height`). Therefore, even when you want to use a single image to test, we have to reshape the test image to (1,`width`, `height`) before feeding into the network. The model returns an array of size `n_classes` where for each class the model predicts the probability this sample belongs to that class."]},{"cell_type":"code","metadata":{"id":"7d167qvBvfVY","colab_type":"code","colab":{}},"source":["# TODO: select one image from the test data and reshape the image to the correct shape (1,width,height) using .reshape from the NumPy library\n","\n","# TODO: let the model predict one image\n","predictions = ...\n","predictions"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DqSngeUWxSLF","colab_type":"text"},"source":["To see which label has the highest probability, we use `np.argmax` to return the <u>index</u> of the maximum value."]},{"cell_type":"code","metadata":{"id":"f_LX9Bbew7s3","colab_type":"code","colab":{}},"source":["pred_label = np.argmax(predictions[0]) # predicted label\n","pred_label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6LvJgbPwyLUR","colab_type":"text"},"source":["We can use the true label to test if the classification of the model is correct."]},{"cell_type":"code","metadata":{"id":"zTHwuSaqyAvJ","colab_type":"code","colab":{}},"source":["true_label = np.argmax(y_test[random_index]) # true label\n","true_label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jKiEfdv-ChSI","colab_type":"code","colab":{}},"source":["if pred_label == true_label:\n","  print('The model correctly classified this sample.')\n","else:\n","  print('The model misclassified this sample.')"],"execution_count":0,"outputs":[]}]}